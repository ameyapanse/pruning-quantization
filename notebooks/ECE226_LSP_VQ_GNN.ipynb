{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!echo 2 | sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prOa9Fu3jhAU",
        "outputId": "a8cee2f3-a2d5-467c-9369-022da23f9a53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.10   2         auto mode\n",
            "  1            /usr/bin/python3.10   2         manual mode\n",
            "  2            /usr/bin/python3.8    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAJaW107j5NH",
        "outputId": "0c3d2a8f-6e50-4768-dc07-f942755a2414"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOThIfFxoSMB",
        "outputId": "0b084a04-5ffd-417b-ec44-178f755806a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.9 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.9 [231 kB]\n",
            "Fetched 2,389 kB in 2s (1,049 kB/s)\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.9_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.9) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.9_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.9) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.9) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install torch==1.9.0\n",
        "!pip install torch-geometric==1.7.2 \\\n",
        "  torch-sparse==0.6.12 \\\n",
        "  torch-scatter==2.0.9 \\\n",
        "  torch-cluster==1.5.9 \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install ogb==1.3.1"
      ],
      "metadata": {
        "id": "5E7VRlEGj7kF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92da0bdd-c18f-4d79-995d-5b91a8cb42d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 15 kB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: typing-extensions, torch\n",
            "Successfully installed torch-1.9.0 typing-extensions-4.6.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-geometric==1.7.2\n",
            "  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 29.6 MB/s \n",
            "\u001b[?25hCollecting torch-sparse==0.6.12\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.12-cp38-cp38-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 41.1 MB/s \n",
            "\u001b[?25hCollecting torch-scatter==2.0.9\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.9-cp38-cp38-linux_x86_64.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 61.5 MB/s \n",
            "\u001b[?25hCollecting torch-cluster==1.5.9\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp38-cp38-linux_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 74.5 MB/s \n",
            "\u001b[?25hCollecting googledrivedownloader\n",
            "  Downloading googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 79.5 MB/s \n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 68.8 MB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 277 kB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 42.2 MB/s \n",
            "\u001b[?25hCollecting pyparsing\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting python-louvain\n",
            "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
            "\u001b[K     |████████████████████████████████| 204 kB 84.5 MB/s \n",
            "\u001b[?25hCollecting rdflib\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[K     |████████████████████████████████| 528 kB 74.6 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 66.4 MB/s \n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[K     |████████████████████████████████| 341 kB 78.5 MB/s \n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[K     |████████████████████████████████| 502 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 76.0 MB/s \n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 691 kB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 128 kB/s \n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 84.7 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 86.9 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 84.1 MB/s \n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[K     |████████████████████████████████| 297 kB 88.6 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: torch-geometric, python-louvain\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388123 sha256=9a32357ad798c14cc550deef6cbb457c62beb48417f1f4f357ae3b221db6589c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/f4/19/2332058c82a978e7ef746a160eb1d7c181c7ba25f16cd01333\n",
            "  Building wheel for python-louvain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9395 sha256=8d4c9068a622c894685404235f790cb29f2fd4970e77e3c777e640fcfd1af456\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/40/91/ef3635f7d3ddbd889b5af9f1ac22b8d30c48d6f744cd74a6d1\n",
            "Successfully built torch-geometric python-louvain\n",
            "Installing collected packages: googledrivedownloader, MarkupSafe, jinja2, networkx, numpy, tzdata, pytz, six, python-dateutil, pandas, pyparsing, python-louvain, isodate, rdflib, idna, urllib3, charset-normalizer, certifi, requests, scipy, joblib, threadpoolctl, scikit-learn, tqdm, torch-geometric, torch-sparse, torch-scatter, torch-cluster\n",
            "Successfully installed MarkupSafe-2.1.3 certifi-2023.5.7 charset-normalizer-3.1.0 googledrivedownloader-0.4 idna-3.4 isodate-0.6.1 jinja2-3.1.2 joblib-1.2.0 networkx-3.1 numpy-1.24.3 pandas-2.0.2 pyparsing-3.0.9 python-dateutil-2.8.2 python-louvain-0.16 pytz-2023.3 rdflib-6.3.2 requests-2.31.0 scikit-learn-1.2.2 scipy-1.10.1 six-1.16.0 threadpoolctl-3.1.0 torch-cluster-1.5.9 torch-geometric-1.7.2 torch-scatter-2.0.9 torch-sparse-0.6.12 tqdm-4.65.0 tzdata-2023.3 urllib3-2.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb==1.3.1\n",
            "  Downloading ogb-1.3.1-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.9.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (2.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.24.3)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.2.2)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->ogb==1.3.1) (4.6.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb==1.3.1) (2023.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb==1.3.1) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb==1.3.1) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb==1.3.1) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb==1.3.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb==1.3.1) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/lib/python3/dist-packages (from outdated>=0.2.0->ogb==1.3.1) (45.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb==1.3.1) (2.31.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb==1.3.1) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb==1.3.1) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb==1.3.1) (3.4)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=1c5383acf4c54b84d7fd5f391e1c04081034e0cff3f47bd3e92e2cdeed4133f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/33/c4/0ef84d7f5568c2823e3d63a6e08988852fb9e4bc822034870a\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.1 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcAKJrJWisc4",
        "outputId": "83c2d5ba-7473-4df7-9079-39601551b018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pruning-quantization'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (345/345), done.\u001b[K\n",
            "remote: Compressing objects: 100% (245/245), done.\u001b[K\n",
            "remote: Total 345 (delta 114), reused 310 (delta 79), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (345/345), 12.67 MiB | 10.84 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ameyapanse/pruning-quantization.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd pruning-quantization && git checkout main-local"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMwxXDtQSISi",
        "outputId": "ec83f372-43bb-43c9-8174-e360f242cae0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'main-local' set up to track remote branch 'main-local' from 'origin'.\n",
            "Switched to a new branch 'main-local'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd pruning-quantization/VQ-GNN/vq_gnn_v2/lsp/  && pip install -r requirments.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9TohKhKUQeW",
        "outputId": "f88b8001-b60a-4ede-c61a-7de1109a866b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clearml==1.11.0\n",
            "  Downloading clearml-1.11.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.4 MB/s \n",
            "\u001b[?25hCollecting data==0.4\n",
            "  Downloading data-0.4.tar.gz (7.0 kB)\n",
            "Collecting datasketch==1.5.9\n",
            "  Downloading datasketch-1.5.9-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.7.1\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 60.5 MB/s \n",
            "\u001b[?25hCollecting mp==0.5.0\n",
            "  Downloading mp-0.5.0.tar.gz (36 kB)\n",
            "Requirement already satisfied: networkx==3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirments.txt (line 6)) (3.1)\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting paramiko==3.2.0\n",
            "  Downloading paramiko-3.2.0-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit_learn==1.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirments.txt (line 9)) (1.2.2)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.8/dist-packages (from -r requirments.txt (line 10)) (1.10.1)\n",
            "Collecting sympy==1.12\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.8/dist-packages (from -r requirments.txt (line 12)) (4.65.0)\n",
            "Collecting warmup_scheduler==0.3\n",
            "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
            "Collecting torchvision==0.10\n",
            "  Downloading torchvision-0.10.0-cp38-cp38-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 75.7 MB/s \n",
            "\u001b[?25hCollecting psutil>=3.4.2\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[K     |████████████████████████████████| 282 kB 79.8 MB/s \n",
            "\u001b[?25hCollecting attrs>=18.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.8/dist-packages (from clearml==1.11.0->-r requirments.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from clearml==1.11.0->-r requirments.txt (line 1)) (2.8.2)\n",
            "Collecting jsonschema>=2.6.0\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.6 MB/s \n",
            "\u001b[?25hCollecting pyjwt<2.5.0,>=2.4.0; python_version > \"3.5\"\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Collecting furl>=2.0.0\n",
            "  Downloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from clearml==1.11.0->-r requirments.txt (line 1)) (2.0.3)\n",
            "Collecting PyYAML>=3.12\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[K     |████████████████████████████████| 701 kB 78.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from clearml==1.11.0->-r requirments.txt (line 1)) (2.31.0)\n",
            "Collecting Pillow>=4.1.1\n",
            "  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 24.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from clearml==1.11.0->-r requirments.txt (line 1)) (1.16.0)\n",
            "Collecting pathlib2>=2.3.0\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from clearml==1.11.0->-r requirments.txt (line 1)) (3.0.9)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.1 MB/s \n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.40.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 50.9 MB/s \n",
            "\u001b[?25hCollecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[K     |████████████████████████████████| 300 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.3->-r requirments.txt (line 7)) (2023.3)\n",
            "Collecting cryptography>=3.3\n",
            "  Downloading cryptography-41.0.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.5\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.2\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.2.2->-r requirments.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn==1.2.2->-r requirments.txt (line 9)) (3.1.0)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[K     |████████████████████████████████| 536 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10->-r requirments.txt (line 14)) (1.9.0)\n",
            "Collecting pkgutil-resolve-name>=1.3.10; python_version < \"3.9\"\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting orderedmultidict>=1.0.1\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->clearml==1.11.0->-r requirments.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->clearml==1.11.0->-r requirments.txt (line 1)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->clearml==1.11.0->-r requirments.txt (line 1)) (3.1.0)\n",
            "Collecting zipp>=3.1.0; python_version < \"3.10\"\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[K     |████████████████████████████████| 442 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->torchvision==0.10->-r requirments.txt (line 14)) (4.6.3)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 68.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: data, mp, warmup-scheduler\n",
            "  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for data: filename=data-0.4-py3-none-any.whl size=7244 sha256=869237a5c5a0a676e029949991f5b9bd82d6474cd64746dcbd5d8d0944de951a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/78/30/ac68ac8de8481b3b4334617a48ef1758323f30709b2f923362\n",
            "  Building wheel for mp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mp: filename=mp-0.5.0-py3-none-any.whl size=51011 sha256=81afb3fadb7c1c9b988ddc21082c5a233b3fed087bbec0b1ac49e5209a6f26f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/bb/5b/8a2be7fdc41a9b7b0044858e2e1ff16f5ab366489e965567e5\n",
            "  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2998 sha256=65e3083949b9ce6edc17dde2574d2eaec2abe6b0d659c52677bc4972c358b2f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ce/4a/215c4f0add432420ff90fe04656bf2664ddfac7302e2b6fe51\n",
            "Successfully built data mp warmup-scheduler\n",
            "Installing collected packages: psutil, attrs, zipp, importlib-resources, pkgutil-resolve-name, pyrsistent, jsonschema, pyjwt, orderedmultidict, furl, PyYAML, Pillow, pathlib2, clearml, decorator, funcsigs, data, datasketch, kiwisolver, fonttools, cycler, packaging, contourpy, matplotlib, pycparser, cffi, cryptography, pynacl, bcrypt, paramiko, mp, pandas, mpmath, sympy, warmup-scheduler, torchvision\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.2\n",
            "    Uninstalling pandas-2.0.2:\n",
            "      Successfully uninstalled pandas-2.0.2\n",
            "Successfully installed Pillow-9.5.0 PyYAML-6.0 attrs-23.1.0 bcrypt-4.0.1 cffi-1.15.1 clearml-1.11.0 contourpy-1.1.0 cryptography-41.0.1 cycler-0.11.0 data-0.4 datasketch-1.5.9 decorator-5.1.1 fonttools-4.40.0 funcsigs-1.0.2 furl-2.1.3 importlib-resources-5.12.0 jsonschema-4.17.3 kiwisolver-1.4.4 matplotlib-3.7.1 mp-0.5.0 mpmath-1.3.0 orderedmultidict-1.0.1 packaging-23.1 pandas-1.5.3 paramiko-3.2.0 pathlib2-2.3.7.post1 pkgutil-resolve-name-1.3.10 psutil-5.9.5 pycparser-2.21 pyjwt-2.4.0 pynacl-1.5.0 pyrsistent-0.19.3 sympy-1.12 torchvision-0.10.0 warmup-scheduler-0.3 zipp-3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd pruning-quantization/VQ-GNN/vq_gnn_v2/ && python main_node.py --hidden-channels 256  --lr 3e-3 --epochs 5000 --batch-size 10000 \\\n",
        "  --test-batch-size 0 --num-M 4096 --num-D 4  --conv-type GAT --sampler-type node --dataset ppi --skip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnBwNzgdjUpe",
        "outputId": "b89b91f9-2809-46c3-e900-4b9df4b413c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch 2.0, train acc:0.8893806614534604\n",
            "num_B_prime:29697, new edges:0\n",
            "Batch 3.0, train acc:0.8839264674568813\n",
            "num_B_prime:28666, new edges:0\n",
            "Batch 4.0, train acc:0.8960250442805947\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 146, Loss: 0.1721, Loss Cls: 0.1721, Train: 83.81%, Valid: 80.41%, Test: 82.62%\n",
            "num_B_prime:29817, new edges:0\n",
            "Batch 0.0, train acc:0.8843937075609395\n",
            "num_B_prime:29628, new edges:0\n",
            "Batch 1.0, train acc:0.8894094469926628\n",
            "num_B_prime:29810, new edges:0\n",
            "Batch 2.0, train acc:0.8842128465760227\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 3.0, train acc:0.890909261929301\n",
            "num_B_prime:28861, new edges:0\n",
            "Batch 4.0, train acc:0.8910520044042265\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 147, Loss: 0.1713, Loss Cls: 0.1713, Train: 82.95%, Valid: 79.57%, Test: 82.04%\n",
            "num_B_prime:30019, new edges:0\n",
            "Batch 0.0, train acc:0.8904434115289724\n",
            "num_B_prime:29705, new edges:0\n",
            "Batch 1.0, train acc:0.8866224762712646\n",
            "num_B_prime:29612, new edges:0\n",
            "Batch 2.0, train acc:0.8909640709358587\n",
            "num_B_prime:29967, new edges:0\n",
            "Batch 3.0, train acc:0.8880078137933317\n",
            "num_B_prime:28699, new edges:0\n",
            "Batch 4.0, train acc:0.8937059124591112\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 148, Loss: 0.1708, Loss Cls: 0.1708, Train: 84.70%, Valid: 81.48%, Test: 83.54%\n",
            "num_B_prime:29907, new edges:0\n",
            "Batch 0.0, train acc:0.8869394605648946\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 1.0, train acc:0.8881448193096045\n",
            "num_B_prime:29815, new edges:0\n",
            "Batch 2.0, train acc:0.885810010339934\n",
            "num_B_prime:29743, new edges:0\n",
            "Batch 3.0, train acc:0.89081142334136\n",
            "num_B_prime:28652, new edges:0\n",
            "Batch 4.0, train acc:0.8854170220023879\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 149, Loss: 0.1721, Loss Cls: 0.1721, Train: 72.13%, Valid: 68.69%, Test: 71.28%\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 0.0, train acc:0.88612694885663\n",
            "num_B_prime:29765, new edges:0\n",
            "Batch 1.0, train acc:0.8822632241495806\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 2.0, train acc:0.8896909321030497\n",
            "num_B_prime:29792, new edges:0\n",
            "Batch 3.0, train acc:0.8883310026598724\n",
            "num_B_prime:28895, new edges:0\n",
            "Batch 4.0, train acc:0.8976046327981047\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 150, Loss: 0.1721, Loss Cls: 0.1721, Train: 84.95%, Valid: 81.74%, Test: 83.97%\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 0.0, train acc:0.8909142678487685\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 1.0, train acc:0.895333991695902\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 2.0, train acc:0.8889024331119315\n",
            "num_B_prime:29810, new edges:0\n",
            "Batch 3.0, train acc:0.8911595662256394\n",
            "num_B_prime:28766, new edges:0\n",
            "Batch 4.0, train acc:0.8886049870805495\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 151, Loss: 0.1675, Loss Cls: 0.1675, Train: 81.05%, Valid: 77.48%, Test: 79.90%\n",
            "num_B_prime:29813, new edges:0\n",
            "Batch 0.0, train acc:0.8897094404363893\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 1.0, train acc:0.887660721720741\n",
            "num_B_prime:29824, new edges:0\n",
            "Batch 2.0, train acc:0.8927289354790277\n",
            "num_B_prime:29589, new edges:0\n",
            "Batch 3.0, train acc:0.887893276550914\n",
            "num_B_prime:29329, new edges:0\n",
            "Batch 4.0, train acc:0.8927721302752806\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 152, Loss: 0.1683, Loss Cls: 0.1683, Train: 83.43%, Valid: 80.11%, Test: 82.49%\n",
            "num_B_prime:29669, new edges:0\n",
            "Batch 0.0, train acc:0.8901354312853874\n",
            "num_B_prime:29726, new edges:0\n",
            "Batch 1.0, train acc:0.8904829562803044\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 2.0, train acc:0.8869924214039276\n",
            "num_B_prime:29865, new edges:0\n",
            "Batch 3.0, train acc:0.8876474746938126\n",
            "num_B_prime:28862, new edges:0\n",
            "Batch 4.0, train acc:0.8830659025787966\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 153, Loss: 0.1712, Loss Cls: 0.1712, Train: 78.15%, Valid: 74.66%, Test: 76.88%\n",
            "num_B_prime:29849, new edges:0\n",
            "Batch 0.0, train acc:0.8837219336709653\n",
            "num_B_prime:29690, new edges:0\n",
            "Batch 1.0, train acc:0.8763549590275785\n",
            "num_B_prime:29899, new edges:0\n",
            "Batch 2.0, train acc:0.8810932884893172\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 3.0, train acc:0.8773037877068351\n",
            "num_B_prime:28932, new edges:0\n",
            "Batch 4.0, train acc:0.8891887536159042\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 154, Loss: 0.1796, Loss Cls: 0.1796, Train: 82.43%, Valid: 78.93%, Test: 81.26%\n",
            "num_B_prime:29720, new edges:0\n",
            "Batch 0.0, train acc:0.8841271848343077\n",
            "num_B_prime:29798, new edges:0\n",
            "Batch 1.0, train acc:0.8916988216367521\n",
            "num_B_prime:29805, new edges:0\n",
            "Batch 2.0, train acc:0.8879821615788066\n",
            "num_B_prime:30049, new edges:0\n",
            "Batch 3.0, train acc:0.8939665903104819\n",
            "num_B_prime:28520, new edges:0\n",
            "Batch 4.0, train acc:0.895667510853835\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 155, Loss: 0.1688, Loss Cls: 0.1688, Train: 83.50%, Valid: 80.15%, Test: 82.57%\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 0.0, train acc:0.8964751595892313\n",
            "num_B_prime:29891, new edges:0\n",
            "Batch 1.0, train acc:0.8964925240703063\n",
            "num_B_prime:29972, new edges:0\n",
            "Batch 2.0, train acc:0.8955476242915557\n",
            "num_B_prime:29673, new edges:0\n",
            "Batch 3.0, train acc:0.8898266176391987\n",
            "num_B_prime:28360, new edges:0\n",
            "Batch 4.0, train acc:0.8946341545816195\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 156, Loss: 0.1639, Loss Cls: 0.1639, Train: 84.93%, Valid: 81.65%, Test: 83.96%\n",
            "num_B_prime:29796, new edges:0\n",
            "Batch 0.0, train acc:0.8875719450874531\n",
            "num_B_prime:29734, new edges:0\n",
            "Batch 1.0, train acc:0.8886221217206574\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 2.0, train acc:0.8844510334001918\n",
            "num_B_prime:29826, new edges:0\n",
            "Batch 3.0, train acc:0.8872493824751668\n",
            "num_B_prime:29006, new edges:0\n",
            "Batch 4.0, train acc:0.8864993083864134\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 157, Loss: 0.1713, Loss Cls: 0.1713, Train: 77.64%, Valid: 73.91%, Test: 76.48%\n",
            "num_B_prime:29751, new edges:0\n",
            "Batch 0.0, train acc:0.8894225636299011\n",
            "num_B_prime:29640, new edges:0\n",
            "Batch 1.0, train acc:0.8861484778770231\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 2.0, train acc:0.8900883218842002\n",
            "num_B_prime:29995, new edges:0\n",
            "Batch 3.0, train acc:0.8881152217390277\n",
            "num_B_prime:28990, new edges:0\n",
            "Batch 4.0, train acc:0.8954237914320848\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 158, Loss: 0.1694, Loss Cls: 0.1694, Train: 83.03%, Valid: 79.60%, Test: 81.77%\n",
            "num_B_prime:30007, new edges:0\n",
            "Batch 0.0, train acc:0.8886025327704955\n",
            "num_B_prime:29711, new edges:0\n",
            "Batch 1.0, train acc:0.8951163477141928\n",
            "num_B_prime:29701, new edges:0\n",
            "Batch 2.0, train acc:0.8883645599646428\n",
            "num_B_prime:29798, new edges:0\n",
            "Batch 3.0, train acc:0.8940300191851935\n",
            "num_B_prime:28547, new edges:0\n",
            "Batch 4.0, train acc:0.8887942470554719\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 159, Loss: 0.1668, Loss Cls: 0.1668, Train: 80.24%, Valid: 76.49%, Test: 79.18%\n",
            "num_B_prime:29990, new edges:0\n",
            "Batch 0.0, train acc:0.8943810951632589\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 1.0, train acc:0.882514001244555\n",
            "num_B_prime:30128, new edges:0\n",
            "Batch 2.0, train acc:0.8920864650391782\n",
            "num_B_prime:29557, new edges:0\n",
            "Batch 3.0, train acc:0.8834633453175346\n",
            "num_B_prime:28530, new edges:0\n",
            "Batch 4.0, train acc:0.8907965486370851\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 160, Loss: 0.1711, Loss Cls: 0.1711, Train: 82.88%, Valid: 79.42%, Test: 81.67%\n",
            "num_B_prime:29869, new edges:0\n",
            "Batch 0.0, train acc:0.8804661515415668\n",
            "num_B_prime:29862, new edges:0\n",
            "Batch 1.0, train acc:0.8908033819516962\n",
            "num_B_prime:29853, new edges:0\n",
            "Batch 2.0, train acc:0.8833526087180408\n",
            "num_B_prime:29776, new edges:0\n",
            "Batch 3.0, train acc:0.8870639691730628\n",
            "num_B_prime:28788, new edges:0\n",
            "Batch 4.0, train acc:0.8868614266727735\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 161, Loss: 0.1728, Loss Cls: 0.1728, Train: 77.79%, Valid: 74.54%, Test: 76.92%\n",
            "num_B_prime:29762, new edges:0\n",
            "Batch 0.0, train acc:0.885347358522544\n",
            "num_B_prime:29766, new edges:0\n",
            "Batch 1.0, train acc:0.8845952816353632\n",
            "num_B_prime:29640, new edges:0\n",
            "Batch 2.0, train acc:0.8913970265974036\n",
            "num_B_prime:29915, new edges:0\n",
            "Batch 3.0, train acc:0.889393675604316\n",
            "num_B_prime:29019, new edges:0\n",
            "Batch 4.0, train acc:0.8965002037397565\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 162, Loss: 0.1695, Loss Cls: 0.1695, Train: 84.30%, Valid: 81.19%, Test: 83.38%\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 0.0, train acc:0.8920810637483864\n",
            "num_B_prime:29904, new edges:0\n",
            "Batch 1.0, train acc:0.8994633175485554\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 2.0, train acc:0.9005093527226571\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 3.0, train acc:0.8996440652468839\n",
            "num_B_prime:28425, new edges:0\n",
            "Batch 4.0, train acc:0.9042537311330985\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 163, Loss: 0.1587, Loss Cls: 0.1587, Train: 84.54%, Valid: 81.20%, Test: 83.56%\n",
            "num_B_prime:29874, new edges:0\n",
            "Batch 0.0, train acc:0.8972519753928015\n",
            "num_B_prime:29648, new edges:0\n",
            "Batch 1.0, train acc:0.8986990742070837\n",
            "num_B_prime:29795, new edges:0\n",
            "Batch 2.0, train acc:0.8971717758258306\n",
            "num_B_prime:29957, new edges:0\n",
            "Batch 3.0, train acc:0.8947297797331751\n",
            "num_B_prime:28666, new edges:0\n",
            "Batch 4.0, train acc:0.8974873860216757\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 164, Loss: 0.1605, Loss Cls: 0.1605, Train: 84.23%, Valid: 80.88%, Test: 83.17%\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 0.0, train acc:0.8934400431017302\n",
            "num_B_prime:29990, new edges:0\n",
            "Batch 1.0, train acc:0.8912522064310754\n",
            "num_B_prime:29525, new edges:0\n",
            "Batch 2.0, train acc:0.8931794460830076\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 3.0, train acc:0.8902735791501292\n",
            "num_B_prime:28992, new edges:0\n",
            "Batch 4.0, train acc:0.8946210166655044\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 165, Loss: 0.1655, Loss Cls: 0.1655, Train: 82.63%, Valid: 79.33%, Test: 81.68%\n",
            "num_B_prime:29713, new edges:0\n",
            "Batch 0.0, train acc:0.8913633730586874\n",
            "num_B_prime:29945, new edges:0\n",
            "Batch 1.0, train acc:0.8903200213393156\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 2.0, train acc:0.889639374912871\n",
            "num_B_prime:29776, new edges:0\n",
            "Batch 3.0, train acc:0.8888728682321004\n",
            "num_B_prime:29247, new edges:0\n",
            "Batch 4.0, train acc:0.8946402645028219\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 166, Loss: 0.1678, Loss Cls: 0.1678, Train: 84.38%, Valid: 81.07%, Test: 83.33%\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 0.0, train acc:0.8899965264263623\n",
            "num_B_prime:29749, new edges:0\n",
            "Batch 1.0, train acc:0.8937679455276328\n",
            "num_B_prime:29783, new edges:0\n",
            "Batch 2.0, train acc:0.8908235471558986\n",
            "num_B_prime:29885, new edges:0\n",
            "Batch 3.0, train acc:0.8918542085809199\n",
            "num_B_prime:28936, new edges:0\n",
            "Batch 4.0, train acc:0.8936238047658493\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 167, Loss: 0.1650, Loss Cls: 0.1650, Train: 84.59%, Valid: 81.16%, Test: 83.60%\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 0.0, train acc:0.8991897428197593\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 1.0, train acc:0.8900282597653344\n",
            "num_B_prime:29446, new edges:0\n",
            "Batch 2.0, train acc:0.8967542823668198\n",
            "num_B_prime:29892, new edges:0\n",
            "Batch 3.0, train acc:0.8879317038599404\n",
            "num_B_prime:29328, new edges:0\n",
            "Batch 4.0, train acc:0.8972197651157411\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 168, Loss: 0.1632, Loss Cls: 0.1632, Train: 84.39%, Valid: 81.13%, Test: 83.31%\n",
            "num_B_prime:29815, new edges:0\n",
            "Batch 0.0, train acc:0.8887763945019225\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 1.0, train acc:0.8966299372866813\n",
            "num_B_prime:29743, new edges:0\n",
            "Batch 2.0, train acc:0.8944050804919645\n",
            "num_B_prime:29679, new edges:0\n",
            "Batch 3.0, train acc:0.8988005794406668\n",
            "num_B_prime:29032, new edges:0\n",
            "Batch 4.0, train acc:0.8947094724330256\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 169, Loss: 0.1619, Loss Cls: 0.1619, Train: 82.88%, Valid: 79.59%, Test: 81.88%\n",
            "num_B_prime:29918, new edges:0\n",
            "Batch 0.0, train acc:0.8962402490146804\n",
            "num_B_prime:29688, new edges:0\n",
            "Batch 1.0, train acc:0.8889057200340968\n",
            "num_B_prime:29879, new edges:0\n",
            "Batch 2.0, train acc:0.8919679507688957\n",
            "num_B_prime:29821, new edges:0\n",
            "Batch 3.0, train acc:0.8884229031675854\n",
            "num_B_prime:28551, new edges:0\n",
            "Batch 4.0, train acc:0.8926531271152599\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 170, Loss: 0.1657, Loss Cls: 0.1657, Train: 83.02%, Valid: 79.61%, Test: 81.86%\n",
            "num_B_prime:29685, new edges:0\n",
            "Batch 0.0, train acc:0.8877341591101607\n",
            "num_B_prime:29848, new edges:0\n",
            "Batch 1.0, train acc:0.8903409122015581\n",
            "num_B_prime:29903, new edges:0\n",
            "Batch 2.0, train acc:0.8915379218313637\n",
            "num_B_prime:29700, new edges:0\n",
            "Batch 3.0, train acc:0.8929754212576027\n",
            "num_B_prime:28879, new edges:0\n",
            "Batch 4.0, train acc:0.8965542310843421\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 171, Loss: 0.1655, Loss Cls: 0.1655, Train: 77.10%, Valid: 73.31%, Test: 75.91%\n",
            "num_B_prime:29915, new edges:0\n",
            "Batch 0.0, train acc:0.8914660468431024\n",
            "num_B_prime:29762, new edges:0\n",
            "Batch 1.0, train acc:0.8890904699430755\n",
            "num_B_prime:29751, new edges:0\n",
            "Batch 2.0, train acc:0.8883036863654957\n",
            "num_B_prime:29800, new edges:0\n",
            "Batch 3.0, train acc:0.8894875361727413\n",
            "num_B_prime:28737, new edges:0\n",
            "Batch 4.0, train acc:0.888279084007552\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 172, Loss: 0.1693, Loss Cls: 0.1693, Train: 80.51%, Valid: 77.22%, Test: 79.25%\n",
            "num_B_prime:29678, new edges:0\n",
            "Batch 0.0, train acc:0.885801718995117\n",
            "num_B_prime:30002, new edges:0\n",
            "Batch 1.0, train acc:0.8915984316783641\n",
            "num_B_prime:29875, new edges:0\n",
            "Batch 2.0, train acc:0.8961929795044777\n",
            "num_B_prime:29879, new edges:0\n",
            "Batch 3.0, train acc:0.8970661881025785\n",
            "num_B_prime:28308, new edges:0\n",
            "Batch 4.0, train acc:0.9001191908707777\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 173, Loss: 0.1631, Loss Cls: 0.1631, Train: 83.18%, Valid: 79.82%, Test: 82.06%\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 0.0, train acc:0.8975004870796088\n",
            "num_B_prime:29892, new edges:0\n",
            "Batch 1.0, train acc:0.9017116841640336\n",
            "num_B_prime:29734, new edges:0\n",
            "Batch 2.0, train acc:0.8979870955953094\n",
            "num_B_prime:29746, new edges:0\n",
            "Batch 3.0, train acc:0.8974690569791253\n",
            "num_B_prime:28612, new edges:0\n",
            "Batch 4.0, train acc:0.8975443523529008\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 174, Loss: 0.1582, Loss Cls: 0.1582, Train: 82.77%, Valid: 79.49%, Test: 81.91%\n",
            "num_B_prime:29852, new edges:0\n",
            "Batch 0.0, train acc:0.8967709839826887\n",
            "num_B_prime:29705, new edges:0\n",
            "Batch 1.0, train acc:0.8941826811120105\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 2.0, train acc:0.8966151745833889\n",
            "num_B_prime:29663, new edges:0\n",
            "Batch 3.0, train acc:0.8906458577335008\n",
            "num_B_prime:29181, new edges:0\n",
            "Batch 4.0, train acc:0.8992779361529242\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 175, Loss: 0.1617, Loss Cls: 0.1617, Train: 81.77%, Valid: 78.15%, Test: 80.27%\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 0.0, train acc:0.8876759131441823\n",
            "num_B_prime:29635, new edges:0\n",
            "Batch 1.0, train acc:0.8933946026606906\n",
            "num_B_prime:29704, new edges:0\n",
            "Batch 2.0, train acc:0.8852975229567212\n",
            "num_B_prime:29919, new edges:0\n",
            "Batch 3.0, train acc:0.8870419586919245\n",
            "num_B_prime:28857, new edges:0\n",
            "Batch 4.0, train acc:0.8848802660880815\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 176, Loss: 0.1697, Loss Cls: 0.1697, Train: 69.46%, Valid: 65.68%, Test: 68.33%\n",
            "num_B_prime:29710, new edges:0\n",
            "Batch 0.0, train acc:0.8867489667613521\n",
            "num_B_prime:29968, new edges:0\n",
            "Batch 1.0, train acc:0.8827575302395446\n",
            "num_B_prime:29769, new edges:0\n",
            "Batch 2.0, train acc:0.893271045551287\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 3.0, train acc:0.8887953236072222\n",
            "num_B_prime:28850, new edges:0\n",
            "Batch 4.0, train acc:0.9040448316040616\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 177, Loss: 0.1672, Loss Cls: 0.1672, Train: 84.81%, Valid: 81.57%, Test: 83.76%\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 0.0, train acc:0.8959576007666282\n",
            "num_B_prime:29816, new edges:0\n",
            "Batch 1.0, train acc:0.905662816407544\n",
            "num_B_prime:29928, new edges:0\n",
            "Batch 2.0, train acc:0.9025076449200358\n",
            "num_B_prime:29715, new edges:0\n",
            "Batch 3.0, train acc:0.9045578208994363\n",
            "num_B_prime:28725, new edges:0\n",
            "Batch 4.0, train acc:0.9060049275247927\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 178, Loss: 0.1529, Loss Cls: 0.1529, Train: 84.11%, Valid: 80.84%, Test: 83.24%\n",
            "num_B_prime:29804, new edges:0\n",
            "Batch 0.0, train acc:0.9044170331612716\n",
            "num_B_prime:29630, new edges:0\n",
            "Batch 1.0, train acc:0.9004820645075322\n",
            "num_B_prime:29786, new edges:0\n",
            "Batch 2.0, train acc:0.9008102092621371\n",
            "num_B_prime:29917, new edges:0\n",
            "Batch 3.0, train acc:0.8976780187909689\n",
            "num_B_prime:28676, new edges:0\n",
            "Batch 4.0, train acc:0.9025761059631827\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 179, Loss: 0.1552, Loss Cls: 0.1552, Train: 84.38%, Valid: 81.05%, Test: 83.41%\n",
            "num_B_prime:29921, new edges:0\n",
            "Batch 0.0, train acc:0.8989965089937084\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 1.0, train acc:0.9004598264087285\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 2.0, train acc:0.8956869245037974\n",
            "num_B_prime:29691, new edges:0\n",
            "Batch 3.0, train acc:0.8966751114783428\n",
            "num_B_prime:28858, new edges:0\n",
            "Batch 4.0, train acc:0.8975162861930817\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 180, Loss: 0.1586, Loss Cls: 0.1586, Train: 81.35%, Valid: 77.85%, Test: 80.29%\n",
            "num_B_prime:29709, new edges:0\n",
            "Batch 0.0, train acc:0.893190522592851\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 1.0, train acc:0.8914909444850002\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 2.0, train acc:0.8953883491839962\n",
            "num_B_prime:29954, new edges:0\n",
            "Batch 3.0, train acc:0.8947962603148673\n",
            "num_B_prime:28877, new edges:0\n",
            "Batch 4.0, train acc:0.9049683026247844\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 181, Loss: 0.1620, Loss Cls: 0.1620, Train: 86.24%, Valid: 82.98%, Test: 85.33%\n",
            "num_B_prime:29859, new edges:0\n",
            "Batch 0.0, train acc:0.8996962802495074\n",
            "num_B_prime:29801, new edges:0\n",
            "Batch 1.0, train acc:0.9013801372762704\n",
            "num_B_prime:29949, new edges:0\n",
            "Batch 2.0, train acc:0.8985906908798719\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 3.0, train acc:0.8999825163666234\n",
            "num_B_prime:28789, new edges:0\n",
            "Batch 4.0, train acc:0.9017080641194749\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 182, Loss: 0.1556, Loss Cls: 0.1556, Train: 85.12%, Valid: 81.72%, Test: 84.04%\n",
            "num_B_prime:29808, new edges:0\n",
            "Batch 0.0, train acc:0.896588401760162\n",
            "num_B_prime:29719, new edges:0\n",
            "Batch 1.0, train acc:0.8999455587121596\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 2.0, train acc:0.8966972946515974\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 3.0, train acc:0.9008412947383432\n",
            "num_B_prime:29164, new edges:0\n",
            "Batch 4.0, train acc:0.8988285169859399\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 183, Loss: 0.1574, Loss Cls: 0.1574, Train: 81.25%, Valid: 77.78%, Test: 80.20%\n",
            "num_B_prime:29591, new edges:0\n",
            "Batch 0.0, train acc:0.8965346561433308\n",
            "num_B_prime:29873, new edges:0\n",
            "Batch 1.0, train acc:0.8927374254800533\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 2.0, train acc:0.8981911055825456\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 3.0, train acc:0.8920366613143472\n",
            "num_B_prime:28789, new edges:0\n",
            "Batch 4.0, train acc:0.8994900837445707\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 184, Loss: 0.1617, Loss Cls: 0.1617, Train: 83.29%, Valid: 80.08%, Test: 82.17%\n",
            "num_B_prime:30050, new edges:0\n",
            "Batch 0.0, train acc:0.8885071501108932\n",
            "num_B_prime:29779, new edges:0\n",
            "Batch 1.0, train acc:0.8981547349587186\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 2.0, train acc:0.8895121610898683\n",
            "num_B_prime:29627, new edges:0\n",
            "Batch 3.0, train acc:0.8972198048216623\n",
            "num_B_prime:28723, new edges:0\n",
            "Batch 4.0, train acc:0.8964045881007838\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 185, Loss: 0.1628, Loss Cls: 0.1628, Train: 72.00%, Valid: 68.40%, Test: 70.83%\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 0.0, train acc:0.8976087120031805\n",
            "num_B_prime:29677, new edges:0\n",
            "Batch 1.0, train acc:0.8921347531083729\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 2.0, train acc:0.9024111024111025\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 3.0, train acc:0.8987445620477674\n",
            "num_B_prime:28629, new edges:0\n",
            "Batch 4.0, train acc:0.9070785912666515\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 186, Loss: 0.1569, Loss Cls: 0.1569, Train: 84.99%, Valid: 81.84%, Test: 83.99%\n",
            "num_B_prime:29724, new edges:0\n",
            "Batch 0.0, train acc:0.9010268163405596\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 1.0, train acc:0.9065297635576748\n",
            "num_B_prime:29667, new edges:0\n",
            "Batch 2.0, train acc:0.90101022989526\n",
            "num_B_prime:29921, new edges:0\n",
            "Batch 3.0, train acc:0.9072732628225759\n",
            "num_B_prime:28792, new edges:0\n",
            "Batch 4.0, train acc:0.9022839914207381\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 187, Loss: 0.1522, Loss Cls: 0.1522, Train: 79.57%, Valid: 75.94%, Test: 78.44%\n",
            "num_B_prime:29772, new edges:0\n",
            "Batch 0.0, train acc:0.9012421332913957\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 1.0, train acc:0.8963875080373626\n",
            "num_B_prime:29899, new edges:0\n",
            "Batch 2.0, train acc:0.8967090346583765\n",
            "num_B_prime:29838, new edges:0\n",
            "Batch 3.0, train acc:0.8950488030073205\n",
            "num_B_prime:28705, new edges:0\n",
            "Batch 4.0, train acc:0.9011852218089702\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 188, Loss: 0.1586, Loss Cls: 0.1586, Train: 84.05%, Valid: 80.78%, Test: 82.99%\n",
            "num_B_prime:29680, new edges:0\n",
            "Batch 0.0, train acc:0.8973958462466631\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 1.0, train acc:0.8989849371106827\n",
            "num_B_prime:29779, new edges:0\n",
            "Batch 2.0, train acc:0.8996116173509436\n",
            "num_B_prime:29779, new edges:0\n",
            "Batch 3.0, train acc:0.9023356474477962\n",
            "num_B_prime:28744, new edges:0\n",
            "Batch 4.0, train acc:0.903993164726152\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 189, Loss: 0.1549, Loss Cls: 0.1549, Train: 83.43%, Valid: 80.01%, Test: 82.51%\n",
            "num_B_prime:29846, new edges:0\n",
            "Batch 0.0, train acc:0.9010539960125008\n",
            "num_B_prime:29815, new edges:0\n",
            "Batch 1.0, train acc:0.8990262974193708\n",
            "num_B_prime:29707, new edges:0\n",
            "Batch 2.0, train acc:0.9005887874392013\n",
            "num_B_prime:29659, new edges:0\n",
            "Batch 3.0, train acc:0.8967155509091691\n",
            "num_B_prime:28852, new edges:0\n",
            "Batch 4.0, train acc:0.9012115896925527\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 190, Loss: 0.1561, Loss Cls: 0.1561, Train: 85.77%, Valid: 82.43%, Test: 84.65%\n",
            "num_B_prime:29672, new edges:0\n",
            "Batch 0.0, train acc:0.8985311152561609\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 1.0, train acc:0.8985937092098447\n",
            "num_B_prime:29959, new edges:0\n",
            "Batch 2.0, train acc:0.8977748506374371\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 3.0, train acc:0.9025907085773732\n",
            "num_B_prime:28998, new edges:0\n",
            "Batch 4.0, train acc:0.9024521850475704\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 191, Loss: 0.1550, Loss Cls: 0.1550, Train: 84.53%, Valid: 81.09%, Test: 83.69%\n",
            "num_B_prime:29885, new edges:0\n",
            "Batch 0.0, train acc:0.8976424761465276\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 1.0, train acc:0.8955123475843969\n",
            "num_B_prime:29659, new edges:0\n",
            "Batch 2.0, train acc:0.8994511996222134\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 3.0, train acc:0.8982567327160382\n",
            "num_B_prime:28746, new edges:0\n",
            "Batch 4.0, train acc:0.904014626763442\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 192, Loss: 0.1571, Loss Cls: 0.1571, Train: 84.26%, Valid: 80.69%, Test: 83.08%\n",
            "num_B_prime:29869, new edges:0\n",
            "Batch 0.0, train acc:0.896611377101082\n",
            "num_B_prime:29892, new edges:0\n",
            "Batch 1.0, train acc:0.8997543163836454\n",
            "num_B_prime:29680, new edges:0\n",
            "Batch 2.0, train acc:0.9000700063942848\n",
            "num_B_prime:30019, new edges:0\n",
            "Batch 3.0, train acc:0.9004723218318251\n",
            "num_B_prime:28708, new edges:0\n",
            "Batch 4.0, train acc:0.9055445055006799\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 193, Loss: 0.1542, Loss Cls: 0.1542, Train: 83.79%, Valid: 80.45%, Test: 82.94%\n",
            "num_B_prime:29952, new edges:0\n",
            "Batch 0.0, train acc:0.9030742758663536\n",
            "num_B_prime:29667, new edges:0\n",
            "Batch 1.0, train acc:0.8994576542473136\n",
            "num_B_prime:29995, new edges:0\n",
            "Batch 2.0, train acc:0.9044235667324395\n",
            "num_B_prime:29677, new edges:0\n",
            "Batch 3.0, train acc:0.9007130263575032\n",
            "num_B_prime:28797, new edges:0\n",
            "Batch 4.0, train acc:0.9054764624691242\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 194, Loss: 0.1522, Loss Cls: 0.1522, Train: 84.09%, Valid: 80.61%, Test: 82.98%\n",
            "num_B_prime:29665, new edges:0\n",
            "Batch 0.0, train acc:0.8988730850521904\n",
            "num_B_prime:29846, new edges:0\n",
            "Batch 1.0, train acc:0.9009597322128822\n",
            "num_B_prime:29761, new edges:0\n",
            "Batch 2.0, train acc:0.8965662312406228\n",
            "num_B_prime:29699, new edges:0\n",
            "Batch 3.0, train acc:0.8970748359577817\n",
            "num_B_prime:28825, new edges:0\n",
            "Batch 4.0, train acc:0.8959257582616569\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 195, Loss: 0.1568, Loss Cls: 0.1568, Train: 73.39%, Valid: 69.12%, Test: 71.87%\n",
            "num_B_prime:29888, new edges:0\n",
            "Batch 0.0, train acc:0.8944647778768667\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 1.0, train acc:0.8942396404967572\n",
            "num_B_prime:29986, new edges:0\n",
            "Batch 2.0, train acc:0.8939797360819918\n",
            "num_B_prime:29694, new edges:0\n",
            "Batch 3.0, train acc:0.8962468035504642\n",
            "num_B_prime:28625, new edges:0\n",
            "Batch 4.0, train acc:0.9043834713697719\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 196, Loss: 0.1593, Loss Cls: 0.1593, Train: 85.98%, Valid: 82.61%, Test: 84.89%\n",
            "num_B_prime:29882, new edges:0\n",
            "Batch 0.0, train acc:0.9035443831807599\n",
            "num_B_prime:29882, new edges:0\n",
            "Batch 1.0, train acc:0.9061065659602354\n",
            "num_B_prime:29699, new edges:0\n",
            "Batch 2.0, train acc:0.9085671933894883\n",
            "num_B_prime:29555, new edges:0\n",
            "Batch 3.0, train acc:0.9062735758956606\n",
            "num_B_prime:29116, new edges:0\n",
            "Batch 4.0, train acc:0.9077770399593766\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 197, Loss: 0.1477, Loss Cls: 0.1477, Train: 85.23%, Valid: 81.77%, Test: 84.12%\n",
            "num_B_prime:29926, new edges:0\n",
            "Batch 0.0, train acc:0.9044406824515764\n",
            "num_B_prime:29853, new edges:0\n",
            "Batch 1.0, train acc:0.9008557288322918\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 2.0, train acc:0.8963546453229867\n",
            "num_B_prime:29611, new edges:0\n",
            "Batch 3.0, train acc:0.8961351281738446\n",
            "num_B_prime:28813, new edges:0\n",
            "Batch 4.0, train acc:0.8901669833245931\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 198, Loss: 0.1602, Loss Cls: 0.1602, Train: 80.97%, Valid: 77.51%, Test: 80.00%\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 0.0, train acc:0.8893487088041938\n",
            "num_B_prime:29696, new edges:0\n",
            "Batch 1.0, train acc:0.8842292433760809\n",
            "num_B_prime:29827, new edges:0\n",
            "Batch 2.0, train acc:0.8996067828283981\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 3.0, train acc:0.8949470452586056\n",
            "num_B_prime:29044, new edges:0\n",
            "Batch 4.0, train acc:0.907054629262847\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 199, Loss: 0.1640, Loss Cls: 0.1640, Train: 85.66%, Valid: 82.38%, Test: 84.55%\n",
            "num_B_prime:29661, new edges:0\n",
            "Batch 0.0, train acc:0.9015526960954056\n",
            "num_B_prime:29892, new edges:0\n",
            "Batch 1.0, train acc:0.9057493287277535\n",
            "num_B_prime:29815, new edges:0\n",
            "Batch 2.0, train acc:0.9033574068460732\n",
            "num_B_prime:29875, new edges:0\n",
            "Batch 3.0, train acc:0.9049761206569572\n",
            "num_B_prime:28808, new edges:0\n",
            "Batch 4.0, train acc:0.9022472417138603\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 200, Loss: 0.1506, Loss Cls: 0.1506, Train: 77.57%, Valid: 74.01%, Test: 76.44%\n",
            "num_B_prime:30019, new edges:0\n",
            "Batch 0.0, train acc:0.9022833302284937\n",
            "num_B_prime:29850, new edges:0\n",
            "Batch 1.0, train acc:0.8960957134854142\n",
            "num_B_prime:29718, new edges:0\n",
            "Batch 2.0, train acc:0.9014179452991221\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 3.0, train acc:0.9008603156243169\n",
            "num_B_prime:28923, new edges:0\n",
            "Batch 4.0, train acc:0.9103449033572937\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 201, Loss: 0.1535, Loss Cls: 0.1535, Train: 83.31%, Valid: 79.95%, Test: 82.02%\n",
            "num_B_prime:29677, new edges:0\n",
            "Batch 0.0, train acc:0.9014131088812275\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 1.0, train acc:0.9063785784260368\n",
            "num_B_prime:29947, new edges:0\n",
            "Batch 2.0, train acc:0.9031850569556327\n",
            "num_B_prime:29889, new edges:0\n",
            "Batch 3.0, train acc:0.9069434386010595\n",
            "num_B_prime:28837, new edges:0\n",
            "Batch 4.0, train acc:0.9040619709871327\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 202, Loss: 0.1495, Loss Cls: 0.1495, Train: 83.70%, Valid: 80.25%, Test: 82.88%\n",
            "num_B_prime:29588, new edges:0\n",
            "Batch 0.0, train acc:0.9054572987877193\n",
            "num_B_prime:29748, new edges:0\n",
            "Batch 1.0, train acc:0.9018609528557682\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 2.0, train acc:0.9068758912014567\n",
            "num_B_prime:30028, new edges:0\n",
            "Batch 3.0, train acc:0.9030112803913961\n",
            "num_B_prime:29054, new edges:0\n",
            "Batch 4.0, train acc:0.9054121047634253\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 203, Loss: 0.1498, Loss Cls: 0.1498, Train: 84.83%, Valid: 81.49%, Test: 83.82%\n",
            "num_B_prime:29966, new edges:0\n",
            "Batch 0.0, train acc:0.9019621329254269\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 1.0, train acc:0.9044502297340308\n",
            "num_B_prime:29736, new edges:0\n",
            "Batch 2.0, train acc:0.9038840866790377\n",
            "num_B_prime:29706, new edges:0\n",
            "Batch 3.0, train acc:0.9071720974605392\n",
            "num_B_prime:28752, new edges:0\n",
            "Batch 4.0, train acc:0.90677763890467\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 204, Loss: 0.1492, Loss Cls: 0.1492, Train: 85.97%, Valid: 82.68%, Test: 85.01%\n",
            "num_B_prime:29874, new edges:0\n",
            "Batch 0.0, train acc:0.9085952190187234\n",
            "num_B_prime:29723, new edges:0\n",
            "Batch 1.0, train acc:0.9046269778541244\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 2.0, train acc:0.9091967959672723\n",
            "num_B_prime:29719, new edges:0\n",
            "Batch 3.0, train acc:0.9056569072572455\n",
            "num_B_prime:28769, new edges:0\n",
            "Batch 4.0, train acc:0.9107412000912108\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 205, Loss: 0.1463, Loss Cls: 0.1463, Train: 84.33%, Valid: 80.93%, Test: 83.17%\n",
            "num_B_prime:29726, new edges:0\n",
            "Batch 0.0, train acc:0.9063239890791431\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 1.0, train acc:0.9077916746267565\n",
            "num_B_prime:29777, new edges:0\n",
            "Batch 2.0, train acc:0.9066510330439186\n",
            "num_B_prime:29975, new edges:0\n",
            "Batch 3.0, train acc:0.9060145381128942\n",
            "num_B_prime:28609, new edges:0\n",
            "Batch 4.0, train acc:0.9074511173577742\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 206, Loss: 0.1462, Loss Cls: 0.1462, Train: 84.63%, Valid: 81.38%, Test: 83.61%\n",
            "num_B_prime:29848, new edges:0\n",
            "Batch 0.0, train acc:0.9074579800027059\n",
            "num_B_prime:29791, new edges:0\n",
            "Batch 1.0, train acc:0.90839571827913\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 2.0, train acc:0.9087667470287419\n",
            "num_B_prime:29694, new edges:0\n",
            "Batch 3.0, train acc:0.9070193503157502\n",
            "num_B_prime:28793, new edges:0\n",
            "Batch 4.0, train acc:0.9111034943895354\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 207, Loss: 0.1452, Loss Cls: 0.1452, Train: 82.69%, Valid: 79.41%, Test: 81.57%\n",
            "num_B_prime:29720, new edges:0\n",
            "Batch 0.0, train acc:0.9052923310864669\n",
            "num_B_prime:29939, new edges:0\n",
            "Batch 1.0, train acc:0.9060857869430029\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 2.0, train acc:0.9013697683896414\n",
            "num_B_prime:29858, new edges:0\n",
            "Batch 3.0, train acc:0.9049650485727544\n",
            "num_B_prime:28767, new edges:0\n",
            "Batch 4.0, train acc:0.9002053039205969\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 208, Loss: 0.1506, Loss Cls: 0.1506, Train: 78.08%, Valid: 74.68%, Test: 77.18%\n",
            "num_B_prime:29664, new edges:0\n",
            "Batch 0.0, train acc:0.9016297674619874\n",
            "num_B_prime:29912, new edges:0\n",
            "Batch 1.0, train acc:0.8942872597674745\n",
            "num_B_prime:29944, new edges:0\n",
            "Batch 2.0, train acc:0.8986254203382013\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 3.0, train acc:0.894038626259048\n",
            "num_B_prime:29024, new edges:0\n",
            "Batch 4.0, train acc:0.9019117622547794\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 209, Loss: 0.1584, Loss Cls: 0.1584, Train: 80.69%, Valid: 77.34%, Test: 79.48%\n",
            "num_B_prime:29937, new edges:0\n",
            "Batch 0.0, train acc:0.8960321570706953\n",
            "num_B_prime:29750, new edges:0\n",
            "Batch 1.0, train acc:0.9002245165563992\n",
            "num_B_prime:29763, new edges:0\n",
            "Batch 2.0, train acc:0.8990267690078377\n",
            "num_B_prime:29766, new edges:0\n",
            "Batch 3.0, train acc:0.9042696909915182\n",
            "num_B_prime:28818, new edges:0\n",
            "Batch 4.0, train acc:0.9046483807326745\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 210, Loss: 0.1524, Loss Cls: 0.1524, Train: 82.79%, Valid: 79.12%, Test: 81.66%\n",
            "num_B_prime:29693, new edges:0\n",
            "Batch 0.0, train acc:0.908689598967707\n",
            "num_B_prime:30012, new edges:0\n",
            "Batch 1.0, train acc:0.9057027017818814\n",
            "num_B_prime:29665, new edges:0\n",
            "Batch 2.0, train acc:0.9038427903094974\n",
            "num_B_prime:29855, new edges:0\n",
            "Batch 3.0, train acc:0.9039750783606527\n",
            "num_B_prime:28778, new edges:0\n",
            "Batch 4.0, train acc:0.9069541358514743\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 211, Loss: 0.1488, Loss Cls: 0.1488, Train: 82.56%, Valid: 78.91%, Test: 81.31%\n",
            "num_B_prime:29875, new edges:0\n",
            "Batch 0.0, train acc:0.905029155615619\n",
            "num_B_prime:30009, new edges:0\n",
            "Batch 1.0, train acc:0.9043777350574808\n",
            "num_B_prime:29769, new edges:0\n",
            "Batch 2.0, train acc:0.9074237482171773\n",
            "num_B_prime:29768, new edges:0\n",
            "Batch 3.0, train acc:0.9018166083967\n",
            "num_B_prime:28500, new edges:0\n",
            "Batch 4.0, train acc:0.9092403274054107\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 212, Loss: 0.1487, Loss Cls: 0.1487, Train: 84.91%, Valid: 81.57%, Test: 84.00%\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 0.0, train acc:0.902640394608425\n",
            "num_B_prime:29963, new edges:0\n",
            "Batch 1.0, train acc:0.9084509409279806\n",
            "num_B_prime:29587, new edges:0\n",
            "Batch 2.0, train acc:0.9015928291347742\n",
            "num_B_prime:29780, new edges:0\n",
            "Batch 3.0, train acc:0.9090044815030273\n",
            "num_B_prime:28976, new edges:0\n",
            "Batch 4.0, train acc:0.9012378088101854\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 213, Loss: 0.1486, Loss Cls: 0.1486, Train: 81.27%, Valid: 77.81%, Test: 80.28%\n",
            "num_B_prime:29714, new edges:0\n",
            "Batch 0.0, train acc:0.9076722947076188\n",
            "num_B_prime:29906, new edges:0\n",
            "Batch 1.0, train acc:0.9000983446483305\n",
            "num_B_prime:29684, new edges:0\n",
            "Batch 2.0, train acc:0.9073046005258818\n",
            "num_B_prime:29760, new edges:0\n",
            "Batch 3.0, train acc:0.9003732279295896\n",
            "num_B_prime:29004, new edges:0\n",
            "Batch 4.0, train acc:0.906992539744772\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 214, Loss: 0.1497, Loss Cls: 0.1497, Train: 81.98%, Valid: 78.55%, Test: 80.76%\n",
            "num_B_prime:29627, new edges:0\n",
            "Batch 0.0, train acc:0.8971153427592897\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 1.0, train acc:0.8998569481643486\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 2.0, train acc:0.8935333210340805\n",
            "num_B_prime:29983, new edges:0\n",
            "Batch 3.0, train acc:0.8969571165984368\n",
            "num_B_prime:28668, new edges:0\n",
            "Batch 4.0, train acc:0.8903300268089003\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 215, Loss: 0.1592, Loss Cls: 0.1592, Train: 72.28%, Valid: 68.37%, Test: 71.03%\n",
            "num_B_prime:29824, new edges:0\n",
            "Batch 0.0, train acc:0.8901621868064821\n",
            "num_B_prime:29864, new edges:0\n",
            "Batch 1.0, train acc:0.8871027252863615\n",
            "num_B_prime:29765, new edges:0\n",
            "Batch 2.0, train acc:0.893452895122921\n",
            "num_B_prime:29798, new edges:0\n",
            "Batch 3.0, train acc:0.8991812716583816\n",
            "num_B_prime:28634, new edges:0\n",
            "Batch 4.0, train acc:0.9086824728144058\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 216, Loss: 0.1618, Loss Cls: 0.1618, Train: 85.23%, Valid: 81.89%, Test: 84.01%\n",
            "num_B_prime:30060, new edges:0\n",
            "Batch 0.0, train acc:0.9091175957440326\n",
            "num_B_prime:29738, new edges:0\n",
            "Batch 1.0, train acc:0.9135595981536792\n",
            "num_B_prime:29906, new edges:0\n",
            "Batch 2.0, train acc:0.9147355981382682\n",
            "num_B_prime:29683, new edges:0\n",
            "Batch 3.0, train acc:0.9171842904425564\n",
            "num_B_prime:28786, new edges:0\n",
            "Batch 4.0, train acc:0.9216476539108953\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 217, Loss: 0.1374, Loss Cls: 0.1374, Train: 87.50%, Valid: 84.34%, Test: 86.58%\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 0.0, train acc:0.918607606808911\n",
            "num_B_prime:29950, new edges:0\n",
            "Batch 1.0, train acc:0.9171511886955677\n",
            "num_B_prime:29770, new edges:0\n",
            "Batch 2.0, train acc:0.918697784593068\n",
            "num_B_prime:29478, new edges:0\n",
            "Batch 3.0, train acc:0.9158728444994421\n",
            "num_B_prime:28932, new edges:0\n",
            "Batch 4.0, train acc:0.9200791020249005\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 218, Loss: 0.1342, Loss Cls: 0.1342, Train: 87.78%, Valid: 84.62%, Test: 86.82%\n",
            "num_B_prime:29731, new edges:0\n",
            "Batch 0.0, train acc:0.9133345355176097\n",
            "num_B_prime:29821, new edges:0\n",
            "Batch 1.0, train acc:0.9126185451954828\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 2.0, train acc:0.9091004922596366\n",
            "num_B_prime:29654, new edges:0\n",
            "Batch 3.0, train acc:0.9101411791794846\n",
            "num_B_prime:29087, new edges:0\n",
            "Batch 4.0, train acc:0.9014617418018147\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 219, Loss: 0.1426, Loss Cls: 0.1426, Train: 81.75%, Valid: 78.20%, Test: 80.84%\n",
            "num_B_prime:29769, new edges:0\n",
            "Batch 0.0, train acc:0.9032437633698875\n",
            "num_B_prime:29845, new edges:0\n",
            "Batch 1.0, train acc:0.8920587591060364\n",
            "num_B_prime:29869, new edges:0\n",
            "Batch 2.0, train acc:0.900422277489443\n",
            "num_B_prime:29971, new edges:0\n",
            "Batch 3.0, train acc:0.8924634796034363\n",
            "num_B_prime:28659, new edges:0\n",
            "Batch 4.0, train acc:0.9091880832134402\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 220, Loss: 0.1543, Loss Cls: 0.1543, Train: 86.01%, Valid: 82.66%, Test: 84.84%\n",
            "num_B_prime:29901, new edges:0\n",
            "Batch 0.0, train acc:0.8985595156355527\n",
            "num_B_prime:29645, new edges:0\n",
            "Batch 1.0, train acc:0.9060579972086904\n",
            "num_B_prime:29701, new edges:0\n",
            "Batch 2.0, train acc:0.9011046736623277\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 3.0, train acc:0.906887482832644\n",
            "num_B_prime:29091, new edges:0\n",
            "Batch 4.0, train acc:0.9099142324213372\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 221, Loss: 0.1489, Loss Cls: 0.1489, Train: 82.38%, Valid: 78.96%, Test: 81.40%\n",
            "num_B_prime:29740, new edges:0\n",
            "Batch 0.0, train acc:0.9114906999536883\n",
            "num_B_prime:29911, new edges:0\n",
            "Batch 1.0, train acc:0.9102422218586702\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 2.0, train acc:0.9117085758702984\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 3.0, train acc:0.9067486093068186\n",
            "num_B_prime:29225, new edges:0\n",
            "Batch 4.0, train acc:0.9160323882170475\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 222, Loss: 0.1415, Loss Cls: 0.1415, Train: 85.97%, Valid: 82.79%, Test: 84.94%\n",
            "num_B_prime:29916, new edges:0\n",
            "Batch 0.0, train acc:0.9119906817523118\n",
            "num_B_prime:29738, new edges:0\n",
            "Batch 1.0, train acc:0.9131041588865295\n",
            "num_B_prime:29804, new edges:0\n",
            "Batch 2.0, train acc:0.9093858371884619\n",
            "num_B_prime:29658, new edges:0\n",
            "Batch 3.0, train acc:0.909296683763671\n",
            "num_B_prime:28796, new edges:0\n",
            "Batch 4.0, train acc:0.9128042310171385\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 223, Loss: 0.1407, Loss Cls: 0.1407, Train: 77.93%, Valid: 74.23%, Test: 76.81%\n",
            "num_B_prime:29658, new edges:0\n",
            "Batch 0.0, train acc:0.9055719398867037\n",
            "num_B_prime:30007, new edges:0\n",
            "Batch 1.0, train acc:0.9037662873991062\n",
            "num_B_prime:29655, new edges:0\n",
            "Batch 2.0, train acc:0.9049674636130518\n",
            "num_B_prime:29864, new edges:0\n",
            "Batch 3.0, train acc:0.9021074977863573\n",
            "num_B_prime:28671, new edges:0\n",
            "Batch 4.0, train acc:0.909826966304546\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 224, Loss: 0.1483, Loss Cls: 0.1483, Train: 81.42%, Valid: 77.93%, Test: 80.13%\n",
            "num_B_prime:29795, new edges:0\n",
            "Batch 0.0, train acc:0.8992076844140705\n",
            "num_B_prime:29702, new edges:0\n",
            "Batch 1.0, train acc:0.9041345436205024\n",
            "num_B_prime:29701, new edges:0\n",
            "Batch 2.0, train acc:0.902720104766322\n",
            "num_B_prime:29801, new edges:0\n",
            "Batch 3.0, train acc:0.9016302404455665\n",
            "num_B_prime:29040, new edges:0\n",
            "Batch 4.0, train acc:0.9050176100699363\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 225, Loss: 0.1509, Loss Cls: 0.1509, Train: 82.84%, Valid: 79.56%, Test: 81.82%\n",
            "num_B_prime:29836, new edges:0\n",
            "Batch 0.0, train acc:0.9063074719155909\n",
            "num_B_prime:29763, new edges:0\n",
            "Batch 1.0, train acc:0.9064083477787975\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 2.0, train acc:0.9085702969437527\n",
            "num_B_prime:29850, new edges:0\n",
            "Batch 3.0, train acc:0.9059928479230308\n",
            "num_B_prime:28576, new edges:0\n",
            "Batch 4.0, train acc:0.9107866285223377\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 226, Loss: 0.1453, Loss Cls: 0.1453, Train: 86.98%, Valid: 83.87%, Test: 86.06%\n",
            "num_B_prime:29716, new edges:0\n",
            "Batch 0.0, train acc:0.9079145259737408\n",
            "num_B_prime:29907, new edges:0\n",
            "Batch 1.0, train acc:0.9089548557088738\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 2.0, train acc:0.9119871344396995\n",
            "num_B_prime:29601, new edges:0\n",
            "Batch 3.0, train acc:0.9079171533259885\n",
            "num_B_prime:29201, new edges:0\n",
            "Batch 4.0, train acc:0.9119380330091704\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 227, Loss: 0.1430, Loss Cls: 0.1430, Train: 84.18%, Valid: 80.95%, Test: 83.20%\n",
            "num_B_prime:29746, new edges:0\n",
            "Batch 0.0, train acc:0.907995294843076\n",
            "num_B_prime:29854, new edges:0\n",
            "Batch 1.0, train acc:0.9123769090158618\n",
            "num_B_prime:29730, new edges:0\n",
            "Batch 2.0, train acc:0.9071311773508012\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 3.0, train acc:0.9085090920990021\n",
            "num_B_prime:28993, new edges:0\n",
            "Batch 4.0, train acc:0.9076323974550337\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 228, Loss: 0.1444, Loss Cls: 0.1444, Train: 84.30%, Valid: 81.13%, Test: 83.21%\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 0.0, train acc:0.9037358015557821\n",
            "num_B_prime:29937, new edges:0\n",
            "Batch 1.0, train acc:0.9028914162230509\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 2.0, train acc:0.9026621279092829\n",
            "num_B_prime:29711, new edges:0\n",
            "Batch 3.0, train acc:0.9011963210061396\n",
            "num_B_prime:28680, new edges:0\n",
            "Batch 4.0, train acc:0.907232801068628\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 229, Loss: 0.1520, Loss Cls: 0.1520, Train: 84.62%, Valid: 81.40%, Test: 83.81%\n",
            "num_B_prime:29708, new edges:0\n",
            "Batch 0.0, train acc:0.907198128731318\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 1.0, train acc:0.9094269162112734\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 2.0, train acc:0.9153722607867156\n",
            "num_B_prime:29842, new edges:0\n",
            "Batch 3.0, train acc:0.9131096639463634\n",
            "num_B_prime:28890, new edges:0\n",
            "Batch 4.0, train acc:0.9185396871557119\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 230, Loss: 0.1399, Loss Cls: 0.1399, Train: 87.50%, Valid: 84.20%, Test: 86.48%\n",
            "num_B_prime:29748, new edges:0\n",
            "Batch 0.0, train acc:0.9139446644694934\n",
            "num_B_prime:29906, new edges:0\n",
            "Batch 1.0, train acc:0.9195947798394731\n",
            "num_B_prime:29533, new edges:0\n",
            "Batch 2.0, train acc:0.9133355932580148\n",
            "num_B_prime:29923, new edges:0\n",
            "Batch 3.0, train acc:0.917520772245137\n",
            "num_B_prime:28688, new edges:0\n",
            "Batch 4.0, train acc:0.9149602586555301\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 231, Loss: 0.1347, Loss Cls: 0.1347, Train: 85.50%, Valid: 82.23%, Test: 84.58%\n",
            "num_B_prime:29957, new edges:0\n",
            "Batch 0.0, train acc:0.9132717074061779\n",
            "num_B_prime:29722, new edges:0\n",
            "Batch 1.0, train acc:0.908525363974395\n",
            "num_B_prime:29603, new edges:0\n",
            "Batch 2.0, train acc:0.9116873704029668\n",
            "num_B_prime:29883, new edges:0\n",
            "Batch 3.0, train acc:0.9065107054478635\n",
            "num_B_prime:28963, new edges:0\n",
            "Batch 4.0, train acc:0.9143608014196887\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 232, Loss: 0.1413, Loss Cls: 0.1413, Train: 80.86%, Valid: 77.37%, Test: 79.62%\n",
            "num_B_prime:29828, new edges:0\n",
            "Batch 0.0, train acc:0.9036360969588958\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 1.0, train acc:0.9047254799674571\n",
            "num_B_prime:29855, new edges:0\n",
            "Batch 2.0, train acc:0.9031985407991189\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 3.0, train acc:0.9086598774247535\n",
            "num_B_prime:29016, new edges:0\n",
            "Batch 4.0, train acc:0.9070034637154686\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 233, Loss: 0.1471, Loss Cls: 0.1471, Train: 82.20%, Valid: 78.78%, Test: 81.31%\n",
            "num_B_prime:30060, new edges:0\n",
            "Batch 0.0, train acc:0.9068329863086254\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 1.0, train acc:0.9018088105641513\n",
            "num_B_prime:29785, new edges:0\n",
            "Batch 2.0, train acc:0.9045862482456754\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 3.0, train acc:0.8982468531925514\n",
            "num_B_prime:28471, new edges:0\n",
            "Batch 4.0, train acc:0.9029486684888929\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 234, Loss: 0.1502, Loss Cls: 0.1502, Train: 82.73%, Valid: 79.30%, Test: 81.52%\n",
            "num_B_prime:29651, new edges:0\n",
            "Batch 0.0, train acc:0.8948648125660794\n",
            "num_B_prime:30079, new edges:0\n",
            "Batch 1.0, train acc:0.9007340651700116\n",
            "num_B_prime:29658, new edges:0\n",
            "Batch 2.0, train acc:0.9057281141768485\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 3.0, train acc:0.9111032615094784\n",
            "num_B_prime:28725, new edges:0\n",
            "Batch 4.0, train acc:0.9117703533026114\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 235, Loss: 0.1484, Loss Cls: 0.1484, Train: 78.71%, Valid: 74.61%, Test: 77.56%\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 0.0, train acc:0.9144348866217121\n",
            "num_B_prime:29765, new edges:0\n",
            "Batch 1.0, train acc:0.9139168197991727\n",
            "num_B_prime:29740, new edges:0\n",
            "Batch 2.0, train acc:0.9181529852013338\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 3.0, train acc:0.9121012741636687\n",
            "num_B_prime:29193, new edges:0\n",
            "Batch 4.0, train acc:0.9186347827752558\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 236, Loss: 0.1362, Loss Cls: 0.1362, Train: 85.65%, Valid: 82.38%, Test: 84.61%\n",
            "num_B_prime:29851, new edges:0\n",
            "Batch 0.0, train acc:0.9094791250720973\n",
            "num_B_prime:29825, new edges:0\n",
            "Batch 1.0, train acc:0.9123154859157111\n",
            "num_B_prime:29666, new edges:0\n",
            "Batch 2.0, train acc:0.9056909486394105\n",
            "num_B_prime:29847, new edges:0\n",
            "Batch 3.0, train acc:0.911075875265105\n",
            "num_B_prime:28818, new edges:0\n",
            "Batch 4.0, train acc:0.9057081439836698\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 237, Loss: 0.1427, Loss Cls: 0.1427, Train: 78.02%, Valid: 74.33%, Test: 76.99%\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 0.0, train acc:0.9089097889914177\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 1.0, train acc:0.9032109457778597\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 2.0, train acc:0.9119996990570004\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 3.0, train acc:0.9059719929539236\n",
            "num_B_prime:29011, new edges:0\n",
            "Batch 4.0, train acc:0.9155246794366135\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 238, Loss: 0.1438, Loss Cls: 0.1438, Train: 85.01%, Valid: 81.79%, Test: 83.84%\n",
            "num_B_prime:30064, new edges:0\n",
            "Batch 0.0, train acc:0.906382236785662\n",
            "num_B_prime:29686, new edges:0\n",
            "Batch 1.0, train acc:0.9113439841435791\n",
            "num_B_prime:29741, new edges:0\n",
            "Batch 2.0, train acc:0.9098767078282074\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 3.0, train acc:0.9136286434142847\n",
            "num_B_prime:28799, new edges:0\n",
            "Batch 4.0, train acc:0.9150055441647312\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 239, Loss: 0.1411, Loss Cls: 0.1411, Train: 86.04%, Valid: 82.74%, Test: 85.11%\n",
            "num_B_prime:29808, new edges:0\n",
            "Batch 0.0, train acc:0.9170845820868493\n",
            "num_B_prime:29948, new edges:0\n",
            "Batch 1.0, train acc:0.9154868364228519\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 2.0, train acc:0.9164948199511983\n",
            "num_B_prime:29661, new edges:0\n",
            "Batch 3.0, train acc:0.9129930062107904\n",
            "num_B_prime:28981, new edges:0\n",
            "Batch 4.0, train acc:0.9131787922347983\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 240, Loss: 0.1369, Loss Cls: 0.1369, Train: 84.82%, Valid: 81.36%, Test: 83.74%\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 0.0, train acc:0.9122424160070659\n",
            "num_B_prime:29882, new edges:0\n",
            "Batch 1.0, train acc:0.9110750951306424\n",
            "num_B_prime:29776, new edges:0\n",
            "Batch 2.0, train acc:0.9096897711041134\n",
            "num_B_prime:29816, new edges:0\n",
            "Batch 3.0, train acc:0.9097276672814216\n",
            "num_B_prime:28868, new edges:0\n",
            "Batch 4.0, train acc:0.9097525147871158\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 241, Loss: 0.1424, Loss Cls: 0.1424, Train: 80.76%, Valid: 77.36%, Test: 79.75%\n",
            "num_B_prime:29962, new edges:0\n",
            "Batch 0.0, train acc:0.9054558593279538\n",
            "num_B_prime:29712, new edges:0\n",
            "Batch 1.0, train acc:0.9055056220957934\n",
            "num_B_prime:29872, new edges:0\n",
            "Batch 2.0, train acc:0.9000107435352842\n",
            "num_B_prime:29664, new edges:0\n",
            "Batch 3.0, train acc:0.9032560185034367\n",
            "num_B_prime:29115, new edges:0\n",
            "Batch 4.0, train acc:0.9031682535051645\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 242, Loss: 0.1501, Loss Cls: 0.1501, Train: 82.04%, Valid: 78.69%, Test: 80.96%\n",
            "num_B_prime:29672, new edges:0\n",
            "Batch 0.0, train acc:0.9073536838259786\n",
            "num_B_prime:30045, new edges:0\n",
            "Batch 1.0, train acc:0.9051556480568975\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 2.0, train acc:0.9127763812823741\n",
            "num_B_prime:29712, new edges:0\n",
            "Batch 3.0, train acc:0.9115689709032488\n",
            "num_B_prime:28862, new edges:0\n",
            "Batch 4.0, train acc:0.9208309130639226\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 243, Loss: 0.1403, Loss Cls: 0.1403, Train: 87.02%, Valid: 83.81%, Test: 85.97%\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 0.0, train acc:0.9140863533899776\n",
            "num_B_prime:29872, new edges:0\n",
            "Batch 1.0, train acc:0.9198768657174043\n",
            "num_B_prime:29886, new edges:0\n",
            "Batch 2.0, train acc:0.9146290268190795\n",
            "num_B_prime:29658, new edges:0\n",
            "Batch 3.0, train acc:0.9153102165860567\n",
            "num_B_prime:28820, new edges:0\n",
            "Batch 4.0, train acc:0.9094235131889151\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 244, Loss: 0.1364, Loss Cls: 0.1364, Train: 81.78%, Valid: 78.32%, Test: 80.65%\n",
            "num_B_prime:29825, new edges:0\n",
            "Batch 0.0, train acc:0.9050505433340733\n",
            "num_B_prime:29828, new edges:0\n",
            "Batch 1.0, train acc:0.9003998988290143\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 2.0, train acc:0.9034400702968514\n",
            "num_B_prime:29843, new edges:0\n",
            "Batch 3.0, train acc:0.9025890625789078\n",
            "num_B_prime:28515, new edges:0\n",
            "Batch 4.0, train acc:0.910756352363846\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 245, Loss: 0.1498, Loss Cls: 0.1498, Train: 85.96%, Valid: 82.85%, Test: 84.86%\n",
            "num_B_prime:30025, new edges:0\n",
            "Batch 0.0, train acc:0.909251415356305\n",
            "num_B_prime:29682, new edges:0\n",
            "Batch 1.0, train acc:0.9126609992575269\n",
            "num_B_prime:29695, new edges:0\n",
            "Batch 2.0, train acc:0.9140342097144619\n",
            "num_B_prime:29897, new edges:0\n",
            "Batch 3.0, train acc:0.9150368725423423\n",
            "num_B_prime:28496, new edges:0\n",
            "Batch 4.0, train acc:0.9215893118085033\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 246, Loss: 0.1363, Loss Cls: 0.1363, Train: 84.56%, Valid: 81.32%, Test: 83.72%\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 0.0, train acc:0.9196412526750855\n",
            "num_B_prime:29870, new edges:0\n",
            "Batch 1.0, train acc:0.9184737635292506\n",
            "num_B_prime:29824, new edges:0\n",
            "Batch 2.0, train acc:0.9194892594756024\n",
            "num_B_prime:29803, new edges:0\n",
            "Batch 3.0, train acc:0.9197774725274726\n",
            "num_B_prime:28549, new edges:0\n",
            "Batch 4.0, train acc:0.9210532841426017\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 247, Loss: 0.1314, Loss Cls: 0.1314, Train: 85.85%, Valid: 82.44%, Test: 84.54%\n",
            "num_B_prime:29688, new edges:0\n",
            "Batch 0.0, train acc:0.9159661456947135\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 1.0, train acc:0.918356870226409\n",
            "num_B_prime:29943, new edges:0\n",
            "Batch 2.0, train acc:0.9128160382486964\n",
            "num_B_prime:29756, new edges:0\n",
            "Batch 3.0, train acc:0.9134977265488945\n",
            "num_B_prime:28761, new edges:0\n",
            "Batch 4.0, train acc:0.9132792389479575\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 248, Loss: 0.1369, Loss Cls: 0.1369, Train: 80.28%, Valid: 76.99%, Test: 79.38%\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 0.0, train acc:0.9116782032619353\n",
            "num_B_prime:29785, new edges:0\n",
            "Batch 1.0, train acc:0.9060423520108921\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 2.0, train acc:0.9125153927420279\n",
            "num_B_prime:29766, new edges:0\n",
            "Batch 3.0, train acc:0.908483318851973\n",
            "num_B_prime:28731, new edges:0\n",
            "Batch 4.0, train acc:0.914253066490983\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 249, Loss: 0.1416, Loss Cls: 0.1416, Train: 83.46%, Valid: 80.07%, Test: 82.25%\n",
            "num_B_prime:29866, new edges:0\n",
            "Batch 0.0, train acc:0.9027256041180773\n",
            "num_B_prime:29849, new edges:0\n",
            "Batch 1.0, train acc:0.9067274733436458\n",
            "num_B_prime:29628, new edges:0\n",
            "Batch 2.0, train acc:0.8990694204216061\n",
            "num_B_prime:29980, new edges:0\n",
            "Batch 3.0, train acc:0.9079655019135198\n",
            "num_B_prime:28727, new edges:0\n",
            "Batch 4.0, train acc:0.9085603112840467\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 250, Loss: 0.1454, Loss Cls: 0.1454, Train: 84.03%, Valid: 80.74%, Test: 83.20%\n",
            "num_B_prime:29680, new edges:0\n",
            "Batch 0.0, train acc:0.9143913219892994\n",
            "num_B_prime:29741, new edges:0\n",
            "Batch 1.0, train acc:0.9132979485246983\n",
            "num_B_prime:29861, new edges:0\n",
            "Batch 2.0, train acc:0.9185575649447193\n",
            "num_B_prime:29765, new edges:0\n",
            "Batch 3.0, train acc:0.9169492466076534\n",
            "num_B_prime:29086, new edges:0\n",
            "Batch 4.0, train acc:0.922006064287991\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 251, Loss: 0.1336, Loss Cls: 0.1336, Train: 86.41%, Valid: 83.16%, Test: 85.40%\n",
            "num_B_prime:29767, new edges:0\n",
            "Batch 0.0, train acc:0.9178577940339575\n",
            "num_B_prime:29594, new edges:0\n",
            "Batch 1.0, train acc:0.9190794094582153\n",
            "num_B_prime:29847, new edges:0\n",
            "Batch 2.0, train acc:0.9141053207223554\n",
            "num_B_prime:29853, new edges:0\n",
            "Batch 3.0, train acc:0.9143404913152369\n",
            "num_B_prime:29377, new edges:0\n",
            "Batch 4.0, train acc:0.9106151291441308\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 252, Loss: 0.1355, Loss Cls: 0.1355, Train: 74.13%, Valid: 69.97%, Test: 72.66%\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 0.0, train acc:0.9086603181604842\n",
            "num_B_prime:29952, new edges:0\n",
            "Batch 1.0, train acc:0.9002396350577931\n",
            "num_B_prime:29929, new edges:0\n",
            "Batch 2.0, train acc:0.9036937341109617\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 3.0, train acc:0.9021018825122877\n",
            "num_B_prime:28717, new edges:0\n",
            "Batch 4.0, train acc:0.9106331782535031\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 253, Loss: 0.1488, Loss Cls: 0.1488, Train: 84.23%, Valid: 80.87%, Test: 83.07%\n",
            "num_B_prime:29711, new edges:0\n",
            "Batch 0.0, train acc:0.9103617778861605\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 1.0, train acc:0.9151277131550545\n",
            "num_B_prime:29838, new edges:0\n",
            "Batch 2.0, train acc:0.9160884250151591\n",
            "num_B_prime:29889, new edges:0\n",
            "Batch 3.0, train acc:0.9184146139002969\n",
            "num_B_prime:28556, new edges:0\n",
            "Batch 4.0, train acc:0.9184876494738967\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 254, Loss: 0.1348, Loss Cls: 0.1348, Train: 84.99%, Valid: 81.67%, Test: 84.07%\n",
            "num_B_prime:29688, new edges:0\n",
            "Batch 0.0, train acc:0.9179097142841757\n",
            "num_B_prime:29992, new edges:0\n",
            "Batch 1.0, train acc:0.915431074240487\n",
            "num_B_prime:29703, new edges:0\n",
            "Batch 2.0, train acc:0.9177686074062387\n",
            "num_B_prime:29836, new edges:0\n",
            "Batch 3.0, train acc:0.9150180879686897\n",
            "num_B_prime:28699, new edges:0\n",
            "Batch 4.0, train acc:0.914800691703986\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 255, Loss: 0.1344, Loss Cls: 0.1344, Train: 85.97%, Valid: 82.76%, Test: 84.95%\n",
            "num_B_prime:29959, new edges:0\n",
            "Batch 0.0, train acc:0.9111624206695758\n",
            "num_B_prime:29747, new edges:0\n",
            "Batch 1.0, train acc:0.9145929922110272\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 2.0, train acc:0.9082330909308785\n",
            "num_B_prime:29869, new edges:0\n",
            "Batch 3.0, train acc:0.9107637340482632\n",
            "num_B_prime:28942, new edges:0\n",
            "Batch 4.0, train acc:0.9104181203370726\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 256, Loss: 0.1390, Loss Cls: 0.1390, Train: 78.54%, Valid: 74.48%, Test: 77.17%\n",
            "num_B_prime:29704, new edges:0\n",
            "Batch 0.0, train acc:0.9091985122297843\n",
            "num_B_prime:29860, new edges:0\n",
            "Batch 1.0, train acc:0.9027860576221584\n",
            "num_B_prime:29838, new edges:0\n",
            "Batch 2.0, train acc:0.9058144798818674\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 3.0, train acc:0.9018998325850074\n",
            "num_B_prime:29100, new edges:0\n",
            "Batch 4.0, train acc:0.9172560016414746\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 257, Loss: 0.1441, Loss Cls: 0.1441, Train: 83.95%, Valid: 80.43%, Test: 82.71%\n",
            "num_B_prime:29750, new edges:0\n",
            "Batch 0.0, train acc:0.9122769085347515\n",
            "num_B_prime:29893, new edges:0\n",
            "Batch 1.0, train acc:0.9189154786150713\n",
            "num_B_prime:29676, new edges:0\n",
            "Batch 2.0, train acc:0.9178916418759144\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 3.0, train acc:0.9229563508953992\n",
            "num_B_prime:28846, new edges:0\n",
            "Batch 4.0, train acc:0.9220915453480822\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 258, Loss: 0.1310, Loss Cls: 0.1310, Train: 85.97%, Valid: 82.69%, Test: 85.08%\n",
            "num_B_prime:29836, new edges:0\n",
            "Batch 0.0, train acc:0.9242904529780837\n",
            "num_B_prime:29949, new edges:0\n",
            "Batch 1.0, train acc:0.9189727010493165\n",
            "num_B_prime:29630, new edges:0\n",
            "Batch 2.0, train acc:0.9230475262633099\n",
            "num_B_prime:29841, new edges:0\n",
            "Batch 3.0, train acc:0.9168185986895172\n",
            "num_B_prime:28549, new edges:0\n",
            "Batch 4.0, train acc:0.9236521423104245\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 259, Loss: 0.1297, Loss Cls: 0.1297, Train: 87.22%, Valid: 83.99%, Test: 86.18%\n",
            "num_B_prime:29848, new edges:0\n",
            "Batch 0.0, train acc:0.916080878124263\n",
            "num_B_prime:29705, new edges:0\n",
            "Batch 1.0, train acc:0.9205819318590773\n",
            "num_B_prime:29830, new edges:0\n",
            "Batch 2.0, train acc:0.91078371331597\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 3.0, train acc:0.9180216126798698\n",
            "num_B_prime:28910, new edges:0\n",
            "Batch 4.0, train acc:0.9145587503955876\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 260, Loss: 0.1335, Loss Cls: 0.1335, Train: 85.23%, Valid: 82.02%, Test: 84.33%\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 0.0, train acc:0.9176647683751291\n",
            "num_B_prime:29850, new edges:0\n",
            "Batch 1.0, train acc:0.9124522791279857\n",
            "num_B_prime:29696, new edges:0\n",
            "Batch 2.0, train acc:0.9146035980350694\n",
            "num_B_prime:30016, new edges:0\n",
            "Batch 3.0, train acc:0.908025868719986\n",
            "num_B_prime:28868, new edges:0\n",
            "Batch 4.0, train acc:0.9150297671612916\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 261, Loss: 0.1368, Loss Cls: 0.1368, Train: 83.15%, Valid: 79.79%, Test: 82.00%\n",
            "num_B_prime:29780, new edges:0\n",
            "Batch 0.0, train acc:0.9083229827394925\n",
            "num_B_prime:29877, new edges:0\n",
            "Batch 1.0, train acc:0.9125306973053727\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 2.0, train acc:0.9097995362978193\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 3.0, train acc:0.9114952180563555\n",
            "num_B_prime:28947, new edges:0\n",
            "Batch 4.0, train acc:0.91022324582631\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 262, Loss: 0.1408, Loss Cls: 0.1408, Train: 83.08%, Valid: 79.91%, Test: 82.15%\n",
            "num_B_prime:30140, new edges:0\n",
            "Batch 0.0, train acc:0.9077966726177736\n",
            "num_B_prime:29555, new edges:0\n",
            "Batch 1.0, train acc:0.9045513647043829\n",
            "num_B_prime:29795, new edges:0\n",
            "Batch 2.0, train acc:0.904675859796375\n",
            "num_B_prime:29870, new edges:0\n",
            "Batch 3.0, train acc:0.9053297880238566\n",
            "num_B_prime:28576, new edges:0\n",
            "Batch 4.0, train acc:0.9063015646022491\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 263, Loss: 0.1477, Loss Cls: 0.1477, Train: 82.32%, Valid: 78.89%, Test: 81.09%\n",
            "num_B_prime:29733, new edges:0\n",
            "Batch 0.0, train acc:0.9067132810055639\n",
            "num_B_prime:29792, new edges:0\n",
            "Batch 1.0, train acc:0.9077413383173072\n",
            "num_B_prime:29847, new edges:0\n",
            "Batch 2.0, train acc:0.9051480283855576\n",
            "num_B_prime:29938, new edges:0\n",
            "Batch 3.0, train acc:0.908026286763204\n",
            "num_B_prime:28704, new edges:0\n",
            "Batch 4.0, train acc:0.9162049122807017\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 264, Loss: 0.1453, Loss Cls: 0.1453, Train: 86.21%, Valid: 83.03%, Test: 85.26%\n",
            "num_B_prime:29685, new edges:0\n",
            "Batch 0.0, train acc:0.9182437164901089\n",
            "num_B_prime:29670, new edges:0\n",
            "Batch 1.0, train acc:0.919292538020536\n",
            "num_B_prime:29737, new edges:0\n",
            "Batch 2.0, train acc:0.9226870383025807\n",
            "num_B_prime:29918, new edges:0\n",
            "Batch 3.0, train acc:0.9218780691837808\n",
            "num_B_prime:29022, new edges:0\n",
            "Batch 4.0, train acc:0.9272199248016519\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 265, Loss: 0.1283, Loss Cls: 0.1283, Train: 87.59%, Valid: 84.34%, Test: 86.56%\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 0.0, train acc:0.9203856000922016\n",
            "num_B_prime:29821, new edges:0\n",
            "Batch 1.0, train acc:0.9227032402149639\n",
            "num_B_prime:29921, new edges:0\n",
            "Batch 2.0, train acc:0.921429519447983\n",
            "num_B_prime:29852, new edges:0\n",
            "Batch 3.0, train acc:0.9189303246217556\n",
            "num_B_prime:28559, new edges:0\n",
            "Batch 4.0, train acc:0.9230691947466245\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 266, Loss: 0.1278, Loss Cls: 0.1278, Train: 86.39%, Valid: 83.47%, Test: 85.61%\n",
            "num_B_prime:29888, new edges:0\n",
            "Batch 0.0, train acc:0.9158127009231254\n",
            "num_B_prime:29801, new edges:0\n",
            "Batch 1.0, train acc:0.9146403888706126\n",
            "num_B_prime:29675, new edges:0\n",
            "Batch 2.0, train acc:0.9117970927876408\n",
            "num_B_prime:29952, new edges:0\n",
            "Batch 3.0, train acc:0.9112801135098891\n",
            "num_B_prime:28606, new edges:0\n",
            "Batch 4.0, train acc:0.913580797094385\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 267, Loss: 0.1361, Loss Cls: 0.1361, Train: 83.39%, Valid: 80.16%, Test: 82.15%\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 0.0, train acc:0.9098200570550801\n",
            "num_B_prime:29747, new edges:0\n",
            "Batch 1.0, train acc:0.9151100285456832\n",
            "num_B_prime:29891, new edges:0\n",
            "Batch 2.0, train acc:0.9139075395832933\n",
            "num_B_prime:29767, new edges:0\n",
            "Batch 3.0, train acc:0.9149095936458023\n",
            "num_B_prime:28463, new edges:0\n",
            "Batch 4.0, train acc:0.9163755988285812\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 268, Loss: 0.1363, Loss Cls: 0.1363, Train: 85.78%, Valid: 82.59%, Test: 84.88%\n",
            "num_B_prime:29861, new edges:0\n",
            "Batch 0.0, train acc:0.9134557262937053\n",
            "num_B_prime:29663, new edges:0\n",
            "Batch 1.0, train acc:0.9153690874326724\n",
            "num_B_prime:29901, new edges:0\n",
            "Batch 2.0, train acc:0.9131108984001094\n",
            "num_B_prime:29848, new edges:0\n",
            "Batch 3.0, train acc:0.9154481376214587\n",
            "num_B_prime:28404, new edges:0\n",
            "Batch 4.0, train acc:0.9199083267971675\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 269, Loss: 0.1383, Loss Cls: 0.1383, Train: 85.39%, Valid: 82.14%, Test: 84.45%\n",
            "num_B_prime:29488, new edges:0\n",
            "Batch 0.0, train acc:0.9185568257013619\n",
            "num_B_prime:30095, new edges:0\n",
            "Batch 1.0, train acc:0.9165710237725219\n",
            "num_B_prime:29942, new edges:0\n",
            "Batch 2.0, train acc:0.9181618701767814\n",
            "num_B_prime:29736, new edges:0\n",
            "Batch 3.0, train acc:0.916982953066713\n",
            "num_B_prime:28908, new edges:0\n",
            "Batch 4.0, train acc:0.916777705760773\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 270, Loss: 0.1322, Loss Cls: 0.1322, Train: 84.78%, Valid: 81.52%, Test: 83.76%\n",
            "num_B_prime:29748, new edges:0\n",
            "Batch 0.0, train acc:0.9121962173086131\n",
            "num_B_prime:29871, new edges:0\n",
            "Batch 1.0, train acc:0.9102393361941873\n",
            "num_B_prime:29922, new edges:0\n",
            "Batch 2.0, train acc:0.9118290746823775\n",
            "num_B_prime:29689, new edges:0\n",
            "Batch 3.0, train acc:0.9119641005273493\n",
            "num_B_prime:28953, new edges:0\n",
            "Batch 4.0, train acc:0.9140698720012435\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 271, Loss: 0.1385, Loss Cls: 0.1385, Train: 82.26%, Valid: 78.87%, Test: 81.18%\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 0.0, train acc:0.9166490855314289\n",
            "num_B_prime:30006, new edges:0\n",
            "Batch 1.0, train acc:0.9165203902518676\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 2.0, train acc:0.9185382415085177\n",
            "num_B_prime:29770, new edges:0\n",
            "Batch 3.0, train acc:0.9182031770136951\n",
            "num_B_prime:28565, new edges:0\n",
            "Batch 4.0, train acc:0.9257107289435001\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 272, Loss: 0.1301, Loss Cls: 0.1301, Train: 87.77%, Valid: 84.56%, Test: 86.77%\n",
            "num_B_prime:29841, new edges:0\n",
            "Batch 0.0, train acc:0.9217575960005758\n",
            "num_B_prime:29857, new edges:0\n",
            "Batch 1.0, train acc:0.9238325400935448\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 2.0, train acc:0.9198363157164656\n",
            "num_B_prime:29684, new edges:0\n",
            "Batch 3.0, train acc:0.9211080477030494\n",
            "num_B_prime:29118, new edges:0\n",
            "Batch 4.0, train acc:0.9167299361350543\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 273, Loss: 0.1276, Loss Cls: 0.1276, Train: 79.73%, Valid: 75.89%, Test: 78.57%\n",
            "num_B_prime:29704, new edges:0\n",
            "Batch 0.0, train acc:0.9128113590263691\n",
            "num_B_prime:29984, new edges:0\n",
            "Batch 1.0, train acc:0.904911640255538\n",
            "num_B_prime:29711, new edges:0\n",
            "Batch 2.0, train acc:0.9058321067878078\n",
            "num_B_prime:29734, new edges:0\n",
            "Batch 3.0, train acc:0.8959759370278642\n",
            "num_B_prime:29062, new edges:0\n",
            "Batch 4.0, train acc:0.9055947012785783\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 274, Loss: 0.1465, Loss Cls: 0.1465, Train: 76.73%, Valid: 73.30%, Test: 75.37%\n",
            "num_B_prime:30004, new edges:0\n",
            "Batch 0.0, train acc:0.891993909168378\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 1.0, train acc:0.9033871486805407\n",
            "num_B_prime:29694, new edges:0\n",
            "Batch 2.0, train acc:0.9015616301080057\n",
            "num_B_prime:29584, new edges:0\n",
            "Batch 3.0, train acc:0.9128389126801052\n",
            "num_B_prime:28986, new edges:0\n",
            "Batch 4.0, train acc:0.9138088437088688\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 275, Loss: 0.1473, Loss Cls: 0.1473, Train: 79.32%, Valid: 75.80%, Test: 78.36%\n",
            "num_B_prime:29776, new edges:0\n",
            "Batch 0.0, train acc:0.9167870354060242\n",
            "num_B_prime:29740, new edges:0\n",
            "Batch 1.0, train acc:0.9171408051655316\n",
            "num_B_prime:30023, new edges:0\n",
            "Batch 2.0, train acc:0.9211866492493516\n",
            "num_B_prime:29750, new edges:0\n",
            "Batch 3.0, train acc:0.9205229890317653\n",
            "num_B_prime:28409, new edges:0\n",
            "Batch 4.0, train acc:0.9227561692528539\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 276, Loss: 0.1301, Loss Cls: 0.1301, Train: 86.10%, Valid: 82.83%, Test: 84.80%\n",
            "num_B_prime:29591, new edges:0\n",
            "Batch 0.0, train acc:0.920125734138473\n",
            "num_B_prime:29728, new edges:0\n",
            "Batch 1.0, train acc:0.9231606369158148\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 2.0, train acc:0.9238648838731005\n",
            "num_B_prime:30013, new edges:0\n",
            "Batch 3.0, train acc:0.922560633169155\n",
            "num_B_prime:28635, new edges:0\n",
            "Batch 4.0, train acc:0.9269890450370698\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 277, Loss: 0.1254, Loss Cls: 0.1254, Train: 86.75%, Valid: 83.69%, Test: 85.92%\n",
            "num_B_prime:29930, new edges:0\n",
            "Batch 0.0, train acc:0.9260225391114716\n",
            "num_B_prime:29684, new edges:0\n",
            "Batch 1.0, train acc:0.9239206061369725\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 2.0, train acc:0.925113700421964\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 3.0, train acc:0.9241439477746949\n",
            "num_B_prime:28543, new edges:0\n",
            "Batch 4.0, train acc:0.925663770834316\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 278, Loss: 0.1235, Loss Cls: 0.1235, Train: 88.81%, Valid: 85.67%, Test: 87.80%\n",
            "num_B_prime:29728, new edges:0\n",
            "Batch 0.0, train acc:0.9205691981637714\n",
            "num_B_prime:29856, new edges:0\n",
            "Batch 1.0, train acc:0.9220945533473514\n",
            "num_B_prime:29941, new edges:0\n",
            "Batch 2.0, train acc:0.9183031223726232\n",
            "num_B_prime:29692, new edges:0\n",
            "Batch 3.0, train acc:0.9175480000816153\n",
            "num_B_prime:28955, new edges:0\n",
            "Batch 4.0, train acc:0.9126248662767272\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 279, Loss: 0.1309, Loss Cls: 0.1309, Train: 86.08%, Valid: 82.93%, Test: 85.07%\n",
            "num_B_prime:29915, new edges:0\n",
            "Batch 0.0, train acc:0.9081067291238935\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 1.0, train acc:0.9073992120169434\n",
            "num_B_prime:29913, new edges:0\n",
            "Batch 2.0, train acc:0.9091877935561843\n",
            "num_B_prime:29826, new edges:0\n",
            "Batch 3.0, train acc:0.910731909464168\n",
            "num_B_prime:28732, new edges:0\n",
            "Batch 4.0, train acc:0.9162833486660534\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 280, Loss: 0.1405, Loss Cls: 0.1405, Train: 82.48%, Valid: 79.07%, Test: 81.41%\n",
            "num_B_prime:29938, new edges:0\n",
            "Batch 0.0, train acc:0.9147639539125261\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 1.0, train acc:0.9162148079396871\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 2.0, train acc:0.9196827990000438\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 3.0, train acc:0.9204553009672907\n",
            "num_B_prime:28669, new edges:0\n",
            "Batch 4.0, train acc:0.9175169685800334\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 281, Loss: 0.1312, Loss Cls: 0.1312, Train: 85.60%, Valid: 82.33%, Test: 84.59%\n",
            "num_B_prime:29572, new edges:0\n",
            "Batch 0.0, train acc:0.919442367690336\n",
            "num_B_prime:29913, new edges:0\n",
            "Batch 1.0, train acc:0.9164405045652386\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 2.0, train acc:0.9173918094214077\n",
            "num_B_prime:29912, new edges:0\n",
            "Batch 3.0, train acc:0.9177846783825286\n",
            "num_B_prime:28985, new edges:0\n",
            "Batch 4.0, train acc:0.9204096003918982\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 282, Loss: 0.1306, Loss Cls: 0.1306, Train: 84.26%, Valid: 80.86%, Test: 83.17%\n",
            "num_B_prime:29827, new edges:0\n",
            "Batch 0.0, train acc:0.9201577394508664\n",
            "num_B_prime:30012, new edges:0\n",
            "Batch 1.0, train acc:0.9226410569430651\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 2.0, train acc:0.9205479452054794\n",
            "num_B_prime:29783, new edges:0\n",
            "Batch 3.0, train acc:0.91996685998343\n",
            "num_B_prime:28311, new edges:0\n",
            "Batch 4.0, train acc:0.9229942242168536\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 283, Loss: 0.1270, Loss Cls: 0.1270, Train: 80.93%, Valid: 77.32%, Test: 79.60%\n",
            "num_B_prime:29810, new edges:0\n",
            "Batch 0.0, train acc:0.9145936801925872\n",
            "num_B_prime:29825, new edges:0\n",
            "Batch 1.0, train acc:0.9139075203182521\n",
            "num_B_prime:29901, new edges:0\n",
            "Batch 2.0, train acc:0.9105047982998676\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 3.0, train acc:0.9097543629301384\n",
            "num_B_prime:28749, new edges:0\n",
            "Batch 4.0, train acc:0.9165586325529785\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 284, Loss: 0.1369, Loss Cls: 0.1369, Train: 82.31%, Valid: 79.13%, Test: 81.40%\n",
            "num_B_prime:29851, new edges:0\n",
            "Batch 0.0, train acc:0.9128557688103879\n",
            "num_B_prime:29684, new edges:0\n",
            "Batch 1.0, train acc:0.9150276578465981\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 2.0, train acc:0.9206710597003761\n",
            "num_B_prime:29787, new edges:0\n",
            "Batch 3.0, train acc:0.9210767994489725\n",
            "num_B_prime:29020, new edges:0\n",
            "Batch 4.0, train acc:0.9249485349476181\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 285, Loss: 0.1302, Loss Cls: 0.1302, Train: 87.61%, Valid: 84.58%, Test: 86.56%\n",
            "num_B_prime:29804, new edges:0\n",
            "Batch 0.0, train acc:0.9196055915023297\n",
            "num_B_prime:29832, new edges:0\n",
            "Batch 1.0, train acc:0.9224802589272519\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 2.0, train acc:0.9155489686162367\n",
            "num_B_prime:29781, new edges:0\n",
            "Batch 3.0, train acc:0.9158889280681738\n",
            "num_B_prime:29011, new edges:0\n",
            "Batch 4.0, train acc:0.9111568018266188\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 286, Loss: 0.1317, Loss Cls: 0.1317, Train: 83.31%, Valid: 79.79%, Test: 82.28%\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 0.0, train acc:0.9151749625436991\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 1.0, train acc:0.9146340787848235\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 2.0, train acc:0.9200800221566724\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 3.0, train acc:0.9191572353551255\n",
            "num_B_prime:28688, new edges:0\n",
            "Batch 4.0, train acc:0.9271294777235264\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 287, Loss: 0.1297, Loss Cls: 0.1297, Train: 85.91%, Valid: 82.64%, Test: 84.94%\n",
            "num_B_prime:29817, new edges:0\n",
            "Batch 0.0, train acc:0.9213716017860581\n",
            "num_B_prime:29906, new edges:0\n",
            "Batch 1.0, train acc:0.9224760589997386\n",
            "num_B_prime:29870, new edges:0\n",
            "Batch 2.0, train acc:0.9171547382386069\n",
            "num_B_prime:29690, new edges:0\n",
            "Batch 3.0, train acc:0.9167273223239376\n",
            "num_B_prime:28432, new edges:0\n",
            "Batch 4.0, train acc:0.9165109635796754\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 288, Loss: 0.1298, Loss Cls: 0.1298, Train: 74.34%, Valid: 70.98%, Test: 73.35%\n",
            "num_B_prime:29854, new edges:0\n",
            "Batch 0.0, train acc:0.9168151802160905\n",
            "num_B_prime:29732, new edges:0\n",
            "Batch 1.0, train acc:0.9152702364276338\n",
            "num_B_prime:29801, new edges:0\n",
            "Batch 2.0, train acc:0.9167596722443153\n",
            "num_B_prime:29902, new edges:0\n",
            "Batch 3.0, train acc:0.9157287197231835\n",
            "num_B_prime:28648, new edges:0\n",
            "Batch 4.0, train acc:0.9242544709957087\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 289, Loss: 0.1320, Loss Cls: 0.1320, Train: 84.83%, Valid: 81.54%, Test: 83.71%\n",
            "num_B_prime:29943, new edges:0\n",
            "Batch 0.0, train acc:0.914725842041717\n",
            "num_B_prime:29719, new edges:0\n",
            "Batch 1.0, train acc:0.9193633495224044\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 2.0, train acc:0.9114494372943317\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 3.0, train acc:0.9171183622058986\n",
            "num_B_prime:28892, new edges:0\n",
            "Batch 4.0, train acc:0.9161047337678446\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 290, Loss: 0.1328, Loss Cls: 0.1328, Train: 84.33%, Valid: 81.15%, Test: 83.50%\n",
            "num_B_prime:29647, new edges:0\n",
            "Batch 0.0, train acc:0.9178491679992969\n",
            "num_B_prime:29684, new edges:0\n",
            "Batch 1.0, train acc:0.9140541462623102\n",
            "num_B_prime:29916, new edges:0\n",
            "Batch 2.0, train acc:0.9207386127851657\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 3.0, train acc:0.9189423277118468\n",
            "num_B_prime:29096, new edges:0\n",
            "Batch 4.0, train acc:0.9255096366910753\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 291, Loss: 0.1296, Loss Cls: 0.1296, Train: 88.34%, Valid: 85.08%, Test: 87.20%\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 0.0, train acc:0.9226637504539323\n",
            "num_B_prime:29728, new edges:0\n",
            "Batch 1.0, train acc:0.9258437234806449\n",
            "num_B_prime:29836, new edges:0\n",
            "Batch 2.0, train acc:0.9228465606586178\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 3.0, train acc:0.9264426228620034\n",
            "num_B_prime:28505, new edges:0\n",
            "Batch 4.0, train acc:0.9257376801961562\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 292, Loss: 0.1231, Loss Cls: 0.1231, Train: 84.73%, Valid: 81.53%, Test: 83.82%\n",
            "num_B_prime:29735, new edges:0\n",
            "Batch 0.0, train acc:0.9218723248217446\n",
            "num_B_prime:29854, new edges:0\n",
            "Batch 1.0, train acc:0.9173573665743564\n",
            "num_B_prime:29928, new edges:0\n",
            "Batch 2.0, train acc:0.9192723487174012\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 3.0, train acc:0.9129445862949418\n",
            "num_B_prime:28871, new edges:0\n",
            "Batch 4.0, train acc:0.9148081898791649\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 293, Loss: 0.1326, Loss Cls: 0.1326, Train: 78.64%, Valid: 74.97%, Test: 77.17%\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 0.0, train acc:0.904853052762147\n",
            "num_B_prime:29719, new edges:0\n",
            "Batch 1.0, train acc:0.9090014716743126\n",
            "num_B_prime:29658, new edges:0\n",
            "Batch 2.0, train acc:0.9096026412402681\n",
            "num_B_prime:29895, new edges:0\n",
            "Batch 3.0, train acc:0.9150114845671882\n",
            "num_B_prime:29065, new edges:0\n",
            "Batch 4.0, train acc:0.9168325573259813\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 294, Loss: 0.1397, Loss Cls: 0.1397, Train: 79.86%, Valid: 75.96%, Test: 78.55%\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 0.0, train acc:0.9169060030996325\n",
            "num_B_prime:29637, new edges:0\n",
            "Batch 1.0, train acc:0.9162632499180416\n",
            "num_B_prime:29856, new edges:0\n",
            "Batch 2.0, train acc:0.9156289564209913\n",
            "num_B_prime:29827, new edges:0\n",
            "Batch 3.0, train acc:0.9202736189218464\n",
            "num_B_prime:28458, new edges:0\n",
            "Batch 4.0, train acc:0.9203291042775089\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 295, Loss: 0.1311, Loss Cls: 0.1311, Train: 87.59%, Valid: 84.52%, Test: 86.79%\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 0.0, train acc:0.9216610470852261\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 1.0, train acc:0.9210240359225476\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 2.0, train acc:0.9239787457635318\n",
            "num_B_prime:29661, new edges:0\n",
            "Batch 3.0, train acc:0.9192660172580679\n",
            "num_B_prime:28578, new edges:0\n",
            "Batch 4.0, train acc:0.9264492603488999\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 296, Loss: 0.1258, Loss Cls: 0.1258, Train: 87.77%, Valid: 84.63%, Test: 86.73%\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 0.0, train acc:0.9177008094730975\n",
            "num_B_prime:29928, new edges:0\n",
            "Batch 1.0, train acc:0.9231022128442788\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 2.0, train acc:0.920053910218751\n",
            "num_B_prime:29577, new edges:0\n",
            "Batch 3.0, train acc:0.926740095258714\n",
            "num_B_prime:29091, new edges:0\n",
            "Batch 4.0, train acc:0.9260424906139637\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 297, Loss: 0.1265, Loss Cls: 0.1265, Train: 88.63%, Valid: 85.48%, Test: 87.72%\n",
            "num_B_prime:29634, new edges:0\n",
            "Batch 0.0, train acc:0.9263940037962978\n",
            "num_B_prime:29930, new edges:0\n",
            "Batch 1.0, train acc:0.9225976410917877\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 2.0, train acc:0.9252625894424192\n",
            "num_B_prime:29735, new edges:0\n",
            "Batch 3.0, train acc:0.9228672340472353\n",
            "num_B_prime:28901, new edges:0\n",
            "Batch 4.0, train acc:0.92844650809349\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 298, Loss: 0.1230, Loss Cls: 0.1230, Train: 88.27%, Valid: 85.15%, Test: 87.42%\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 0.0, train acc:0.9226487241307835\n",
            "num_B_prime:29721, new edges:0\n",
            "Batch 1.0, train acc:0.9250695665906108\n",
            "num_B_prime:29878, new edges:0\n",
            "Batch 2.0, train acc:0.9238285872996109\n",
            "num_B_prime:29780, new edges:0\n",
            "Batch 3.0, train acc:0.9228080340427391\n",
            "num_B_prime:28849, new edges:0\n",
            "Batch 4.0, train acc:0.9251459869273758\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 299, Loss: 0.1235, Loss Cls: 0.1235, Train: 86.94%, Valid: 83.79%, Test: 85.84%\n",
            "num_B_prime:29643, new edges:0\n",
            "Batch 0.0, train acc:0.9249418235094011\n",
            "num_B_prime:29776, new edges:0\n",
            "Batch 1.0, train acc:0.9235817332268591\n",
            "num_B_prime:29812, new edges:0\n",
            "Batch 2.0, train acc:0.9236477404466238\n",
            "num_B_prime:29816, new edges:0\n",
            "Batch 3.0, train acc:0.9208343709219365\n",
            "num_B_prime:28989, new edges:0\n",
            "Batch 4.0, train acc:0.9258436481010014\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 300, Loss: 0.1238, Loss Cls: 0.1238, Train: 79.63%, Valid: 76.18%, Test: 78.50%\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 0.0, train acc:0.9151533455973203\n",
            "num_B_prime:29861, new edges:0\n",
            "Batch 1.0, train acc:0.913309202789516\n",
            "num_B_prime:29758, new edges:0\n",
            "Batch 2.0, train acc:0.910589944624157\n",
            "num_B_prime:29691, new edges:0\n",
            "Batch 3.0, train acc:0.9075538624662506\n",
            "num_B_prime:28812, new edges:0\n",
            "Batch 4.0, train acc:0.9089372887720616\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 301, Loss: 0.1425, Loss Cls: 0.1425, Train: 81.87%, Valid: 78.30%, Test: 80.40%\n",
            "num_B_prime:29731, new edges:0\n",
            "Batch 0.0, train acc:0.9067537865272894\n",
            "num_B_prime:29847, new edges:0\n",
            "Batch 1.0, train acc:0.9087872930360887\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 2.0, train acc:0.910154977873987\n",
            "num_B_prime:29859, new edges:0\n",
            "Batch 3.0, train acc:0.9178208554519928\n",
            "num_B_prime:28604, new edges:0\n",
            "Batch 4.0, train acc:0.9218890588447004\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 302, Loss: 0.1382, Loss Cls: 0.1382, Train: 82.29%, Valid: 79.05%, Test: 81.33%\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 0.0, train acc:0.924172352775307\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 1.0, train acc:0.9224472411519016\n",
            "num_B_prime:29900, new edges:0\n",
            "Batch 2.0, train acc:0.926090654473945\n",
            "num_B_prime:29896, new edges:0\n",
            "Batch 3.0, train acc:0.9237276860722687\n",
            "num_B_prime:28698, new edges:0\n",
            "Batch 4.0, train acc:0.9288659083074802\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 303, Loss: 0.1236, Loss Cls: 0.1236, Train: 85.83%, Valid: 82.37%, Test: 84.60%\n",
            "num_B_prime:29848, new edges:0\n",
            "Batch 0.0, train acc:0.9204066355707884\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 1.0, train acc:0.9227027769473778\n",
            "num_B_prime:29621, new edges:0\n",
            "Batch 2.0, train acc:0.9214691388096447\n",
            "num_B_prime:29928, new edges:0\n",
            "Batch 3.0, train acc:0.9223971494757803\n",
            "num_B_prime:29013, new edges:0\n",
            "Batch 4.0, train acc:0.9212746384859603\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 304, Loss: 0.1262, Loss Cls: 0.1262, Train: 79.70%, Valid: 76.27%, Test: 78.53%\n",
            "num_B_prime:29866, new edges:0\n",
            "Batch 0.0, train acc:0.9185836570857447\n",
            "num_B_prime:29929, new edges:0\n",
            "Batch 1.0, train acc:0.9156429359140424\n",
            "num_B_prime:29645, new edges:0\n",
            "Batch 2.0, train acc:0.9178039853599024\n",
            "num_B_prime:29797, new edges:0\n",
            "Batch 3.0, train acc:0.9153203682253246\n",
            "num_B_prime:28797, new edges:0\n",
            "Batch 4.0, train acc:0.9249722596765573\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 305, Loss: 0.1308, Loss Cls: 0.1308, Train: 84.21%, Valid: 80.89%, Test: 82.99%\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 0.0, train acc:0.917915352992948\n",
            "num_B_prime:29648, new edges:0\n",
            "Batch 1.0, train acc:0.921528169080696\n",
            "num_B_prime:29931, new edges:0\n",
            "Batch 2.0, train acc:0.9202211776808629\n",
            "num_B_prime:29797, new edges:0\n",
            "Batch 3.0, train acc:0.9211489709746071\n",
            "num_B_prime:28728, new edges:0\n",
            "Batch 4.0, train acc:0.9208229547619244\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 306, Loss: 0.1275, Loss Cls: 0.1275, Train: 79.04%, Valid: 75.35%, Test: 77.76%\n",
            "num_B_prime:29618, new edges:0\n",
            "Batch 0.0, train acc:0.9213577702144885\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 1.0, train acc:0.9192295440192697\n",
            "num_B_prime:29832, new edges:0\n",
            "Batch 2.0, train acc:0.9247598797958727\n",
            "num_B_prime:29881, new edges:0\n",
            "Batch 3.0, train acc:0.922733191617233\n",
            "num_B_prime:28971, new edges:0\n",
            "Batch 4.0, train acc:0.9309809372302247\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 307, Loss: 0.1240, Loss Cls: 0.1240, Train: 88.97%, Valid: 85.87%, Test: 88.02%\n",
            "num_B_prime:29921, new edges:0\n",
            "Batch 0.0, train acc:0.9275009417943776\n",
            "num_B_prime:29936, new edges:0\n",
            "Batch 1.0, train acc:0.9277130356832262\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 2.0, train acc:0.9253298659809341\n",
            "num_B_prime:29890, new edges:0\n",
            "Batch 3.0, train acc:0.9207502232807383\n",
            "num_B_prime:28397, new edges:0\n",
            "Batch 4.0, train acc:0.9211973156028468\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 308, Loss: 0.1224, Loss Cls: 0.1224, Train: 82.79%, Valid: 79.54%, Test: 81.93%\n",
            "num_B_prime:29689, new edges:0\n",
            "Batch 0.0, train acc:0.9162417360983814\n",
            "num_B_prime:29873, new edges:0\n",
            "Batch 1.0, train acc:0.912755080836208\n",
            "num_B_prime:29911, new edges:0\n",
            "Batch 2.0, train acc:0.9157803835404499\n",
            "num_B_prime:29800, new edges:0\n",
            "Batch 3.0, train acc:0.9145396139348816\n",
            "num_B_prime:28875, new edges:0\n",
            "Batch 4.0, train acc:0.9237380958804328\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 309, Loss: 0.1334, Loss Cls: 0.1334, Train: 86.65%, Valid: 83.38%, Test: 85.77%\n",
            "num_B_prime:29812, new edges:0\n",
            "Batch 0.0, train acc:0.9203449649130034\n",
            "num_B_prime:29783, new edges:0\n",
            "Batch 1.0, train acc:0.9249968747017525\n",
            "num_B_prime:29556, new edges:0\n",
            "Batch 2.0, train acc:0.9259763794974366\n",
            "num_B_prime:29787, new edges:0\n",
            "Batch 3.0, train acc:0.929034514735669\n",
            "num_B_prime:29112, new edges:0\n",
            "Batch 4.0, train acc:0.9283847360167278\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 310, Loss: 0.1212, Loss Cls: 0.1212, Train: 86.67%, Valid: 83.26%, Test: 85.59%\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 0.0, train acc:0.9309618718088802\n",
            "num_B_prime:29871, new edges:0\n",
            "Batch 1.0, train acc:0.9270116280358707\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 2.0, train acc:0.9296599470576258\n",
            "num_B_prime:29951, new edges:0\n",
            "Batch 3.0, train acc:0.9276888610482722\n",
            "num_B_prime:28654, new edges:0\n",
            "Batch 4.0, train acc:0.9293358014414336\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 311, Loss: 0.1176, Loss Cls: 0.1176, Train: 86.01%, Valid: 82.77%, Test: 84.91%\n",
            "num_B_prime:29898, new edges:0\n",
            "Batch 0.0, train acc:0.921337896317836\n",
            "num_B_prime:29659, new edges:0\n",
            "Batch 1.0, train acc:0.9225374048097269\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 2.0, train acc:0.9161227163047225\n",
            "num_B_prime:29763, new edges:0\n",
            "Batch 3.0, train acc:0.9150647286605379\n",
            "num_B_prime:28942, new edges:0\n",
            "Batch 4.0, train acc:0.9053740486356042\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 312, Loss: 0.1320, Loss Cls: 0.1320, Train: 77.80%, Valid: 74.45%, Test: 77.02%\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 0.0, train acc:0.9064919323481063\n",
            "num_B_prime:29660, new edges:0\n",
            "Batch 1.0, train acc:0.8978498126504931\n",
            "num_B_prime:29846, new edges:0\n",
            "Batch 2.0, train acc:0.90462059289577\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 3.0, train acc:0.8981894762443032\n",
            "num_B_prime:28838, new edges:0\n",
            "Batch 4.0, train acc:0.911497427506191\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 313, Loss: 0.1522, Loss Cls: 0.1522, Train: 82.75%, Valid: 79.52%, Test: 81.81%\n",
            "num_B_prime:29626, new edges:0\n",
            "Batch 0.0, train acc:0.9088100910925204\n",
            "num_B_prime:29913, new edges:0\n",
            "Batch 1.0, train acc:0.9165403111394762\n",
            "num_B_prime:29938, new edges:0\n",
            "Batch 2.0, train acc:0.9162740550263652\n",
            "num_B_prime:29850, new edges:0\n",
            "Batch 3.0, train acc:0.9244176649004302\n",
            "num_B_prime:28502, new edges:0\n",
            "Batch 4.0, train acc:0.9256826823366747\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 314, Loss: 0.1319, Loss Cls: 0.1319, Train: 87.68%, Valid: 84.69%, Test: 86.71%\n",
            "num_B_prime:29674, new edges:0\n",
            "Batch 0.0, train acc:0.9263235788400862\n",
            "num_B_prime:29856, new edges:0\n",
            "Batch 1.0, train acc:0.9260215077380086\n",
            "num_B_prime:29859, new edges:0\n",
            "Batch 2.0, train acc:0.930606151574404\n",
            "num_B_prime:29804, new edges:0\n",
            "Batch 3.0, train acc:0.9281461768498449\n",
            "num_B_prime:28801, new edges:0\n",
            "Batch 4.0, train acc:0.9330661411517535\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 315, Loss: 0.1175, Loss Cls: 0.1175, Train: 89.59%, Valid: 86.54%, Test: 88.76%\n",
            "num_B_prime:29970, new edges:0\n",
            "Batch 0.0, train acc:0.9298925222772377\n",
            "num_B_prime:29868, new edges:0\n",
            "Batch 1.0, train acc:0.9313719620063686\n",
            "num_B_prime:29851, new edges:0\n",
            "Batch 2.0, train acc:0.9303394192730126\n",
            "num_B_prime:29763, new edges:0\n",
            "Batch 3.0, train acc:0.9319918385338567\n",
            "num_B_prime:28670, new edges:0\n",
            "Batch 4.0, train acc:0.9300939862907215\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 316, Loss: 0.1147, Loss Cls: 0.1147, Train: 88.44%, Valid: 85.29%, Test: 87.41%\n",
            "num_B_prime:29762, new edges:0\n",
            "Batch 0.0, train acc:0.9314671669176601\n",
            "num_B_prime:29643, new edges:0\n",
            "Batch 1.0, train acc:0.9273679252367072\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 2.0, train acc:0.9299933956033587\n",
            "num_B_prime:29791, new edges:0\n",
            "Batch 3.0, train acc:0.9269200653873099\n",
            "num_B_prime:28796, new edges:0\n",
            "Batch 4.0, train acc:0.932627115139116\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 317, Loss: 0.1164, Loss Cls: 0.1164, Train: 86.47%, Valid: 83.15%, Test: 85.48%\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 0.0, train acc:0.9256153958447525\n",
            "num_B_prime:29870, new edges:0\n",
            "Batch 1.0, train acc:0.9257324975063053\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 2.0, train acc:0.9238646971610566\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 3.0, train acc:0.9258290314584703\n",
            "num_B_prime:28928, new edges:0\n",
            "Batch 4.0, train acc:0.925288886522179\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 318, Loss: 0.1217, Loss Cls: 0.1217, Train: 85.25%, Valid: 82.08%, Test: 84.27%\n",
            "num_B_prime:29872, new edges:0\n",
            "Batch 0.0, train acc:0.9237480483139461\n",
            "num_B_prime:29768, new edges:0\n",
            "Batch 1.0, train acc:0.9213886982352676\n",
            "num_B_prime:29830, new edges:0\n",
            "Batch 2.0, train acc:0.9245119670854264\n",
            "num_B_prime:29762, new edges:0\n",
            "Batch 3.0, train acc:0.9239058514741938\n",
            "num_B_prime:28720, new edges:0\n",
            "Batch 4.0, train acc:0.9274779787510865\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 319, Loss: 0.1225, Loss Cls: 0.1225, Train: 86.53%, Valid: 83.30%, Test: 85.40%\n",
            "num_B_prime:29868, new edges:0\n",
            "Batch 0.0, train acc:0.922836734111547\n",
            "num_B_prime:29746, new edges:0\n",
            "Batch 1.0, train acc:0.9226273617622636\n",
            "num_B_prime:29624, new edges:0\n",
            "Batch 2.0, train acc:0.9230545632360331\n",
            "num_B_prime:29901, new edges:0\n",
            "Batch 3.0, train acc:0.9186062679771528\n",
            "num_B_prime:28691, new edges:0\n",
            "Batch 4.0, train acc:0.9187471326688076\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 320, Loss: 0.1262, Loss Cls: 0.1262, Train: 83.55%, Valid: 80.23%, Test: 82.66%\n",
            "num_B_prime:29568, new edges:0\n",
            "Batch 0.0, train acc:0.9166909322289807\n",
            "num_B_prime:29612, new edges:0\n",
            "Batch 1.0, train acc:0.9114780241686028\n",
            "num_B_prime:29933, new edges:0\n",
            "Batch 2.0, train acc:0.9156681168931127\n",
            "num_B_prime:29941, new edges:0\n",
            "Batch 3.0, train acc:0.9130941993638056\n",
            "num_B_prime:28670, new edges:0\n",
            "Batch 4.0, train acc:0.919107874474138\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 321, Loss: 0.1363, Loss Cls: 0.1363, Train: 81.98%, Valid: 78.49%, Test: 80.88%\n",
            "num_B_prime:29960, new edges:0\n",
            "Batch 0.0, train acc:0.9182307303017128\n",
            "num_B_prime:29641, new edges:0\n",
            "Batch 1.0, train acc:0.9207817881672\n",
            "num_B_prime:29694, new edges:0\n",
            "Batch 2.0, train acc:0.9238245673365749\n",
            "num_B_prime:29805, new edges:0\n",
            "Batch 3.0, train acc:0.9236690430274529\n",
            "num_B_prime:29055, new edges:0\n",
            "Batch 4.0, train acc:0.9285982443548834\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 322, Loss: 0.1240, Loss Cls: 0.1240, Train: 84.79%, Valid: 81.41%, Test: 83.65%\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 0.0, train acc:0.9254194976149189\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 1.0, train acc:0.9260611792490221\n",
            "num_B_prime:29628, new edges:0\n",
            "Batch 2.0, train acc:0.9255173828325302\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 3.0, train acc:0.9283147393992812\n",
            "num_B_prime:28885, new edges:0\n",
            "Batch 4.0, train acc:0.9295085078826315\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 323, Loss: 0.1190, Loss Cls: 0.1190, Train: 84.73%, Valid: 81.49%, Test: 83.77%\n",
            "num_B_prime:29587, new edges:0\n",
            "Batch 0.0, train acc:0.9262741837659549\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 1.0, train acc:0.9271221605133431\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 2.0, train acc:0.928347626461922\n",
            "num_B_prime:30112, new edges:0\n",
            "Batch 3.0, train acc:0.9257456592307785\n",
            "num_B_prime:28513, new edges:0\n",
            "Batch 4.0, train acc:0.9268636233308186\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 324, Loss: 0.1195, Loss Cls: 0.1195, Train: 86.81%, Valid: 83.54%, Test: 85.69%\n",
            "num_B_prime:29547, new edges:0\n",
            "Batch 0.0, train acc:0.9207747348998632\n",
            "num_B_prime:29958, new edges:0\n",
            "Batch 1.0, train acc:0.9178995435026658\n",
            "num_B_prime:30012, new edges:0\n",
            "Batch 2.0, train acc:0.9135589720023688\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 3.0, train acc:0.9176199931089681\n",
            "num_B_prime:28641, new edges:0\n",
            "Batch 4.0, train acc:0.920328511109186\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 325, Loss: 0.1299, Loss Cls: 0.1299, Train: 87.81%, Valid: 84.66%, Test: 87.00%\n",
            "num_B_prime:29786, new edges:0\n",
            "Batch 0.0, train acc:0.9217076950490559\n",
            "num_B_prime:29550, new edges:0\n",
            "Batch 1.0, train acc:0.9222410406173416\n",
            "num_B_prime:30029, new edges:0\n",
            "Batch 2.0, train acc:0.9248004815285278\n",
            "num_B_prime:29740, new edges:0\n",
            "Batch 3.0, train acc:0.9257826789259308\n",
            "num_B_prime:28919, new edges:0\n",
            "Batch 4.0, train acc:0.9294781034591358\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 326, Loss: 0.1219, Loss Cls: 0.1219, Train: 86.50%, Valid: 83.47%, Test: 85.51%\n",
            "num_B_prime:29934, new edges:0\n",
            "Batch 0.0, train acc:0.9270657215936187\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 1.0, train acc:0.9239746145685322\n",
            "num_B_prime:29821, new edges:0\n",
            "Batch 2.0, train acc:0.9265782847927526\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 3.0, train acc:0.9238481521554067\n",
            "num_B_prime:28646, new edges:0\n",
            "Batch 4.0, train acc:0.9291454464475902\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 327, Loss: 0.1200, Loss Cls: 0.1200, Train: 86.00%, Valid: 82.76%, Test: 84.92%\n",
            "num_B_prime:29861, new edges:0\n",
            "Batch 0.0, train acc:0.9258133954891342\n",
            "num_B_prime:29766, new edges:0\n",
            "Batch 1.0, train acc:0.9261846500897758\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 2.0, train acc:0.9241376295553554\n",
            "num_B_prime:29756, new edges:0\n",
            "Batch 3.0, train acc:0.9253980216034925\n",
            "num_B_prime:28727, new edges:0\n",
            "Batch 4.0, train acc:0.9219869743543516\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 328, Loss: 0.1207, Loss Cls: 0.1207, Train: 77.37%, Valid: 73.95%, Test: 76.43%\n",
            "num_B_prime:29716, new edges:0\n",
            "Batch 0.0, train acc:0.9176199792841524\n",
            "num_B_prime:29970, new edges:0\n",
            "Batch 1.0, train acc:0.9107235337055054\n",
            "num_B_prime:29607, new edges:0\n",
            "Batch 2.0, train acc:0.903933855877276\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 3.0, train acc:0.8926813359572299\n",
            "num_B_prime:28691, new edges:0\n",
            "Batch 4.0, train acc:0.8908755118974331\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 329, Loss: 0.1563, Loss Cls: 0.1563, Train: 72.59%, Valid: 69.12%, Test: 71.00%\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 0.0, train acc:0.8856318554578568\n",
            "num_B_prime:29830, new edges:0\n",
            "Batch 1.0, train acc:0.9022818661886537\n",
            "num_B_prime:29677, new edges:0\n",
            "Batch 2.0, train acc:0.911959526998243\n",
            "num_B_prime:29881, new edges:0\n",
            "Batch 3.0, train acc:0.9238600015283677\n",
            "num_B_prime:28992, new edges:0\n",
            "Batch 4.0, train acc:0.9310064125992624\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 330, Loss: 0.1451, Loss Cls: 0.1451, Train: 86.92%, Valid: 83.81%, Test: 85.97%\n",
            "num_B_prime:29904, new edges:0\n",
            "Batch 0.0, train acc:0.9312882578460687\n",
            "num_B_prime:29707, new edges:0\n",
            "Batch 1.0, train acc:0.9330837021274268\n",
            "num_B_prime:29972, new edges:0\n",
            "Batch 2.0, train acc:0.9337001345483623\n",
            "num_B_prime:29768, new edges:0\n",
            "Batch 3.0, train acc:0.9336651048315804\n",
            "num_B_prime:28691, new edges:0\n",
            "Batch 4.0, train acc:0.9406640719277173\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 331, Loss: 0.1107, Loss Cls: 0.1107, Train: 90.19%, Valid: 87.17%, Test: 89.24%\n",
            "num_B_prime:29846, new edges:0\n",
            "Batch 0.0, train acc:0.9363557246655466\n",
            "num_B_prime:29918, new edges:0\n",
            "Batch 1.0, train acc:0.9357448443424152\n",
            "num_B_prime:29726, new edges:0\n",
            "Batch 2.0, train acc:0.9339519680591432\n",
            "num_B_prime:29772, new edges:0\n",
            "Batch 3.0, train acc:0.931072671731124\n",
            "num_B_prime:28654, new edges:0\n",
            "Batch 4.0, train acc:0.9342746049692524\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 332, Loss: 0.1106, Loss Cls: 0.1106, Train: 88.81%, Valid: 85.67%, Test: 87.87%\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 0.0, train acc:0.9285857910222372\n",
            "num_B_prime:29657, new edges:0\n",
            "Batch 1.0, train acc:0.9279245180999757\n",
            "num_B_prime:29850, new edges:0\n",
            "Batch 2.0, train acc:0.9238938545543074\n",
            "num_B_prime:29878, new edges:0\n",
            "Batch 3.0, train acc:0.9232332861180292\n",
            "num_B_prime:28837, new edges:0\n",
            "Batch 4.0, train acc:0.9240829159384903\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 333, Loss: 0.1205, Loss Cls: 0.1205, Train: 87.65%, Valid: 84.51%, Test: 86.72%\n",
            "num_B_prime:29747, new edges:0\n",
            "Batch 0.0, train acc:0.9200713892350555\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 1.0, train acc:0.916817082228557\n",
            "num_B_prime:29916, new edges:0\n",
            "Batch 2.0, train acc:0.9236162745037184\n",
            "num_B_prime:29700, new edges:0\n",
            "Batch 3.0, train acc:0.9205561672345671\n",
            "num_B_prime:28946, new edges:0\n",
            "Batch 4.0, train acc:0.9306701184473486\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 334, Loss: 0.1255, Loss Cls: 0.1255, Train: 88.34%, Valid: 85.18%, Test: 87.25%\n",
            "num_B_prime:29866, new edges:0\n",
            "Batch 0.0, train acc:0.9286089698668535\n",
            "num_B_prime:29725, new edges:0\n",
            "Batch 1.0, train acc:0.9294950572965515\n",
            "num_B_prime:29736, new edges:0\n",
            "Batch 2.0, train acc:0.928356092240961\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 3.0, train acc:0.9292290738538245\n",
            "num_B_prime:29000, new edges:0\n",
            "Batch 4.0, train acc:0.9313669301525873\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 335, Loss: 0.1151, Loss Cls: 0.1151, Train: 87.68%, Valid: 84.64%, Test: 86.93%\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 0.0, train acc:0.9320404105976386\n",
            "num_B_prime:29597, new edges:0\n",
            "Batch 1.0, train acc:0.9294916494401555\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 2.0, train acc:0.9303529691828254\n",
            "num_B_prime:29935, new edges:0\n",
            "Batch 3.0, train acc:0.9264725340154807\n",
            "num_B_prime:28852, new edges:0\n",
            "Batch 4.0, train acc:0.9315874810949273\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 336, Loss: 0.1148, Loss Cls: 0.1148, Train: 88.21%, Valid: 85.04%, Test: 87.13%\n",
            "num_B_prime:29931, new edges:0\n",
            "Batch 0.0, train acc:0.927360183513426\n",
            "num_B_prime:29561, new edges:0\n",
            "Batch 1.0, train acc:0.9275818929062626\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 2.0, train acc:0.9250900086611461\n",
            "num_B_prime:29918, new edges:0\n",
            "Batch 3.0, train acc:0.9275082924616562\n",
            "num_B_prime:28502, new edges:0\n",
            "Batch 4.0, train acc:0.9237166321558562\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 337, Loss: 0.1194, Loss Cls: 0.1194, Train: 85.23%, Valid: 82.02%, Test: 84.26%\n",
            "num_B_prime:29798, new edges:0\n",
            "Batch 0.0, train acc:0.9240414202766704\n",
            "num_B_prime:29862, new edges:0\n",
            "Batch 1.0, train acc:0.9186210513241606\n",
            "num_B_prime:29673, new edges:0\n",
            "Batch 2.0, train acc:0.9216840408076296\n",
            "num_B_prime:30011, new edges:0\n",
            "Batch 3.0, train acc:0.9202777910557836\n",
            "num_B_prime:28759, new edges:0\n",
            "Batch 4.0, train acc:0.925455822228637\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 338, Loss: 0.1247, Loss Cls: 0.1247, Train: 85.65%, Valid: 82.62%, Test: 84.65%\n",
            "num_B_prime:30037, new edges:0\n",
            "Batch 0.0, train acc:0.9203275855383779\n",
            "num_B_prime:29577, new edges:0\n",
            "Batch 1.0, train acc:0.9223618104040365\n",
            "num_B_prime:29940, new edges:0\n",
            "Batch 2.0, train acc:0.9186979093357677\n",
            "num_B_prime:29702, new edges:0\n",
            "Batch 3.0, train acc:0.9228109449381684\n",
            "num_B_prime:28557, new edges:0\n",
            "Batch 4.0, train acc:0.9252142154797022\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 339, Loss: 0.1277, Loss Cls: 0.1277, Train: 82.51%, Valid: 79.28%, Test: 81.53%\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 0.0, train acc:0.924311621994487\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 1.0, train acc:0.9223572766232805\n",
            "num_B_prime:29830, new edges:0\n",
            "Batch 2.0, train acc:0.9279064215803294\n",
            "num_B_prime:29737, new edges:0\n",
            "Batch 3.0, train acc:0.9252488207937963\n",
            "num_B_prime:28865, new edges:0\n",
            "Batch 4.0, train acc:0.9295005002693759\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 340, Loss: 0.1218, Loss Cls: 0.1218, Train: 86.33%, Valid: 83.07%, Test: 85.17%\n",
            "num_B_prime:29815, new edges:0\n",
            "Batch 0.0, train acc:0.9241369653138719\n",
            "num_B_prime:29862, new edges:0\n",
            "Batch 1.0, train acc:0.9247249596894677\n",
            "num_B_prime:29728, new edges:0\n",
            "Batch 2.0, train acc:0.9198307447204617\n",
            "num_B_prime:29682, new edges:0\n",
            "Batch 3.0, train acc:0.9205715953421995\n",
            "num_B_prime:29105, new edges:0\n",
            "Batch 4.0, train acc:0.9203283220037797\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 341, Loss: 0.1231, Loss Cls: 0.1231, Train: 80.43%, Valid: 76.75%, Test: 79.25%\n",
            "num_B_prime:29795, new edges:0\n",
            "Batch 0.0, train acc:0.9222100811374742\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 1.0, train acc:0.9235743826164207\n",
            "num_B_prime:29707, new edges:0\n",
            "Batch 2.0, train acc:0.926474044656968\n",
            "num_B_prime:29845, new edges:0\n",
            "Batch 3.0, train acc:0.9251377434154864\n",
            "num_B_prime:28928, new edges:0\n",
            "Batch 4.0, train acc:0.9318423128468138\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 342, Loss: 0.1197, Loss Cls: 0.1197, Train: 86.82%, Valid: 83.58%, Test: 85.73%\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 0.0, train acc:0.9251080914144534\n",
            "num_B_prime:29851, new edges:0\n",
            "Batch 1.0, train acc:0.9291868522515419\n",
            "num_B_prime:29682, new edges:0\n",
            "Batch 2.0, train acc:0.9251899270874603\n",
            "num_B_prime:29733, new edges:0\n",
            "Batch 3.0, train acc:0.9286597770913736\n",
            "num_B_prime:29160, new edges:0\n",
            "Batch 4.0, train acc:0.9271322653140026\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 343, Loss: 0.1181, Loss Cls: 0.1181, Train: 83.37%, Valid: 80.19%, Test: 82.43%\n",
            "num_B_prime:29957, new edges:0\n",
            "Batch 0.0, train acc:0.9255961082791678\n",
            "num_B_prime:29625, new edges:0\n",
            "Batch 1.0, train acc:0.9214957315939729\n",
            "num_B_prime:29655, new edges:0\n",
            "Batch 2.0, train acc:0.9256825280921667\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 3.0, train acc:0.9251765015481149\n",
            "num_B_prime:28507, new edges:0\n",
            "Batch 4.0, train acc:0.9332424309884239\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 344, Loss: 0.1206, Loss Cls: 0.1206, Train: 85.23%, Valid: 81.77%, Test: 83.97%\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 0.0, train acc:0.9267425854770076\n",
            "num_B_prime:29716, new edges:0\n",
            "Batch 1.0, train acc:0.9280632903338473\n",
            "num_B_prime:29865, new edges:0\n",
            "Batch 2.0, train acc:0.9257575653061647\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 3.0, train acc:0.9272928696936619\n",
            "num_B_prime:29013, new edges:0\n",
            "Batch 4.0, train acc:0.9294049431035734\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 345, Loss: 0.1172, Loss Cls: 0.1172, Train: 82.98%, Valid: 79.83%, Test: 82.17%\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 0.0, train acc:0.9281279573187606\n",
            "num_B_prime:29681, new edges:0\n",
            "Batch 1.0, train acc:0.9254696285699074\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 2.0, train acc:0.9228642182489846\n",
            "num_B_prime:29812, new edges:0\n",
            "Batch 3.0, train acc:0.9202897065074621\n",
            "num_B_prime:28978, new edges:0\n",
            "Batch 4.0, train acc:0.9199504364408067\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 346, Loss: 0.1248, Loss Cls: 0.1248, Train: 84.73%, Valid: 81.22%, Test: 83.50%\n",
            "num_B_prime:29812, new edges:0\n",
            "Batch 0.0, train acc:0.9100382067784141\n",
            "num_B_prime:29928, new edges:0\n",
            "Batch 1.0, train acc:0.9002506224610143\n",
            "num_B_prime:29780, new edges:0\n",
            "Batch 2.0, train acc:0.9014047418350823\n",
            "num_B_prime:29680, new edges:0\n",
            "Batch 3.0, train acc:0.9027488932358694\n",
            "num_B_prime:28488, new edges:0\n",
            "Batch 4.0, train acc:0.9177571899982051\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 347, Loss: 0.1530, Loss Cls: 0.1530, Train: 87.23%, Valid: 84.09%, Test: 86.35%\n",
            "num_B_prime:29982, new edges:0\n",
            "Batch 0.0, train acc:0.9205139473878162\n",
            "num_B_prime:29653, new edges:0\n",
            "Batch 1.0, train acc:0.9286445663126205\n",
            "num_B_prime:29760, new edges:0\n",
            "Batch 2.0, train acc:0.9291197406286565\n",
            "num_B_prime:29954, new edges:0\n",
            "Batch 3.0, train acc:0.9336093666583802\n",
            "num_B_prime:28776, new edges:0\n",
            "Batch 4.0, train acc:0.9362703949745671\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 348, Loss: 0.1161, Loss Cls: 0.1161, Train: 87.74%, Valid: 84.54%, Test: 86.81%\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 0.0, train acc:0.93477793881319\n",
            "num_B_prime:29888, new edges:0\n",
            "Batch 1.0, train acc:0.931977454139042\n",
            "num_B_prime:29694, new edges:0\n",
            "Batch 2.0, train acc:0.935964860657097\n",
            "num_B_prime:29710, new edges:0\n",
            "Batch 3.0, train acc:0.9308802904050821\n",
            "num_B_prime:29170, new edges:0\n",
            "Batch 4.0, train acc:0.9364812553726203\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 349, Loss: 0.1106, Loss Cls: 0.1106, Train: 88.19%, Valid: 85.08%, Test: 87.23%\n",
            "num_B_prime:29902, new edges:0\n",
            "Batch 0.0, train acc:0.9318077206759056\n",
            "num_B_prime:29804, new edges:0\n",
            "Batch 1.0, train acc:0.9318239698810036\n",
            "num_B_prime:29972, new edges:0\n",
            "Batch 2.0, train acc:0.9325095108918133\n",
            "num_B_prime:29613, new edges:0\n",
            "Batch 3.0, train acc:0.9352267689650108\n",
            "num_B_prime:29221, new edges:0\n",
            "Batch 4.0, train acc:0.9336208962377187\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 350, Loss: 0.1110, Loss Cls: 0.1110, Train: 82.42%, Valid: 78.96%, Test: 81.26%\n",
            "num_B_prime:29898, new edges:0\n",
            "Batch 0.0, train acc:0.9313510504892001\n",
            "num_B_prime:29894, new edges:0\n",
            "Batch 1.0, train acc:0.9259251045758339\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 2.0, train acc:0.928471512600856\n",
            "num_B_prime:29820, new edges:0\n",
            "Batch 3.0, train acc:0.9242551830877601\n",
            "num_B_prime:28774, new edges:0\n",
            "Batch 4.0, train acc:0.9248834511589223\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 351, Loss: 0.1191, Loss Cls: 0.1191, Train: 84.83%, Valid: 81.58%, Test: 83.70%\n",
            "num_B_prime:29754, new edges:0\n",
            "Batch 0.0, train acc:0.9212019058452655\n",
            "num_B_prime:29759, new edges:0\n",
            "Batch 1.0, train acc:0.9212642324940662\n",
            "num_B_prime:29741, new edges:0\n",
            "Batch 2.0, train acc:0.9209852768107712\n",
            "num_B_prime:29965, new edges:0\n",
            "Batch 3.0, train acc:0.9260762388580105\n",
            "num_B_prime:28718, new edges:0\n",
            "Batch 4.0, train acc:0.9303591319919347\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 352, Loss: 0.1238, Loss Cls: 0.1238, Train: 86.07%, Valid: 82.82%, Test: 85.14%\n",
            "num_B_prime:29860, new edges:0\n",
            "Batch 0.0, train acc:0.9319323879799648\n",
            "num_B_prime:29854, new edges:0\n",
            "Batch 1.0, train acc:0.9315168454241303\n",
            "num_B_prime:29717, new edges:0\n",
            "Batch 2.0, train acc:0.9347124864040022\n",
            "num_B_prime:29761, new edges:0\n",
            "Batch 3.0, train acc:0.93127486755622\n",
            "num_B_prime:28755, new edges:0\n",
            "Batch 4.0, train acc:0.9356186182203953\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 353, Loss: 0.1109, Loss Cls: 0.1109, Train: 88.22%, Valid: 84.92%, Test: 87.12%\n",
            "num_B_prime:29752, new edges:0\n",
            "Batch 0.0, train acc:0.9294697041203285\n",
            "num_B_prime:29800, new edges:0\n",
            "Batch 1.0, train acc:0.9296790673040178\n",
            "num_B_prime:29920, new edges:0\n",
            "Batch 2.0, train acc:0.9256127157750812\n",
            "num_B_prime:29842, new edges:0\n",
            "Batch 3.0, train acc:0.9251972790212863\n",
            "num_B_prime:28459, new edges:0\n",
            "Batch 4.0, train acc:0.9255257303207486\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 354, Loss: 0.1168, Loss Cls: 0.1168, Train: 86.15%, Valid: 82.91%, Test: 85.37%\n",
            "num_B_prime:29898, new edges:0\n",
            "Batch 0.0, train acc:0.9248952581425732\n",
            "num_B_prime:29585, new edges:0\n",
            "Batch 1.0, train acc:0.9246846539146434\n",
            "num_B_prime:29719, new edges:0\n",
            "Batch 2.0, train acc:0.9295172437993718\n",
            "num_B_prime:29888, new edges:0\n",
            "Batch 3.0, train acc:0.9289483418922447\n",
            "num_B_prime:28913, new edges:0\n",
            "Batch 4.0, train acc:0.9325290079649222\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 355, Loss: 0.1168, Loss Cls: 0.1168, Train: 89.03%, Valid: 85.87%, Test: 88.03%\n",
            "num_B_prime:29780, new edges:0\n",
            "Batch 0.0, train acc:0.9302084795014911\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 1.0, train acc:0.9276343723719281\n",
            "num_B_prime:29709, new edges:0\n",
            "Batch 2.0, train acc:0.9280348343970705\n",
            "num_B_prime:29959, new edges:0\n",
            "Batch 3.0, train acc:0.9267697492969152\n",
            "num_B_prime:28861, new edges:0\n",
            "Batch 4.0, train acc:0.9307582189887312\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 356, Loss: 0.1156, Loss Cls: 0.1156, Train: 85.55%, Valid: 82.35%, Test: 84.66%\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 0.0, train acc:0.9242587531125744\n",
            "num_B_prime:29726, new edges:0\n",
            "Batch 1.0, train acc:0.9259303723107928\n",
            "num_B_prime:29625, new edges:0\n",
            "Batch 2.0, train acc:0.9202776670120717\n",
            "num_B_prime:29896, new edges:0\n",
            "Batch 3.0, train acc:0.920450364860221\n",
            "num_B_prime:29179, new edges:0\n",
            "Batch 4.0, train acc:0.924715592237341\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 357, Loss: 0.1245, Loss Cls: 0.1245, Train: 85.08%, Valid: 82.00%, Test: 84.12%\n",
            "num_B_prime:29691, new edges:0\n",
            "Batch 0.0, train acc:0.9224860005795189\n",
            "num_B_prime:29900, new edges:0\n",
            "Batch 1.0, train acc:0.9217521364022195\n",
            "num_B_prime:29741, new edges:0\n",
            "Batch 2.0, train acc:0.9220859004343923\n",
            "num_B_prime:30092, new edges:0\n",
            "Batch 3.0, train acc:0.926900156311059\n",
            "num_B_prime:28670, new edges:0\n",
            "Batch 4.0, train acc:0.9286631284616709\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 358, Loss: 0.1243, Loss Cls: 0.1243, Train: 83.41%, Valid: 79.88%, Test: 82.32%\n",
            "num_B_prime:29770, new edges:0\n",
            "Batch 0.0, train acc:0.927805301150127\n",
            "num_B_prime:29838, new edges:0\n",
            "Batch 1.0, train acc:0.9252875610818929\n",
            "num_B_prime:29643, new edges:0\n",
            "Batch 2.0, train acc:0.926825059586079\n",
            "num_B_prime:29897, new edges:0\n",
            "Batch 3.0, train acc:0.9187005277044854\n",
            "num_B_prime:28639, new edges:0\n",
            "Batch 4.0, train acc:0.9228752663797571\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 359, Loss: 0.1219, Loss Cls: 0.1219, Train: 81.81%, Valid: 78.43%, Test: 80.61%\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 0.0, train acc:0.9155188131769016\n",
            "num_B_prime:29819, new edges:0\n",
            "Batch 1.0, train acc:0.9175949489938966\n",
            "num_B_prime:29659, new edges:0\n",
            "Batch 2.0, train acc:0.9168650976307825\n",
            "num_B_prime:29865, new edges:0\n",
            "Batch 3.0, train acc:0.9209670483255389\n",
            "num_B_prime:28825, new edges:0\n",
            "Batch 4.0, train acc:0.9234028910355594\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 360, Loss: 0.1278, Loss Cls: 0.1278, Train: 82.40%, Valid: 79.02%, Test: 81.44%\n",
            "num_B_prime:29819, new edges:0\n",
            "Batch 0.0, train acc:0.929847370101569\n",
            "num_B_prime:30006, new edges:0\n",
            "Batch 1.0, train acc:0.9305887356262111\n",
            "num_B_prime:29605, new edges:0\n",
            "Batch 2.0, train acc:0.9335720617104698\n",
            "num_B_prime:29756, new edges:0\n",
            "Batch 3.0, train acc:0.9322578426923024\n",
            "num_B_prime:28526, new edges:0\n",
            "Batch 4.0, train acc:0.9397361044643467\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 361, Loss: 0.1107, Loss Cls: 0.1107, Train: 89.73%, Valid: 86.56%, Test: 88.74%\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 0.0, train acc:0.936225903080309\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 1.0, train acc:0.9385987669496878\n",
            "num_B_prime:29826, new edges:0\n",
            "Batch 2.0, train acc:0.9373157446647751\n",
            "num_B_prime:29768, new edges:0\n",
            "Batch 3.0, train acc:0.9348251113846675\n",
            "num_B_prime:28981, new edges:0\n",
            "Batch 4.0, train acc:0.9356396105600893\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 362, Loss: 0.1068, Loss Cls: 0.1068, Train: 86.80%, Valid: 83.40%, Test: 85.73%\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 0.0, train acc:0.9321995212229738\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 1.0, train acc:0.9296644913042235\n",
            "num_B_prime:29715, new edges:0\n",
            "Batch 2.0, train acc:0.9303782234255649\n",
            "num_B_prime:29893, new edges:0\n",
            "Batch 3.0, train acc:0.9297279819143704\n",
            "num_B_prime:28782, new edges:0\n",
            "Batch 4.0, train acc:0.9288995528169208\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 363, Loss: 0.1142, Loss Cls: 0.1142, Train: 87.08%, Valid: 83.93%, Test: 86.02%\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 0.0, train acc:0.9277219849960242\n",
            "num_B_prime:29756, new edges:0\n",
            "Batch 1.0, train acc:0.9271595246474107\n",
            "num_B_prime:29922, new edges:0\n",
            "Batch 2.0, train acc:0.9259353284486228\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 3.0, train acc:0.923342048966009\n",
            "num_B_prime:28825, new edges:0\n",
            "Batch 4.0, train acc:0.9273623705878917\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 364, Loss: 0.1191, Loss Cls: 0.1191, Train: 81.44%, Valid: 77.86%, Test: 80.06%\n",
            "num_B_prime:29873, new edges:0\n",
            "Batch 0.0, train acc:0.9215540700991084\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 1.0, train acc:0.9245593148532479\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 2.0, train acc:0.9196466924027817\n",
            "num_B_prime:29723, new edges:0\n",
            "Batch 3.0, train acc:0.9239010049075623\n",
            "num_B_prime:28556, new edges:0\n",
            "Batch 4.0, train acc:0.9234344629426181\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 365, Loss: 0.1241, Loss Cls: 0.1241, Train: 86.74%, Valid: 83.57%, Test: 85.65%\n",
            "num_B_prime:29860, new edges:0\n",
            "Batch 0.0, train acc:0.924709517989336\n",
            "num_B_prime:29982, new edges:0\n",
            "Batch 1.0, train acc:0.9215336578147474\n",
            "num_B_prime:29737, new edges:0\n",
            "Batch 2.0, train acc:0.9261223502861288\n",
            "num_B_prime:29783, new edges:0\n",
            "Batch 3.0, train acc:0.9269861016082326\n",
            "num_B_prime:28492, new edges:0\n",
            "Batch 4.0, train acc:0.9343061663367759\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 366, Loss: 0.1193, Loss Cls: 0.1193, Train: 88.06%, Valid: 84.71%, Test: 87.01%\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 0.0, train acc:0.9316459361380439\n",
            "num_B_prime:29803, new edges:0\n",
            "Batch 1.0, train acc:0.9347834309551083\n",
            "num_B_prime:29682, new edges:0\n",
            "Batch 2.0, train acc:0.9332082896801912\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 3.0, train acc:0.9334958895525844\n",
            "num_B_prime:28918, new edges:0\n",
            "Batch 4.0, train acc:0.9370109955456203\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 367, Loss: 0.1097, Loss Cls: 0.1097, Train: 86.67%, Valid: 83.52%, Test: 85.72%\n",
            "num_B_prime:29829, new edges:0\n",
            "Batch 0.0, train acc:0.9293774057151963\n",
            "num_B_prime:29690, new edges:0\n",
            "Batch 1.0, train acc:0.9307013029227728\n",
            "num_B_prime:29831, new edges:0\n",
            "Batch 2.0, train acc:0.9245414671674389\n",
            "num_B_prime:29791, new edges:0\n",
            "Batch 3.0, train acc:0.9265761381139824\n",
            "num_B_prime:28639, new edges:0\n",
            "Batch 4.0, train acc:0.9217250873366118\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 368, Loss: 0.1179, Loss Cls: 0.1179, Train: 83.09%, Valid: 79.86%, Test: 82.33%\n",
            "num_B_prime:29785, new edges:0\n",
            "Batch 0.0, train acc:0.9249704998463464\n",
            "num_B_prime:30023, new edges:0\n",
            "Batch 1.0, train acc:0.9201350610212121\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 2.0, train acc:0.9265988586575945\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 3.0, train acc:0.9199428291792994\n",
            "num_B_prime:28519, new edges:0\n",
            "Batch 4.0, train acc:0.9283461783989194\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 369, Loss: 0.1226, Loss Cls: 0.1226, Train: 83.29%, Valid: 79.94%, Test: 81.99%\n",
            "num_B_prime:29873, new edges:0\n",
            "Batch 0.0, train acc:0.9195458731373919\n",
            "num_B_prime:29947, new edges:0\n",
            "Batch 1.0, train acc:0.9240054302915831\n",
            "num_B_prime:29681, new edges:0\n",
            "Batch 2.0, train acc:0.9188386471087404\n",
            "num_B_prime:29586, new edges:0\n",
            "Batch 3.0, train acc:0.9218664291018676\n",
            "num_B_prime:28783, new edges:0\n",
            "Batch 4.0, train acc:0.9164978830371064\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 370, Loss: 0.1272, Loss Cls: 0.1272, Train: 66.25%, Valid: 62.59%, Test: 65.45%\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 0.0, train acc:0.9166344917201659\n",
            "num_B_prime:29767, new edges:0\n",
            "Batch 1.0, train acc:0.9156089853032865\n",
            "num_B_prime:29779, new edges:0\n",
            "Batch 2.0, train acc:0.9216760533832523\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 3.0, train acc:0.9252446909807569\n",
            "num_B_prime:28724, new edges:0\n",
            "Batch 4.0, train acc:0.9333978013858821\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 371, Loss: 0.1248, Loss Cls: 0.1248, Train: 86.26%, Valid: 82.93%, Test: 85.16%\n",
            "num_B_prime:29830, new edges:0\n",
            "Batch 0.0, train acc:0.9299683554304856\n",
            "num_B_prime:29698, new edges:0\n",
            "Batch 1.0, train acc:0.9321523630225916\n",
            "num_B_prime:29732, new edges:0\n",
            "Batch 2.0, train acc:0.930316389008329\n",
            "num_B_prime:29997, new edges:0\n",
            "Batch 3.0, train acc:0.9316321663259198\n",
            "num_B_prime:28869, new edges:0\n",
            "Batch 4.0, train acc:0.9306927940301495\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 372, Loss: 0.1130, Loss Cls: 0.1130, Train: 87.44%, Valid: 84.34%, Test: 86.36%\n",
            "num_B_prime:29739, new edges:0\n",
            "Batch 0.0, train acc:0.9261810400666858\n",
            "num_B_prime:29843, new edges:0\n",
            "Batch 1.0, train acc:0.9244101314947465\n",
            "num_B_prime:29776, new edges:0\n",
            "Batch 2.0, train acc:0.9262377013307687\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 3.0, train acc:0.9246643758166477\n",
            "num_B_prime:28900, new edges:0\n",
            "Batch 4.0, train acc:0.9341072556573414\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 373, Loss: 0.1179, Loss Cls: 0.1179, Train: 84.76%, Valid: 81.51%, Test: 83.71%\n",
            "num_B_prime:29930, new edges:0\n",
            "Batch 0.0, train acc:0.9276878468738862\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 1.0, train acc:0.9322806936934868\n",
            "num_B_prime:29747, new edges:0\n",
            "Batch 2.0, train acc:0.9301149180007194\n",
            "num_B_prime:29871, new edges:0\n",
            "Batch 3.0, train acc:0.9336466028431772\n",
            "num_B_prime:29060, new edges:0\n",
            "Batch 4.0, train acc:0.9349343587049467\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 374, Loss: 0.1114, Loss Cls: 0.1114, Train: 86.78%, Valid: 83.55%, Test: 85.78%\n",
            "num_B_prime:29661, new edges:0\n",
            "Batch 0.0, train acc:0.9342621624149555\n",
            "num_B_prime:29848, new edges:0\n",
            "Batch 1.0, train acc:0.9314374958972452\n",
            "num_B_prime:29879, new edges:0\n",
            "Batch 2.0, train acc:0.9337262576510773\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 3.0, train acc:0.9283002748937283\n",
            "num_B_prime:28854, new edges:0\n",
            "Batch 4.0, train acc:0.9341782513273948\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 375, Loss: 0.1103, Loss Cls: 0.1103, Train: 87.58%, Valid: 84.17%, Test: 86.47%\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 0.0, train acc:0.9298737497050867\n",
            "num_B_prime:29829, new edges:0\n",
            "Batch 1.0, train acc:0.9319208199248221\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 2.0, train acc:0.9327334887976281\n",
            "num_B_prime:29907, new edges:0\n",
            "Batch 3.0, train acc:0.9345985578053911\n",
            "num_B_prime:28849, new edges:0\n",
            "Batch 4.0, train acc:0.9351289302013047\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 376, Loss: 0.1097, Loss Cls: 0.1097, Train: 88.70%, Valid: 85.71%, Test: 87.88%\n",
            "num_B_prime:29852, new edges:0\n",
            "Batch 0.0, train acc:0.9342824930854271\n",
            "num_B_prime:29843, new edges:0\n",
            "Batch 1.0, train acc:0.9356425786908814\n",
            "num_B_prime:29759, new edges:0\n",
            "Batch 2.0, train acc:0.9363893162706263\n",
            "num_B_prime:29785, new edges:0\n",
            "Batch 3.0, train acc:0.9353487490264598\n",
            "num_B_prime:28894, new edges:0\n",
            "Batch 4.0, train acc:0.9378819887238444\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 377, Loss: 0.1071, Loss Cls: 0.1071, Train: 88.45%, Valid: 85.37%, Test: 87.39%\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 0.0, train acc:0.9334875806629939\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 1.0, train acc:0.9308077426986089\n",
            "num_B_prime:29921, new edges:0\n",
            "Batch 2.0, train acc:0.9315513977661216\n",
            "num_B_prime:29748, new edges:0\n",
            "Batch 3.0, train acc:0.9291678663979268\n",
            "num_B_prime:28797, new edges:0\n",
            "Batch 4.0, train acc:0.9299863754593122\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 378, Loss: 0.1133, Loss Cls: 0.1133, Train: 86.74%, Valid: 83.78%, Test: 86.03%\n",
            "num_B_prime:29760, new edges:0\n",
            "Batch 0.0, train acc:0.9269059844047103\n",
            "num_B_prime:29732, new edges:0\n",
            "Batch 1.0, train acc:0.9254162710701566\n",
            "num_B_prime:29973, new edges:0\n",
            "Batch 2.0, train acc:0.9234719983274372\n",
            "num_B_prime:29710, new edges:0\n",
            "Batch 3.0, train acc:0.9237349582102862\n",
            "num_B_prime:28783, new edges:0\n",
            "Batch 4.0, train acc:0.9232380873616453\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 379, Loss: 0.1217, Loss Cls: 0.1217, Train: 85.44%, Valid: 82.00%, Test: 84.05%\n",
            "num_B_prime:29855, new edges:0\n",
            "Batch 0.0, train acc:0.9214103068851976\n",
            "num_B_prime:29621, new edges:0\n",
            "Batch 1.0, train acc:0.9188366551126517\n",
            "num_B_prime:29778, new edges:0\n",
            "Batch 2.0, train acc:0.9200324544716943\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 3.0, train acc:0.919986398329562\n",
            "num_B_prime:28891, new edges:0\n",
            "Batch 4.0, train acc:0.9256664458693962\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 380, Loss: 0.1296, Loss Cls: 0.1296, Train: 87.27%, Valid: 83.98%, Test: 86.24%\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 0.0, train acc:0.9251240365326457\n",
            "num_B_prime:29670, new edges:0\n",
            "Batch 1.0, train acc:0.9273499689761869\n",
            "num_B_prime:29976, new edges:0\n",
            "Batch 2.0, train acc:0.929763742587976\n",
            "num_B_prime:29825, new edges:0\n",
            "Batch 3.0, train acc:0.929243010468272\n",
            "num_B_prime:28656, new edges:0\n",
            "Batch 4.0, train acc:0.9339180427388573\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 381, Loss: 0.1151, Loss Cls: 0.1151, Train: 83.25%, Valid: 79.77%, Test: 82.06%\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 0.0, train acc:0.9310088281507025\n",
            "num_B_prime:29704, new edges:0\n",
            "Batch 1.0, train acc:0.9279986441400745\n",
            "num_B_prime:29921, new edges:0\n",
            "Batch 2.0, train acc:0.9258300442401112\n",
            "num_B_prime:29903, new edges:0\n",
            "Batch 3.0, train acc:0.9243673519816116\n",
            "num_B_prime:28684, new edges:0\n",
            "Batch 4.0, train acc:0.9269661678666624\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 382, Loss: 0.1184, Loss Cls: 0.1184, Train: 82.99%, Valid: 79.79%, Test: 81.98%\n",
            "num_B_prime:29975, new edges:0\n",
            "Batch 0.0, train acc:0.9238478764351925\n",
            "num_B_prime:29827, new edges:0\n",
            "Batch 1.0, train acc:0.9261045369055125\n",
            "num_B_prime:29745, new edges:0\n",
            "Batch 2.0, train acc:0.9265395135756077\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 3.0, train acc:0.9324792243767314\n",
            "num_B_prime:28693, new edges:0\n",
            "Batch 4.0, train acc:0.933322569779839\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 383, Loss: 0.1158, Loss Cls: 0.1158, Train: 84.45%, Valid: 81.34%, Test: 83.40%\n",
            "num_B_prime:29943, new edges:0\n",
            "Batch 0.0, train acc:0.9312125666042385\n",
            "num_B_prime:29834, new edges:0\n",
            "Batch 1.0, train acc:0.9282498902064119\n",
            "num_B_prime:29746, new edges:0\n",
            "Batch 2.0, train acc:0.9265075479174697\n",
            "num_B_prime:29786, new edges:0\n",
            "Batch 3.0, train acc:0.9292502842426816\n",
            "num_B_prime:28619, new edges:0\n",
            "Batch 4.0, train acc:0.93378645751007\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 384, Loss: 0.1168, Loss Cls: 0.1168, Train: 87.97%, Valid: 84.83%, Test: 86.95%\n",
            "num_B_prime:29694, new edges:0\n",
            "Batch 0.0, train acc:0.9311458502958259\n",
            "num_B_prime:29648, new edges:0\n",
            "Batch 1.0, train acc:0.9335282976227629\n",
            "num_B_prime:29949, new edges:0\n",
            "Batch 2.0, train acc:0.9303921068698293\n",
            "num_B_prime:29858, new edges:0\n",
            "Batch 3.0, train acc:0.9323155992072998\n",
            "num_B_prime:29169, new edges:0\n",
            "Batch 4.0, train acc:0.9357421394598149\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 385, Loss: 0.1110, Loss Cls: 0.1110, Train: 90.05%, Valid: 87.08%, Test: 89.23%\n",
            "num_B_prime:29775, new edges:0\n",
            "Batch 0.0, train acc:0.9345530460162284\n",
            "num_B_prime:29627, new edges:0\n",
            "Batch 1.0, train acc:0.9321364857101232\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 2.0, train acc:0.9339331946402051\n",
            "num_B_prime:29865, new edges:0\n",
            "Batch 3.0, train acc:0.9309045551872418\n",
            "num_B_prime:28900, new edges:0\n",
            "Batch 4.0, train acc:0.9362054726642074\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 386, Loss: 0.1092, Loss Cls: 0.1092, Train: 89.02%, Valid: 85.78%, Test: 87.93%\n",
            "num_B_prime:29659, new edges:0\n",
            "Batch 0.0, train acc:0.9318047902231437\n",
            "num_B_prime:29843, new edges:0\n",
            "Batch 1.0, train acc:0.932248629081781\n",
            "num_B_prime:29787, new edges:0\n",
            "Batch 2.0, train acc:0.9312900365182619\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 3.0, train acc:0.93182337241123\n",
            "num_B_prime:28946, new edges:0\n",
            "Batch 4.0, train acc:0.9343259075792785\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 387, Loss: 0.1113, Loss Cls: 0.1113, Train: 87.65%, Valid: 84.70%, Test: 86.96%\n",
            "num_B_prime:29663, new edges:0\n",
            "Batch 0.0, train acc:0.930309493045321\n",
            "num_B_prime:29739, new edges:0\n",
            "Batch 1.0, train acc:0.9320171476438416\n",
            "num_B_prime:29864, new edges:0\n",
            "Batch 2.0, train acc:0.934254290506306\n",
            "num_B_prime:29821, new edges:0\n",
            "Batch 3.0, train acc:0.9312966586839376\n",
            "num_B_prime:28732, new edges:0\n",
            "Batch 4.0, train acc:0.9378029430304085\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 388, Loss: 0.1107, Loss Cls: 0.1107, Train: 86.50%, Valid: 83.08%, Test: 85.25%\n",
            "num_B_prime:29898, new edges:0\n",
            "Batch 0.0, train acc:0.9319650499774383\n",
            "num_B_prime:29885, new edges:0\n",
            "Batch 1.0, train acc:0.9329506948614565\n",
            "num_B_prime:29751, new edges:0\n",
            "Batch 2.0, train acc:0.9306985828751327\n",
            "num_B_prime:30036, new edges:0\n",
            "Batch 3.0, train acc:0.9337191503074899\n",
            "num_B_prime:28668, new edges:0\n",
            "Batch 4.0, train acc:0.9301387857673197\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 389, Loss: 0.1104, Loss Cls: 0.1104, Train: 83.66%, Valid: 80.46%, Test: 82.88%\n",
            "num_B_prime:29762, new edges:0\n",
            "Batch 0.0, train acc:0.9319062621610239\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 1.0, train acc:0.9252020149752603\n",
            "num_B_prime:29937, new edges:0\n",
            "Batch 2.0, train acc:0.9262522445171314\n",
            "num_B_prime:29919, new edges:0\n",
            "Batch 3.0, train acc:0.9186734637335845\n",
            "num_B_prime:28761, new edges:0\n",
            "Batch 4.0, train acc:0.9251938330882491\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 390, Loss: 0.1196, Loss Cls: 0.1196, Train: 82.54%, Valid: 79.23%, Test: 81.26%\n",
            "num_B_prime:29983, new edges:0\n",
            "Batch 0.0, train acc:0.9130016929071884\n",
            "num_B_prime:29659, new edges:0\n",
            "Batch 1.0, train acc:0.9144781091286548\n",
            "num_B_prime:29785, new edges:0\n",
            "Batch 2.0, train acc:0.9038511999955806\n",
            "num_B_prime:29897, new edges:0\n",
            "Batch 3.0, train acc:0.9025060582776762\n",
            "num_B_prime:28396, new edges:0\n",
            "Batch 4.0, train acc:0.8990632582811354\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 391, Loss: 0.1506, Loss Cls: 0.1506, Train: 66.07%, Valid: 63.59%, Test: 65.46%\n",
            "num_B_prime:29739, new edges:0\n",
            "Batch 0.0, train acc:0.896136721793979\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 1.0, train acc:0.8976255039288427\n",
            "num_B_prime:29650, new edges:0\n",
            "Batch 2.0, train acc:0.9052107789886813\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 3.0, train acc:0.9113240003535562\n",
            "num_B_prime:28886, new edges:0\n",
            "Batch 4.0, train acc:0.918170151522322\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 392, Loss: 0.1607, Loss Cls: 0.1607, Train: 85.99%, Valid: 82.48%, Test: 84.62%\n",
            "num_B_prime:29857, new edges:0\n",
            "Batch 0.0, train acc:0.9233286740970412\n",
            "num_B_prime:29817, new edges:0\n",
            "Batch 1.0, train acc:0.9271157959269901\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 2.0, train acc:0.9357960210816201\n",
            "num_B_prime:29849, new edges:0\n",
            "Batch 3.0, train acc:0.9368001460982566\n",
            "num_B_prime:28740, new edges:0\n",
            "Batch 4.0, train acc:0.9437224265953547\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 393, Loss: 0.1134, Loss Cls: 0.1134, Train: 91.05%, Valid: 88.14%, Test: 90.20%\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 0.0, train acc:0.9399468112900874\n",
            "num_B_prime:29850, new edges:0\n",
            "Batch 1.0, train acc:0.9412073102697326\n",
            "num_B_prime:29780, new edges:0\n",
            "Batch 2.0, train acc:0.9424229852518893\n",
            "num_B_prime:29704, new edges:0\n",
            "Batch 3.0, train acc:0.9419416541894243\n",
            "num_B_prime:28693, new edges:0\n",
            "Batch 4.0, train acc:0.9453882503444758\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 394, Loss: 0.0996, Loss Cls: 0.0996, Train: 90.34%, Valid: 87.48%, Test: 89.53%\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 0.0, train acc:0.9424266553995493\n",
            "num_B_prime:29858, new edges:0\n",
            "Batch 1.0, train acc:0.9444094509659563\n",
            "num_B_prime:29750, new edges:0\n",
            "Batch 2.0, train acc:0.9429001918130695\n",
            "num_B_prime:29748, new edges:0\n",
            "Batch 3.0, train acc:0.9414505855763303\n",
            "num_B_prime:28815, new edges:0\n",
            "Batch 4.0, train acc:0.9454534483798949\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 395, Loss: 0.0984, Loss Cls: 0.0984, Train: 90.85%, Valid: 87.87%, Test: 89.93%\n",
            "num_B_prime:29749, new edges:0\n",
            "Batch 0.0, train acc:0.9433177900512888\n",
            "num_B_prime:29828, new edges:0\n",
            "Batch 1.0, train acc:0.941635506862385\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 2.0, train acc:0.9403789568940962\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 3.0, train acc:0.9396996809748677\n",
            "num_B_prime:28521, new edges:0\n",
            "Batch 4.0, train acc:0.9400268336314849\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 396, Loss: 0.1006, Loss Cls: 0.1006, Train: 87.77%, Valid: 84.72%, Test: 86.79%\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 0.0, train acc:0.9365460437985702\n",
            "num_B_prime:29747, new edges:0\n",
            "Batch 1.0, train acc:0.9320335591111774\n",
            "num_B_prime:29731, new edges:0\n",
            "Batch 2.0, train acc:0.9321524652233537\n",
            "num_B_prime:29787, new edges:0\n",
            "Batch 3.0, train acc:0.927797579478221\n",
            "num_B_prime:29024, new edges:0\n",
            "Batch 4.0, train acc:0.9289280148727342\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 397, Loss: 0.1110, Loss Cls: 0.1110, Train: 86.03%, Valid: 82.65%, Test: 84.96%\n",
            "num_B_prime:29795, new edges:0\n",
            "Batch 0.0, train acc:0.9197447544703489\n",
            "num_B_prime:29933, new edges:0\n",
            "Batch 1.0, train acc:0.9242381988212766\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 2.0, train acc:0.9199704012140519\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 3.0, train acc:0.9254625021934613\n",
            "num_B_prime:28892, new edges:0\n",
            "Batch 4.0, train acc:0.9289669663501439\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 398, Loss: 0.1207, Loss Cls: 0.1207, Train: 82.64%, Valid: 79.15%, Test: 81.45%\n",
            "num_B_prime:29891, new edges:0\n",
            "Batch 0.0, train acc:0.9286877081749152\n",
            "num_B_prime:29763, new edges:0\n",
            "Batch 1.0, train acc:0.9300231544556923\n",
            "num_B_prime:29676, new edges:0\n",
            "Batch 2.0, train acc:0.9354926614454744\n",
            "num_B_prime:30059, new edges:0\n",
            "Batch 3.0, train acc:0.9350738351804692\n",
            "num_B_prime:28439, new edges:0\n",
            "Batch 4.0, train acc:0.9393989286968738\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 399, Loss: 0.1097, Loss Cls: 0.1097, Train: 88.39%, Valid: 85.34%, Test: 87.44%\n",
            "num_B_prime:29657, new edges:0\n",
            "Batch 0.0, train acc:0.936776350902417\n",
            "num_B_prime:29627, new edges:0\n",
            "Batch 1.0, train acc:0.9370893645589974\n",
            "num_B_prime:29919, new edges:0\n",
            "Batch 2.0, train acc:0.9343956116075823\n",
            "num_B_prime:29751, new edges:0\n",
            "Batch 3.0, train acc:0.9351532209504141\n",
            "num_B_prime:29079, new edges:0\n",
            "Batch 4.0, train acc:0.9360091419464267\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 400, Loss: 0.1061, Loss Cls: 0.1061, Train: 84.39%, Valid: 81.00%, Test: 83.33%\n",
            "num_B_prime:29629, new edges:0\n",
            "Batch 0.0, train acc:0.9343001347987685\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 1.0, train acc:0.9301752261888783\n",
            "num_B_prime:29941, new edges:0\n",
            "Batch 2.0, train acc:0.9309466167142297\n",
            "num_B_prime:29749, new edges:0\n",
            "Batch 3.0, train acc:0.9312905117030393\n",
            "num_B_prime:29032, new edges:0\n",
            "Batch 4.0, train acc:0.9361643880618261\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 401, Loss: 0.1103, Loss Cls: 0.1103, Train: 89.46%, Valid: 86.51%, Test: 88.52%\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 0.0, train acc:0.9323724521062771\n",
            "num_B_prime:29854, new edges:0\n",
            "Batch 1.0, train acc:0.9357841863687537\n",
            "num_B_prime:30040, new edges:0\n",
            "Batch 2.0, train acc:0.9351424855947962\n",
            "num_B_prime:29739, new edges:0\n",
            "Batch 3.0, train acc:0.9334908488203971\n",
            "num_B_prime:28450, new edges:0\n",
            "Batch 4.0, train acc:0.934455816247604\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 402, Loss: 0.1080, Loss Cls: 0.1080, Train: 86.19%, Valid: 82.91%, Test: 85.05%\n",
            "num_B_prime:29791, new edges:0\n",
            "Batch 0.0, train acc:0.9289082712851832\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 1.0, train acc:0.931312362273539\n",
            "num_B_prime:29819, new edges:0\n",
            "Batch 2.0, train acc:0.9312703138229591\n",
            "num_B_prime:29904, new edges:0\n",
            "Batch 3.0, train acc:0.9320089963206795\n",
            "num_B_prime:28715, new edges:0\n",
            "Batch 4.0, train acc:0.934771280702568\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 403, Loss: 0.1118, Loss Cls: 0.1118, Train: 86.79%, Valid: 83.79%, Test: 85.80%\n",
            "num_B_prime:29734, new edges:0\n",
            "Batch 0.0, train acc:0.9325519327311281\n",
            "num_B_prime:29715, new edges:0\n",
            "Batch 1.0, train acc:0.9320795038153261\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 2.0, train acc:0.9363676004638611\n",
            "num_B_prime:29851, new edges:0\n",
            "Batch 3.0, train acc:0.93408402305897\n",
            "num_B_prime:28749, new edges:0\n",
            "Batch 4.0, train acc:0.9356037424811305\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 404, Loss: 0.1083, Loss Cls: 0.1083, Train: 87.72%, Valid: 84.44%, Test: 86.73%\n",
            "num_B_prime:29808, new edges:0\n",
            "Batch 0.0, train acc:0.9327236281633675\n",
            "num_B_prime:29854, new edges:0\n",
            "Batch 1.0, train acc:0.9340911630963297\n",
            "num_B_prime:29820, new edges:0\n",
            "Batch 2.0, train acc:0.9325551674425139\n",
            "num_B_prime:29905, new edges:0\n",
            "Batch 3.0, train acc:0.9326561482812376\n",
            "num_B_prime:28411, new edges:0\n",
            "Batch 4.0, train acc:0.9366915012118735\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 405, Loss: 0.1082, Loss Cls: 0.1082, Train: 88.16%, Valid: 85.02%, Test: 87.15%\n",
            "num_B_prime:29855, new edges:0\n",
            "Batch 0.0, train acc:0.932033854834573\n",
            "num_B_prime:29736, new edges:0\n",
            "Batch 1.0, train acc:0.9337653270793653\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 2.0, train acc:0.9338410293824306\n",
            "num_B_prime:29875, new edges:0\n",
            "Batch 3.0, train acc:0.9352978876920204\n",
            "num_B_prime:28722, new edges:0\n",
            "Batch 4.0, train acc:0.9323030330022715\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 406, Loss: 0.1090, Loss Cls: 0.1090, Train: 86.79%, Valid: 83.51%, Test: 85.78%\n",
            "num_B_prime:29786, new edges:0\n",
            "Batch 0.0, train acc:0.9301196266808637\n",
            "num_B_prime:29777, new edges:0\n",
            "Batch 1.0, train acc:0.9269731439064253\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 2.0, train acc:0.9290539580658386\n",
            "num_B_prime:29631, new edges:0\n",
            "Batch 3.0, train acc:0.9276336671591966\n",
            "num_B_prime:28812, new edges:0\n",
            "Batch 4.0, train acc:0.934230041000535\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 407, Loss: 0.1145, Loss Cls: 0.1145, Train: 82.99%, Valid: 79.42%, Test: 81.72%\n",
            "num_B_prime:29915, new edges:0\n",
            "Batch 0.0, train acc:0.9305074116227691\n",
            "num_B_prime:29981, new edges:0\n",
            "Batch 1.0, train acc:0.9368343283018664\n",
            "num_B_prime:29697, new edges:0\n",
            "Batch 2.0, train acc:0.9357989446401859\n",
            "num_B_prime:29622, new edges:0\n",
            "Batch 3.0, train acc:0.9369271460922652\n",
            "num_B_prime:28582, new edges:0\n",
            "Batch 4.0, train acc:0.9391528487580619\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 408, Loss: 0.1066, Loss Cls: 0.1066, Train: 88.67%, Valid: 85.32%, Test: 87.55%\n",
            "num_B_prime:29862, new edges:0\n",
            "Batch 0.0, train acc:0.9375140859412124\n",
            "num_B_prime:29759, new edges:0\n",
            "Batch 1.0, train acc:0.9396074306796095\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 2.0, train acc:0.934951100511968\n",
            "num_B_prime:29781, new edges:0\n",
            "Batch 3.0, train acc:0.9322461042450295\n",
            "num_B_prime:28850, new edges:0\n",
            "Batch 4.0, train acc:0.9260606474603094\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 409, Loss: 0.1071, Loss Cls: 0.1071, Train: 76.94%, Valid: 73.18%, Test: 75.96%\n",
            "num_B_prime:29900, new edges:0\n",
            "Batch 0.0, train acc:0.9198031529521745\n",
            "num_B_prime:29922, new edges:0\n",
            "Batch 1.0, train acc:0.9069204985787339\n",
            "num_B_prime:29911, new edges:0\n",
            "Batch 2.0, train acc:0.902821524749425\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 3.0, train acc:0.9033334119635397\n",
            "num_B_prime:28345, new edges:0\n",
            "Batch 4.0, train acc:0.9101991856318696\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 410, Loss: 0.1485, Loss Cls: 0.1485, Train: 76.70%, Valid: 73.01%, Test: 75.15%\n",
            "num_B_prime:29656, new edges:0\n",
            "Batch 0.0, train acc:0.9099680849304649\n",
            "num_B_prime:29777, new edges:0\n",
            "Batch 1.0, train acc:0.9165165295241137\n",
            "num_B_prime:29660, new edges:0\n",
            "Batch 2.0, train acc:0.9236779977892711\n",
            "num_B_prime:29929, new edges:0\n",
            "Batch 3.0, train acc:0.9293852334178847\n",
            "num_B_prime:29099, new edges:0\n",
            "Batch 4.0, train acc:0.9373406896551724\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 411, Loss: 0.1261, Loss Cls: 0.1261, Train: 87.41%, Valid: 84.25%, Test: 86.41%\n",
            "num_B_prime:29524, new edges:0\n",
            "Batch 0.0, train acc:0.9376744336989681\n",
            "num_B_prime:29856, new edges:0\n",
            "Batch 1.0, train acc:0.9385042655611495\n",
            "num_B_prime:30022, new edges:0\n",
            "Batch 2.0, train acc:0.936711451985998\n",
            "num_B_prime:29753, new edges:0\n",
            "Batch 3.0, train acc:0.9382873253569208\n",
            "num_B_prime:29102, new edges:0\n",
            "Batch 4.0, train acc:0.9410307234886025\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 412, Loss: 0.1032, Loss Cls: 0.1032, Train: 87.53%, Valid: 84.32%, Test: 86.61%\n",
            "num_B_prime:29725, new edges:0\n",
            "Batch 0.0, train acc:0.9384118870389437\n",
            "num_B_prime:29796, new edges:0\n",
            "Batch 1.0, train acc:0.9373562470461722\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 2.0, train acc:0.9357160450650405\n",
            "num_B_prime:29928, new edges:0\n",
            "Batch 3.0, train acc:0.936487600891774\n",
            "num_B_prime:28789, new edges:0\n",
            "Batch 4.0, train acc:0.9392930117393139\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 413, Loss: 0.1039, Loss Cls: 0.1039, Train: 89.06%, Valid: 85.88%, Test: 88.20%\n",
            "num_B_prime:29819, new edges:0\n",
            "Batch 0.0, train acc:0.9355115394696937\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 1.0, train acc:0.9356785119347996\n",
            "num_B_prime:29760, new edges:0\n",
            "Batch 2.0, train acc:0.9348670670318765\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 3.0, train acc:0.9372464138525927\n",
            "num_B_prime:28842, new edges:0\n",
            "Batch 4.0, train acc:0.9383180587290677\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 414, Loss: 0.1050, Loss Cls: 0.1050, Train: 87.59%, Valid: 84.56%, Test: 86.66%\n",
            "num_B_prime:30006, new edges:0\n",
            "Batch 0.0, train acc:0.9363935516572756\n",
            "num_B_prime:29728, new edges:0\n",
            "Batch 1.0, train acc:0.9344927106620721\n",
            "num_B_prime:29870, new edges:0\n",
            "Batch 2.0, train acc:0.9368719526399075\n",
            "num_B_prime:29766, new edges:0\n",
            "Batch 3.0, train acc:0.9335687012126861\n",
            "num_B_prime:28277, new edges:0\n",
            "Batch 4.0, train acc:0.9364970412891013\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 415, Loss: 0.1068, Loss Cls: 0.1068, Train: 86.94%, Valid: 83.85%, Test: 86.05%\n",
            "num_B_prime:29700, new edges:0\n",
            "Batch 0.0, train acc:0.9312243084101767\n",
            "num_B_prime:29811, new edges:0\n",
            "Batch 1.0, train acc:0.931884219712015\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 2.0, train acc:0.9333017722980765\n",
            "num_B_prime:29646, new edges:0\n",
            "Batch 3.0, train acc:0.9343102371187223\n",
            "num_B_prime:29353, new edges:0\n",
            "Batch 4.0, train acc:0.9350999682640432\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 416, Loss: 0.1109, Loss Cls: 0.1109, Train: 85.34%, Valid: 82.09%, Test: 84.21%\n",
            "num_B_prime:29749, new edges:0\n",
            "Batch 0.0, train acc:0.9314433677547539\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 1.0, train acc:0.9302631362687573\n",
            "num_B_prime:29942, new edges:0\n",
            "Batch 2.0, train acc:0.9321446126389138\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 3.0, train acc:0.929370159175251\n",
            "num_B_prime:28615, new edges:0\n",
            "Batch 4.0, train acc:0.9376339862863502\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 417, Loss: 0.1116, Loss Cls: 0.1116, Train: 88.06%, Valid: 84.94%, Test: 87.06%\n",
            "num_B_prime:29918, new edges:0\n",
            "Batch 0.0, train acc:0.9342361256141662\n",
            "num_B_prime:29682, new edges:0\n",
            "Batch 1.0, train acc:0.937514617289128\n",
            "num_B_prime:29896, new edges:0\n",
            "Batch 2.0, train acc:0.937153949177566\n",
            "num_B_prime:29810, new edges:0\n",
            "Batch 3.0, train acc:0.9382849448061291\n",
            "num_B_prime:28522, new edges:0\n",
            "Batch 4.0, train acc:0.9403787520697023\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 418, Loss: 0.1039, Loss Cls: 0.1039, Train: 89.26%, Valid: 86.25%, Test: 88.28%\n",
            "num_B_prime:29963, new edges:0\n",
            "Batch 0.0, train acc:0.9389487227655999\n",
            "num_B_prime:29696, new edges:0\n",
            "Batch 1.0, train acc:0.9378848954611655\n",
            "num_B_prime:29797, new edges:0\n",
            "Batch 2.0, train acc:0.9383943435017706\n",
            "num_B_prime:29767, new edges:0\n",
            "Batch 3.0, train acc:0.9393489564321579\n",
            "num_B_prime:28407, new edges:0\n",
            "Batch 4.0, train acc:0.9416357473444404\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 419, Loss: 0.1024, Loss Cls: 0.1024, Train: 89.97%, Valid: 86.94%, Test: 89.06%\n",
            "num_B_prime:29677, new edges:0\n",
            "Batch 0.0, train acc:0.9367537928592073\n",
            "num_B_prime:29760, new edges:0\n",
            "Batch 1.0, train acc:0.9365339330383697\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 2.0, train acc:0.9326090467072597\n",
            "num_B_prime:29831, new edges:0\n",
            "Batch 3.0, train acc:0.9281992963210812\n",
            "num_B_prime:29126, new edges:0\n",
            "Batch 4.0, train acc:0.9271000194414551\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 420, Loss: 0.1097, Loss Cls: 0.1097, Train: 83.86%, Valid: 80.31%, Test: 82.65%\n",
            "num_B_prime:29684, new edges:0\n",
            "Batch 0.0, train acc:0.9208583015555959\n",
            "num_B_prime:29789, new edges:0\n",
            "Batch 1.0, train acc:0.9201387073727499\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 2.0, train acc:0.9194126848085229\n",
            "num_B_prime:29968, new edges:0\n",
            "Batch 3.0, train acc:0.9264784515025132\n",
            "num_B_prime:28663, new edges:0\n",
            "Batch 4.0, train acc:0.9292452697553967\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 421, Loss: 0.1205, Loss Cls: 0.1205, Train: 85.65%, Valid: 82.36%, Test: 84.65%\n",
            "num_B_prime:29788, new edges:0\n",
            "Batch 0.0, train acc:0.9303542787150837\n",
            "num_B_prime:29948, new edges:0\n",
            "Batch 1.0, train acc:0.9287713815834481\n",
            "num_B_prime:29680, new edges:0\n",
            "Batch 2.0, train acc:0.9344072512130257\n",
            "num_B_prime:29737, new edges:0\n",
            "Batch 3.0, train acc:0.9322073773917569\n",
            "num_B_prime:28903, new edges:0\n",
            "Batch 4.0, train acc:0.936951665951275\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 422, Loss: 0.1099, Loss Cls: 0.1099, Train: 88.94%, Valid: 85.78%, Test: 88.00%\n",
            "num_B_prime:29787, new edges:0\n",
            "Batch 0.0, train acc:0.9343495241975945\n",
            "num_B_prime:29624, new edges:0\n",
            "Batch 1.0, train acc:0.9366217703814025\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 2.0, train acc:0.9351764028619205\n",
            "num_B_prime:30020, new edges:0\n",
            "Batch 3.0, train acc:0.9372720396897792\n",
            "num_B_prime:29145, new edges:0\n",
            "Batch 4.0, train acc:0.9377826143541094\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 423, Loss: 0.1054, Loss Cls: 0.1054, Train: 86.24%, Valid: 83.05%, Test: 85.22%\n",
            "num_B_prime:29890, new edges:0\n",
            "Batch 0.0, train acc:0.9321913949051002\n",
            "num_B_prime:29761, new edges:0\n",
            "Batch 1.0, train acc:0.9324593642878545\n",
            "num_B_prime:29871, new edges:0\n",
            "Batch 2.0, train acc:0.9328135156194277\n",
            "num_B_prime:29559, new edges:0\n",
            "Batch 3.0, train acc:0.9314446452047961\n",
            "num_B_prime:29260, new edges:0\n",
            "Batch 4.0, train acc:0.9337352522778593\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 424, Loss: 0.1106, Loss Cls: 0.1106, Train: 85.12%, Valid: 81.91%, Test: 84.05%\n",
            "num_B_prime:29712, new edges:0\n",
            "Batch 0.0, train acc:0.9289588559030897\n",
            "num_B_prime:29839, new edges:0\n",
            "Batch 1.0, train acc:0.9286197025519826\n",
            "num_B_prime:30070, new edges:0\n",
            "Batch 2.0, train acc:0.9247395252991297\n",
            "num_B_prime:29607, new edges:0\n",
            "Batch 3.0, train acc:0.9222879791508307\n",
            "num_B_prime:28978, new edges:0\n",
            "Batch 4.0, train acc:0.9236781850471885\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 425, Loss: 0.1224, Loss Cls: 0.1224, Train: 74.70%, Valid: 71.25%, Test: 73.43%\n",
            "num_B_prime:29660, new edges:0\n",
            "Batch 0.0, train acc:0.9170257662362861\n",
            "num_B_prime:29894, new edges:0\n",
            "Batch 1.0, train acc:0.9192549670245336\n",
            "num_B_prime:29649, new edges:0\n",
            "Batch 2.0, train acc:0.9245796963260757\n",
            "num_B_prime:29896, new edges:0\n",
            "Batch 3.0, train acc:0.9279730578447093\n",
            "num_B_prime:28877, new edges:0\n",
            "Batch 4.0, train acc:0.9342222592608026\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 426, Loss: 0.1246, Loss Cls: 0.1246, Train: 87.11%, Valid: 83.80%, Test: 85.98%\n",
            "num_B_prime:29960, new edges:0\n",
            "Batch 0.0, train acc:0.9325376524304523\n",
            "num_B_prime:29706, new edges:0\n",
            "Batch 1.0, train acc:0.9332085909534656\n",
            "num_B_prime:29881, new edges:0\n",
            "Batch 2.0, train acc:0.9345102785091665\n",
            "num_B_prime:29883, new edges:0\n",
            "Batch 3.0, train acc:0.9369794353947077\n",
            "num_B_prime:28723, new edges:0\n",
            "Batch 4.0, train acc:0.9390206118781652\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 427, Loss: 0.1066, Loss Cls: 0.1066, Train: 86.80%, Valid: 83.71%, Test: 85.95%\n",
            "num_B_prime:29845, new edges:0\n",
            "Batch 0.0, train acc:0.9375351670706372\n",
            "num_B_prime:29873, new edges:0\n",
            "Batch 1.0, train acc:0.9378335317985358\n",
            "num_B_prime:29915, new edges:0\n",
            "Batch 2.0, train acc:0.9405868467791563\n",
            "num_B_prime:29672, new edges:0\n",
            "Batch 3.0, train acc:0.9388107871560637\n",
            "num_B_prime:28513, new edges:0\n",
            "Batch 4.0, train acc:0.9430173631756664\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 428, Loss: 0.1017, Loss Cls: 0.1017, Train: 91.00%, Valid: 88.14%, Test: 90.13%\n",
            "num_B_prime:29728, new edges:0\n",
            "Batch 0.0, train acc:0.9405718720707474\n",
            "num_B_prime:29944, new edges:0\n",
            "Batch 1.0, train acc:0.9401248470374742\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 2.0, train acc:0.9401870486304588\n",
            "num_B_prime:29917, new edges:0\n",
            "Batch 3.0, train acc:0.9384305234077503\n",
            "num_B_prime:28608, new edges:0\n",
            "Batch 4.0, train acc:0.9421660535908529\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 429, Loss: 0.1024, Loss Cls: 0.1024, Train: 90.52%, Valid: 87.62%, Test: 89.67%\n",
            "num_B_prime:29901, new edges:0\n",
            "Batch 0.0, train acc:0.9371465290335336\n",
            "num_B_prime:29610, new edges:0\n",
            "Batch 1.0, train acc:0.9399043611478279\n",
            "num_B_prime:29909, new edges:0\n",
            "Batch 2.0, train acc:0.9368250220898738\n",
            "num_B_prime:29740, new edges:0\n",
            "Batch 3.0, train acc:0.9402335687272355\n",
            "num_B_prime:28975, new edges:0\n",
            "Batch 4.0, train acc:0.9353892524733823\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 430, Loss: 0.1032, Loss Cls: 0.1032, Train: 88.27%, Valid: 85.38%, Test: 87.47%\n",
            "num_B_prime:29817, new edges:0\n",
            "Batch 0.0, train acc:0.9372156918132566\n",
            "num_B_prime:29801, new edges:0\n",
            "Batch 1.0, train acc:0.9289629582488247\n",
            "num_B_prime:29615, new edges:0\n",
            "Batch 2.0, train acc:0.9334587006133599\n",
            "num_B_prime:30013, new edges:0\n",
            "Batch 3.0, train acc:0.9266100269666832\n",
            "num_B_prime:28567, new edges:0\n",
            "Batch 4.0, train acc:0.9344283615253286\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 431, Loss: 0.1099, Loss Cls: 0.1099, Train: 86.41%, Valid: 82.87%, Test: 85.13%\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 0.0, train acc:0.926381655082543\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 1.0, train acc:0.9291338372835194\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 2.0, train acc:0.9239295556807335\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 3.0, train acc:0.928297285465274\n",
            "num_B_prime:28817, new edges:0\n",
            "Batch 4.0, train acc:0.9308352884515183\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 432, Loss: 0.1199, Loss Cls: 0.1199, Train: 81.25%, Valid: 77.98%, Test: 80.51%\n",
            "num_B_prime:29546, new edges:0\n",
            "Batch 0.0, train acc:0.9312658956569214\n",
            "num_B_prime:29992, new edges:0\n",
            "Batch 1.0, train acc:0.9306237875351785\n",
            "num_B_prime:29932, new edges:0\n",
            "Batch 2.0, train acc:0.9335924837450539\n",
            "num_B_prime:29744, new edges:0\n",
            "Batch 3.0, train acc:0.9300690815327551\n",
            "num_B_prime:28800, new edges:0\n",
            "Batch 4.0, train acc:0.9350027982924928\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 433, Loss: 0.1118, Loss Cls: 0.1118, Train: 87.37%, Valid: 84.09%, Test: 86.25%\n",
            "num_B_prime:29916, new edges:0\n",
            "Batch 0.0, train acc:0.930976127795\n",
            "num_B_prime:29826, new edges:0\n",
            "Batch 1.0, train acc:0.9356918364611079\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 2.0, train acc:0.9374660067070988\n",
            "num_B_prime:29617, new edges:0\n",
            "Batch 3.0, train acc:0.9371066026335669\n",
            "num_B_prime:28798, new edges:0\n",
            "Batch 4.0, train acc:0.9392560745299954\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 434, Loss: 0.1071, Loss Cls: 0.1071, Train: 89.74%, Valid: 86.75%, Test: 88.80%\n",
            "num_B_prime:29841, new edges:0\n",
            "Batch 0.0, train acc:0.9388206520278441\n",
            "num_B_prime:30043, new edges:0\n",
            "Batch 1.0, train acc:0.9370910109519222\n",
            "num_B_prime:29685, new edges:0\n",
            "Batch 2.0, train acc:0.9385373500249508\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 3.0, train acc:0.9355473716155809\n",
            "num_B_prime:28339, new edges:0\n",
            "Batch 4.0, train acc:0.9396485444518808\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 435, Loss: 0.1046, Loss Cls: 0.1046, Train: 85.05%, Valid: 81.95%, Test: 84.17%\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 0.0, train acc:0.934753955202259\n",
            "num_B_prime:29831, new edges:0\n",
            "Batch 1.0, train acc:0.9340738262154068\n",
            "num_B_prime:29677, new edges:0\n",
            "Batch 2.0, train acc:0.9359420107773867\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 3.0, train acc:0.9336116174587147\n",
            "num_B_prime:29113, new edges:0\n",
            "Batch 4.0, train acc:0.9349065901817256\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 436, Loss: 0.1099, Loss Cls: 0.1099, Train: 86.27%, Valid: 83.14%, Test: 85.19%\n",
            "num_B_prime:29904, new edges:0\n",
            "Batch 0.0, train acc:0.9319079152109848\n",
            "num_B_prime:29749, new edges:0\n",
            "Batch 1.0, train acc:0.9317682940918228\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 2.0, train acc:0.9318311497057402\n",
            "num_B_prime:29825, new edges:0\n",
            "Batch 3.0, train acc:0.9324723101103773\n",
            "num_B_prime:28622, new edges:0\n",
            "Batch 4.0, train acc:0.9359216724823793\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 437, Loss: 0.1126, Loss Cls: 0.1126, Train: 83.61%, Valid: 80.34%, Test: 82.57%\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 0.0, train acc:0.9334780763328872\n",
            "num_B_prime:29792, new edges:0\n",
            "Batch 1.0, train acc:0.9384353436687874\n",
            "num_B_prime:29632, new edges:0\n",
            "Batch 2.0, train acc:0.9386494283923671\n",
            "num_B_prime:29827, new edges:0\n",
            "Batch 3.0, train acc:0.9425704026273243\n",
            "num_B_prime:28944, new edges:0\n",
            "Batch 4.0, train acc:0.9426189689679965\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 438, Loss: 0.1023, Loss Cls: 0.1023, Train: 90.34%, Valid: 87.34%, Test: 89.31%\n",
            "num_B_prime:29891, new edges:0\n",
            "Batch 0.0, train acc:0.9430304515654677\n",
            "num_B_prime:29805, new edges:0\n",
            "Batch 1.0, train acc:0.9410017129153819\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 2.0, train acc:0.9410525185553036\n",
            "num_B_prime:29805, new edges:0\n",
            "Batch 3.0, train acc:0.9379036927541365\n",
            "num_B_prime:28787, new edges:0\n",
            "Batch 4.0, train acc:0.9373402207481063\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 439, Loss: 0.0997, Loss Cls: 0.0997, Train: 83.67%, Valid: 80.41%, Test: 82.78%\n",
            "num_B_prime:29892, new edges:0\n",
            "Batch 0.0, train acc:0.9304471878842357\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 1.0, train acc:0.9268728371927617\n",
            "num_B_prime:29989, new edges:0\n",
            "Batch 2.0, train acc:0.9253443222396023\n",
            "num_B_prime:29665, new edges:0\n",
            "Batch 3.0, train acc:0.9237879004820443\n",
            "num_B_prime:28776, new edges:0\n",
            "Batch 4.0, train acc:0.9275129981487692\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 440, Loss: 0.1183, Loss Cls: 0.1183, Train: 84.00%, Valid: 80.62%, Test: 82.68%\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 0.0, train acc:0.9242996664395599\n",
            "num_B_prime:29942, new edges:0\n",
            "Batch 1.0, train acc:0.9282319866805478\n",
            "num_B_prime:29842, new edges:0\n",
            "Batch 2.0, train acc:0.9302150786308974\n",
            "num_B_prime:29754, new edges:0\n",
            "Batch 3.0, train acc:0.933844691790558\n",
            "num_B_prime:28595, new edges:0\n",
            "Batch 4.0, train acc:0.9359554344658616\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 441, Loss: 0.1133, Loss Cls: 0.1133, Train: 88.17%, Valid: 85.08%, Test: 87.38%\n",
            "num_B_prime:29881, new edges:0\n",
            "Batch 0.0, train acc:0.9363294665266452\n",
            "num_B_prime:29930, new edges:0\n",
            "Batch 1.0, train acc:0.9330282935757261\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 2.0, train acc:0.9308283403093942\n",
            "num_B_prime:29689, new edges:0\n",
            "Batch 3.0, train acc:0.9264210987618757\n",
            "num_B_prime:28522, new edges:0\n",
            "Batch 4.0, train acc:0.9280021546038167\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 442, Loss: 0.1152, Loss Cls: 0.1152, Train: 84.78%, Valid: 81.05%, Test: 83.33%\n",
            "num_B_prime:29974, new edges:0\n",
            "Batch 0.0, train acc:0.9214467687720322\n",
            "num_B_prime:29953, new edges:0\n",
            "Batch 1.0, train acc:0.923947679929003\n",
            "num_B_prime:29652, new edges:0\n",
            "Batch 2.0, train acc:0.9218894371460961\n",
            "num_B_prime:29634, new edges:0\n",
            "Batch 3.0, train acc:0.9247011250102574\n",
            "num_B_prime:28754, new edges:0\n",
            "Batch 4.0, train acc:0.9249347606861854\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 443, Loss: 0.1290, Loss Cls: 0.1290, Train: 76.16%, Valid: 73.14%, Test: 75.40%\n",
            "num_B_prime:29937, new edges:0\n",
            "Batch 0.0, train acc:0.9245948340252567\n",
            "num_B_prime:29710, new edges:0\n",
            "Batch 1.0, train acc:0.921481781140942\n",
            "num_B_prime:29770, new edges:0\n",
            "Batch 2.0, train acc:0.9271376205597256\n",
            "num_B_prime:29893, new edges:0\n",
            "Batch 3.0, train acc:0.9266557655221378\n",
            "num_B_prime:28734, new edges:0\n",
            "Batch 4.0, train acc:0.9361577546179124\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 444, Loss: 0.1215, Loss Cls: 0.1215, Train: 86.61%, Valid: 83.38%, Test: 85.56%\n",
            "num_B_prime:29871, new edges:0\n",
            "Batch 0.0, train acc:0.9367807074393696\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 1.0, train acc:0.9420622136628917\n",
            "num_B_prime:29689, new edges:0\n",
            "Batch 2.0, train acc:0.9437714614704492\n",
            "num_B_prime:29918, new edges:0\n",
            "Batch 3.0, train acc:0.9455172980524285\n",
            "num_B_prime:28496, new edges:0\n",
            "Batch 4.0, train acc:0.9474366399161632\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 445, Loss: 0.0974, Loss Cls: 0.0974, Train: 91.21%, Valid: 88.38%, Test: 90.30%\n",
            "num_B_prime:29658, new edges:0\n",
            "Batch 0.0, train acc:0.9479387885539969\n",
            "num_B_prime:29818, new edges:0\n",
            "Batch 1.0, train acc:0.9472929443270521\n",
            "num_B_prime:29947, new edges:0\n",
            "Batch 2.0, train acc:0.9464138432487573\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 3.0, train acc:0.9449413098981868\n",
            "num_B_prime:28479, new edges:0\n",
            "Batch 4.0, train acc:0.9478193232957387\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 446, Loss: 0.0928, Loss Cls: 0.0928, Train: 91.26%, Valid: 88.37%, Test: 90.36%\n",
            "num_B_prime:29652, new edges:0\n",
            "Batch 0.0, train acc:0.9454035787400448\n",
            "num_B_prime:29895, new edges:0\n",
            "Batch 1.0, train acc:0.9454410511334673\n",
            "num_B_prime:29961, new edges:0\n",
            "Batch 2.0, train acc:0.9438168550797933\n",
            "num_B_prime:29866, new edges:0\n",
            "Batch 3.0, train acc:0.9436801925564753\n",
            "num_B_prime:28949, new edges:0\n",
            "Batch 4.0, train acc:0.9448872127941895\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 447, Loss: 0.0950, Loss Cls: 0.0950, Train: 89.05%, Valid: 86.05%, Test: 88.11%\n",
            "num_B_prime:29769, new edges:0\n",
            "Batch 0.0, train acc:0.9397029817057878\n",
            "num_B_prime:29773, new edges:0\n",
            "Batch 1.0, train acc:0.9391227948486739\n",
            "num_B_prime:29853, new edges:0\n",
            "Batch 2.0, train acc:0.9382856895684757\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 3.0, train acc:0.935561198800324\n",
            "num_B_prime:28615, new edges:0\n",
            "Batch 4.0, train acc:0.9338504216293801\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 448, Loss: 0.1043, Loss Cls: 0.1043, Train: 87.00%, Valid: 83.96%, Test: 86.07%\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 0.0, train acc:0.9310638831934367\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 1.0, train acc:0.9294839599665891\n",
            "num_B_prime:29791, new edges:0\n",
            "Batch 2.0, train acc:0.9282275069017238\n",
            "num_B_prime:29731, new edges:0\n",
            "Batch 3.0, train acc:0.9288146072214473\n",
            "num_B_prime:28729, new edges:0\n",
            "Batch 4.0, train acc:0.9296672278619571\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 449, Loss: 0.1140, Loss Cls: 0.1140, Train: 81.79%, Valid: 78.25%, Test: 80.49%\n",
            "num_B_prime:29708, new edges:0\n",
            "Batch 0.0, train acc:0.9283051772297752\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 1.0, train acc:0.9258234029092037\n",
            "num_B_prime:30019, new edges:0\n",
            "Batch 2.0, train acc:0.9253604715629854\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 3.0, train acc:0.9255898662607372\n",
            "num_B_prime:28623, new edges:0\n",
            "Batch 4.0, train acc:0.9321807005776964\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 450, Loss: 0.1193, Loss Cls: 0.1193, Train: 86.98%, Valid: 84.00%, Test: 86.23%\n",
            "num_B_prime:29644, new edges:0\n",
            "Batch 0.0, train acc:0.933419689119171\n",
            "num_B_prime:29942, new edges:0\n",
            "Batch 1.0, train acc:0.9404445768530242\n",
            "num_B_prime:29915, new edges:0\n",
            "Batch 2.0, train acc:0.9392471501599191\n",
            "num_B_prime:29784, new edges:0\n",
            "Batch 3.0, train acc:0.9418069423726231\n",
            "num_B_prime:28965, new edges:0\n",
            "Batch 4.0, train acc:0.9378145417623168\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 451, Loss: 0.1024, Loss Cls: 0.1024, Train: 89.07%, Valid: 85.90%, Test: 88.05%\n",
            "num_B_prime:29697, new edges:0\n",
            "Batch 0.0, train acc:0.9374976896885495\n",
            "num_B_prime:29741, new edges:0\n",
            "Batch 1.0, train acc:0.9383152558230616\n",
            "num_B_prime:29876, new edges:0\n",
            "Batch 2.0, train acc:0.9378785238115986\n",
            "num_B_prime:30045, new edges:0\n",
            "Batch 3.0, train acc:0.9358746188947374\n",
            "num_B_prime:28457, new edges:0\n",
            "Batch 4.0, train acc:0.9402619875564179\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 452, Loss: 0.1030, Loss Cls: 0.1030, Train: 87.09%, Valid: 83.75%, Test: 86.06%\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 0.0, train acc:0.9361595618597149\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 1.0, train acc:0.9356155017474471\n",
            "num_B_prime:29668, new edges:0\n",
            "Batch 2.0, train acc:0.9375905782461358\n",
            "num_B_prime:29998, new edges:0\n",
            "Batch 3.0, train acc:0.9341679543637396\n",
            "num_B_prime:28795, new edges:0\n",
            "Batch 4.0, train acc:0.9444735661750799\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 453, Loss: 0.1025, Loss Cls: 0.1025, Train: 89.63%, Valid: 86.52%, Test: 88.67%\n",
            "num_B_prime:29796, new edges:0\n",
            "Batch 0.0, train acc:0.9363887170996903\n",
            "num_B_prime:29852, new edges:0\n",
            "Batch 1.0, train acc:0.9399009424979057\n",
            "num_B_prime:29842, new edges:0\n",
            "Batch 2.0, train acc:0.9347516720224452\n",
            "num_B_prime:29755, new edges:0\n",
            "Batch 3.0, train acc:0.9398089709945026\n",
            "num_B_prime:29123, new edges:0\n",
            "Batch 4.0, train acc:0.9374770468554899\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 454, Loss: 0.1009, Loss Cls: 0.1009, Train: 85.47%, Valid: 82.19%, Test: 84.59%\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 0.0, train acc:0.9388401543361129\n",
            "num_B_prime:29736, new edges:0\n",
            "Batch 1.0, train acc:0.9325954602469485\n",
            "num_B_prime:29914, new edges:0\n",
            "Batch 2.0, train acc:0.9356653688729161\n",
            "num_B_prime:29844, new edges:0\n",
            "Batch 3.0, train acc:0.9290817783535672\n",
            "num_B_prime:28753, new edges:0\n",
            "Batch 4.0, train acc:0.9378679447617796\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 455, Loss: 0.1057, Loss Cls: 0.1057, Train: 85.89%, Valid: 82.41%, Test: 84.52%\n",
            "num_B_prime:30025, new edges:0\n",
            "Batch 0.0, train acc:0.9316802141553259\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 1.0, train acc:0.934411360402258\n",
            "num_B_prime:29808, new edges:0\n",
            "Batch 2.0, train acc:0.9315067740628584\n",
            "num_B_prime:29743, new edges:0\n",
            "Batch 3.0, train acc:0.934258860419136\n",
            "num_B_prime:28359, new edges:0\n",
            "Batch 4.0, train acc:0.9331355917894109\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 456, Loss: 0.1082, Loss Cls: 0.1082, Train: 77.40%, Valid: 73.87%, Test: 76.40%\n",
            "num_B_prime:29785, new edges:0\n",
            "Batch 0.0, train acc:0.9332336761059742\n",
            "num_B_prime:29904, new edges:0\n",
            "Batch 1.0, train acc:0.9323706682130872\n",
            "num_B_prime:29907, new edges:0\n",
            "Batch 2.0, train acc:0.9343213048565071\n",
            "num_B_prime:29891, new edges:0\n",
            "Batch 3.0, train acc:0.9348777117251192\n",
            "num_B_prime:28651, new edges:0\n",
            "Batch 4.0, train acc:0.9357178025719556\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 457, Loss: 0.1083, Loss Cls: 0.1083, Train: 83.94%, Valid: 80.75%, Test: 82.85%\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 0.0, train acc:0.9327636081443607\n",
            "num_B_prime:29539, new edges:0\n",
            "Batch 1.0, train acc:0.9321005895203281\n",
            "num_B_prime:30024, new edges:0\n",
            "Batch 2.0, train acc:0.9288112333668244\n",
            "num_B_prime:29869, new edges:0\n",
            "Batch 3.0, train acc:0.9302162264078763\n",
            "num_B_prime:28587, new edges:0\n",
            "Batch 4.0, train acc:0.933818681470893\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 458, Loss: 0.1115, Loss Cls: 0.1115, Train: 85.49%, Valid: 82.39%, Test: 84.45%\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 0.0, train acc:0.9337406974307672\n",
            "num_B_prime:29814, new edges:0\n",
            "Batch 1.0, train acc:0.9350454829234205\n",
            "num_B_prime:29839, new edges:0\n",
            "Batch 2.0, train acc:0.9368516043607076\n",
            "num_B_prime:29813, new edges:0\n",
            "Batch 3.0, train acc:0.9391928193154598\n",
            "num_B_prime:28581, new edges:0\n",
            "Batch 4.0, train acc:0.9415415895966\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 459, Loss: 0.1034, Loss Cls: 0.1034, Train: 88.42%, Valid: 85.47%, Test: 87.59%\n",
            "num_B_prime:29899, new edges:0\n",
            "Batch 0.0, train acc:0.9402477260314613\n",
            "num_B_prime:29689, new edges:0\n",
            "Batch 1.0, train acc:0.9386822359317024\n",
            "num_B_prime:29948, new edges:0\n",
            "Batch 2.0, train acc:0.9427843341136285\n",
            "num_B_prime:29840, new edges:0\n",
            "Batch 3.0, train acc:0.9413640908226755\n",
            "num_B_prime:28557, new edges:0\n",
            "Batch 4.0, train acc:0.94546515973626\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 460, Loss: 0.0984, Loss Cls: 0.0984, Train: 90.35%, Valid: 87.34%, Test: 89.40%\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 0.0, train acc:0.9418524376590052\n",
            "num_B_prime:29909, new edges:0\n",
            "Batch 1.0, train acc:0.9393835551754004\n",
            "num_B_prime:29570, new edges:0\n",
            "Batch 2.0, train acc:0.9394730337902619\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 3.0, train acc:0.9398390745354065\n",
            "num_B_prime:28498, new edges:0\n",
            "Batch 4.0, train acc:0.9399880803911397\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 461, Loss: 0.1008, Loss Cls: 0.1008, Train: 89.03%, Valid: 86.06%, Test: 88.18%\n",
            "num_B_prime:29752, new edges:0\n",
            "Batch 0.0, train acc:0.9388635812286046\n",
            "num_B_prime:29686, new edges:0\n",
            "Batch 1.0, train acc:0.9376551663929372\n",
            "num_B_prime:29941, new edges:0\n",
            "Batch 2.0, train acc:0.9356594784523478\n",
            "num_B_prime:29599, new edges:0\n",
            "Batch 3.0, train acc:0.934585935319326\n",
            "num_B_prime:29163, new edges:0\n",
            "Batch 4.0, train acc:0.9355242378373654\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 462, Loss: 0.1046, Loss Cls: 0.1046, Train: 84.85%, Valid: 81.41%, Test: 83.59%\n",
            "num_B_prime:29651, new edges:0\n",
            "Batch 0.0, train acc:0.9298227493021144\n",
            "num_B_prime:29674, new edges:0\n",
            "Batch 1.0, train acc:0.927851209872176\n",
            "num_B_prime:29874, new edges:0\n",
            "Batch 2.0, train acc:0.9301630457035697\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 3.0, train acc:0.9314947683711976\n",
            "num_B_prime:28880, new edges:0\n",
            "Batch 4.0, train acc:0.9327522106812058\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 463, Loss: 0.1120, Loss Cls: 0.1120, Train: 81.25%, Valid: 77.57%, Test: 79.88%\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 0.0, train acc:0.9333948623288725\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 1.0, train acc:0.9334595632807072\n",
            "num_B_prime:29920, new edges:0\n",
            "Batch 2.0, train acc:0.9363340555190406\n",
            "num_B_prime:29640, new edges:0\n",
            "Batch 3.0, train acc:0.9360355890764512\n",
            "num_B_prime:29017, new edges:0\n",
            "Batch 4.0, train acc:0.9396959005284155\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 464, Loss: 0.1059, Loss Cls: 0.1059, Train: 87.68%, Valid: 84.49%, Test: 86.56%\n",
            "num_B_prime:29706, new edges:0\n",
            "Batch 0.0, train acc:0.9387691924152206\n",
            "num_B_prime:29727, new edges:0\n",
            "Batch 1.0, train acc:0.9430169739545506\n",
            "num_B_prime:30154, new edges:0\n",
            "Batch 2.0, train acc:0.9414685017220797\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 3.0, train acc:0.941929290457835\n",
            "num_B_prime:28492, new edges:0\n",
            "Batch 4.0, train acc:0.9429862312439856\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 465, Loss: 0.0977, Loss Cls: 0.0977, Train: 84.91%, Valid: 81.64%, Test: 84.00%\n",
            "num_B_prime:29639, new edges:0\n",
            "Batch 0.0, train acc:0.940002341293282\n",
            "num_B_prime:30104, new edges:0\n",
            "Batch 1.0, train acc:0.9329662930358666\n",
            "num_B_prime:29813, new edges:0\n",
            "Batch 2.0, train acc:0.9344888146410939\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 3.0, train acc:0.9289749035621413\n",
            "num_B_prime:28589, new edges:0\n",
            "Batch 4.0, train acc:0.9329524577920484\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 466, Loss: 0.1071, Loss Cls: 0.1071, Train: 84.03%, Valid: 80.64%, Test: 82.67%\n",
            "num_B_prime:29855, new edges:0\n",
            "Batch 0.0, train acc:0.9243182929220672\n",
            "num_B_prime:29757, new edges:0\n",
            "Batch 1.0, train acc:0.9292484201322188\n",
            "num_B_prime:29669, new edges:0\n",
            "Batch 2.0, train acc:0.9227173479340308\n",
            "num_B_prime:29791, new edges:0\n",
            "Batch 3.0, train acc:0.9277522413261682\n",
            "num_B_prime:28922, new edges:0\n",
            "Batch 4.0, train acc:0.9268422287356874\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 467, Loss: 0.1188, Loss Cls: 0.1188, Train: 76.30%, Valid: 73.29%, Test: 75.44%\n",
            "num_B_prime:29987, new edges:0\n",
            "Batch 0.0, train acc:0.9277230645377701\n",
            "num_B_prime:29587, new edges:0\n",
            "Batch 1.0, train acc:0.9248821588094438\n",
            "num_B_prime:29985, new edges:0\n",
            "Batch 2.0, train acc:0.9275542661024487\n",
            "num_B_prime:29680, new edges:0\n",
            "Batch 3.0, train acc:0.9325019234211889\n",
            "num_B_prime:28552, new edges:0\n",
            "Batch 4.0, train acc:0.939179891244035\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 468, Loss: 0.1169, Loss Cls: 0.1169, Train: 87.80%, Valid: 84.47%, Test: 86.65%\n",
            "num_B_prime:29989, new edges:0\n",
            "Batch 0.0, train acc:0.9389885401433192\n",
            "num_B_prime:29679, new edges:0\n",
            "Batch 1.0, train acc:0.941193361674431\n",
            "num_B_prime:29908, new edges:0\n",
            "Batch 2.0, train acc:0.9435103416693538\n",
            "num_B_prime:29835, new edges:0\n",
            "Batch 3.0, train acc:0.9433039984563951\n",
            "num_B_prime:28406, new edges:0\n",
            "Batch 4.0, train acc:0.948313074463376\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 469, Loss: 0.0966, Loss Cls: 0.0966, Train: 90.06%, Valid: 87.05%, Test: 89.03%\n",
            "num_B_prime:30097, new edges:0\n",
            "Batch 0.0, train acc:0.9466426176586883\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 1.0, train acc:0.9442524700952528\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 2.0, train acc:0.9451185965922752\n",
            "num_B_prime:29554, new edges:0\n",
            "Batch 3.0, train acc:0.94506634794301\n",
            "num_B_prime:28647, new edges:0\n",
            "Batch 4.0, train acc:0.9457431465390057\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 470, Loss: 0.0935, Loss Cls: 0.0935, Train: 90.19%, Valid: 87.12%, Test: 89.29%\n",
            "num_B_prime:29910, new edges:0\n",
            "Batch 0.0, train acc:0.9431523326224054\n",
            "num_B_prime:29855, new edges:0\n",
            "Batch 1.0, train acc:0.9416331165479508\n",
            "num_B_prime:29665, new edges:0\n",
            "Batch 2.0, train acc:0.9417177050617488\n",
            "num_B_prime:29829, new edges:0\n",
            "Batch 3.0, train acc:0.9392136819504825\n",
            "num_B_prime:28597, new edges:0\n",
            "Batch 4.0, train acc:0.9429618772330628\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 471, Loss: 0.0976, Loss Cls: 0.0976, Train: 88.23%, Valid: 85.05%, Test: 87.31%\n",
            "num_B_prime:29657, new edges:0\n",
            "Batch 0.0, train acc:0.9377195880415248\n",
            "num_B_prime:29889, new edges:0\n",
            "Batch 1.0, train acc:0.9371128699242945\n",
            "num_B_prime:29845, new edges:0\n",
            "Batch 2.0, train acc:0.933871480397637\n",
            "num_B_prime:29808, new edges:0\n",
            "Batch 3.0, train acc:0.934607326176998\n",
            "num_B_prime:28642, new edges:0\n",
            "Batch 4.0, train acc:0.9338401893157444\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 472, Loss: 0.1048, Loss Cls: 0.1048, Train: 87.41%, Valid: 84.30%, Test: 86.44%\n",
            "num_B_prime:29748, new edges:0\n",
            "Batch 0.0, train acc:0.9357908236040643\n",
            "num_B_prime:29685, new edges:0\n",
            "Batch 1.0, train acc:0.9322818618386477\n",
            "num_B_prime:30071, new edges:0\n",
            "Batch 2.0, train acc:0.9373466317311069\n",
            "num_B_prime:29913, new edges:0\n",
            "Batch 3.0, train acc:0.9352255776838853\n",
            "num_B_prime:28679, new edges:0\n",
            "Batch 4.0, train acc:0.9424116463628194\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 473, Loss: 0.1044, Loss Cls: 0.1044, Train: 87.69%, Valid: 84.63%, Test: 86.71%\n",
            "num_B_prime:29898, new edges:0\n",
            "Batch 0.0, train acc:0.9349049302115854\n",
            "num_B_prime:29675, new edges:0\n",
            "Batch 1.0, train acc:0.9397244361266175\n",
            "num_B_prime:29799, new edges:0\n",
            "Batch 2.0, train acc:0.9363647279713563\n",
            "num_B_prime:29917, new edges:0\n",
            "Batch 3.0, train acc:0.9368712593052947\n",
            "num_B_prime:28867, new edges:0\n",
            "Batch 4.0, train acc:0.9370994606930917\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 474, Loss: 0.1048, Loss Cls: 0.1048, Train: 82.23%, Valid: 78.92%, Test: 81.09%\n",
            "num_B_prime:29955, new edges:0\n",
            "Batch 0.0, train acc:0.9337853058974929\n",
            "num_B_prime:29880, new edges:0\n",
            "Batch 1.0, train acc:0.9276988261672381\n",
            "num_B_prime:29900, new edges:0\n",
            "Batch 2.0, train acc:0.9270945923321614\n",
            "num_B_prime:29594, new edges:0\n",
            "Batch 3.0, train acc:0.9265649241332263\n",
            "num_B_prime:28591, new edges:0\n",
            "Batch 4.0, train acc:0.9313324939872885\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 475, Loss: 0.1205, Loss Cls: 0.1205, Train: 85.80%, Valid: 82.78%, Test: 84.74%\n",
            "num_B_prime:29819, new edges:0\n",
            "Batch 0.0, train acc:0.9244395020102926\n",
            "num_B_prime:29887, new edges:0\n",
            "Batch 1.0, train acc:0.9299570110936944\n",
            "num_B_prime:29782, new edges:0\n",
            "Batch 2.0, train acc:0.9323023317260057\n",
            "num_B_prime:29902, new edges:0\n",
            "Batch 3.0, train acc:0.9386399317084468\n",
            "num_B_prime:28512, new edges:0\n",
            "Batch 4.0, train acc:0.9392450050329249\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 476, Loss: 0.1105, Loss Cls: 0.1105, Train: 88.37%, Valid: 85.28%, Test: 87.53%\n",
            "num_B_prime:29946, new edges:0\n",
            "Batch 0.0, train acc:0.94074686326465\n",
            "num_B_prime:29884, new edges:0\n",
            "Batch 1.0, train acc:0.934968827474315\n",
            "num_B_prime:29610, new edges:0\n",
            "Batch 2.0, train acc:0.9385306981361218\n",
            "num_B_prime:29893, new edges:0\n",
            "Batch 3.0, train acc:0.9309624865905954\n",
            "num_B_prime:28666, new edges:0\n",
            "Batch 4.0, train acc:0.9365825176404488\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 477, Loss: 0.1043, Loss Cls: 0.1043, Train: 88.64%, Valid: 85.47%, Test: 87.64%\n",
            "num_B_prime:29939, new edges:0\n",
            "Batch 0.0, train acc:0.9287896405339885\n",
            "num_B_prime:29793, new edges:0\n",
            "Batch 1.0, train acc:0.9332288753295508\n",
            "num_B_prime:29618, new edges:0\n",
            "Batch 2.0, train acc:0.9299228612079665\n",
            "num_B_prime:29742, new edges:0\n",
            "Batch 3.0, train acc:0.9321150447738609\n",
            "num_B_prime:29115, new edges:0\n",
            "Batch 4.0, train acc:0.931401172322411\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 478, Loss: 0.1119, Loss Cls: 0.1119, Train: 84.17%, Valid: 80.88%, Test: 83.27%\n",
            "num_B_prime:29826, new edges:0\n",
            "Batch 0.0, train acc:0.9330716988547124\n",
            "num_B_prime:29833, new edges:0\n",
            "Batch 1.0, train acc:0.9353038332595012\n",
            "num_B_prime:29663, new edges:0\n",
            "Batch 2.0, train acc:0.9420511534939963\n",
            "num_B_prime:29792, new edges:0\n",
            "Batch 3.0, train acc:0.9410508668026465\n",
            "num_B_prime:28646, new edges:0\n",
            "Batch 4.0, train acc:0.9466400619681454\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 479, Loss: 0.1011, Loss Cls: 0.1011, Train: 88.41%, Valid: 85.13%, Test: 87.33%\n",
            "num_B_prime:29903, new edges:0\n",
            "Batch 0.0, train acc:0.9416686451570649\n",
            "num_B_prime:29596, new edges:0\n",
            "Batch 1.0, train acc:0.942115314905888\n",
            "num_B_prime:29794, new edges:0\n",
            "Batch 2.0, train acc:0.9414997950498345\n",
            "num_B_prime:29902, new edges:0\n",
            "Batch 3.0, train acc:0.9422070200285931\n",
            "num_B_prime:28976, new edges:0\n",
            "Batch 4.0, train acc:0.9403825717321999\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 480, Loss: 0.0982, Loss Cls: 0.0982, Train: 82.91%, Valid: 79.71%, Test: 81.80%\n",
            "num_B_prime:29863, new edges:0\n",
            "Batch 0.0, train acc:0.9379857421859302\n",
            "num_B_prime:29936, new edges:0\n",
            "Batch 1.0, train acc:0.9324755040136843\n",
            "num_B_prime:29600, new edges:0\n",
            "Batch 2.0, train acc:0.9325039692853402\n",
            "num_B_prime:29879, new edges:0\n",
            "Batch 3.0, train acc:0.9327462911054898\n",
            "num_B_prime:28975, new edges:0\n",
            "Batch 4.0, train acc:0.936890561620118\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 481, Loss: 0.1078, Loss Cls: 0.1078, Train: 84.91%, Valid: 81.52%, Test: 83.75%\n",
            "num_B_prime:29807, new edges:0\n",
            "Batch 0.0, train acc:0.935483428144699\n",
            "num_B_prime:29764, new edges:0\n",
            "Batch 1.0, train acc:0.9362688792463679\n",
            "num_B_prime:29902, new edges:0\n",
            "Batch 2.0, train acc:0.9357970260426651\n",
            "num_B_prime:29867, new edges:0\n",
            "Batch 3.0, train acc:0.934926803532141\n",
            "num_B_prime:28675, new edges:0\n",
            "Batch 4.0, train acc:0.9396712949063656\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 482, Loss: 0.1056, Loss Cls: 0.1056, Train: 83.83%, Valid: 80.43%, Test: 82.71%\n",
            "num_B_prime:29663, new edges:0\n",
            "Batch 0.0, train acc:0.9376994041512273\n",
            "num_B_prime:29566, new edges:0\n",
            "Batch 1.0, train acc:0.9386058047116986\n",
            "num_B_prime:30023, new edges:0\n",
            "Batch 2.0, train acc:0.9402194760150967\n",
            "num_B_prime:29729, new edges:0\n",
            "Batch 3.0, train acc:0.9382792647835396\n",
            "num_B_prime:28887, new edges:0\n",
            "Batch 4.0, train acc:0.9427440531991294\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 483, Loss: 0.1007, Loss Cls: 0.1007, Train: 88.64%, Valid: 85.40%, Test: 87.62%\n",
            "num_B_prime:29802, new edges:0\n",
            "Batch 0.0, train acc:0.9400131551295453\n",
            "num_B_prime:29657, new edges:0\n",
            "Batch 1.0, train acc:0.9402902521325881\n",
            "num_B_prime:29719, new edges:0\n",
            "Batch 2.0, train acc:0.9421999195157984\n",
            "num_B_prime:29879, new edges:0\n",
            "Batch 3.0, train acc:0.9413393273583456\n",
            "num_B_prime:29045, new edges:0\n",
            "Batch 4.0, train acc:0.9437515907355561\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 484, Loss: 0.0976, Loss Cls: 0.0976, Train: 89.65%, Valid: 86.55%, Test: 88.73%\n",
            "num_B_prime:29701, new edges:0\n",
            "Batch 0.0, train acc:0.9439444236696201\n",
            "num_B_prime:29967, new edges:0\n",
            "Batch 1.0, train acc:0.9427425835012461\n",
            "num_B_prime:29759, new edges:0\n",
            "Batch 2.0, train acc:0.9442288360274183\n",
            "num_B_prime:29754, new edges:0\n",
            "Batch 3.0, train acc:0.9427969972377424\n",
            "num_B_prime:28831, new edges:0\n",
            "Batch 4.0, train acc:0.9454922153499283\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 485, Loss: 0.0947, Loss Cls: 0.0947, Train: 89.56%, Valid: 86.57%, Test: 88.56%\n",
            "num_B_prime:29722, new edges:0\n",
            "Batch 0.0, train acc:0.9434562054315879\n",
            "num_B_prime:29819, new edges:0\n",
            "Batch 1.0, train acc:0.9403537874519637\n",
            "num_B_prime:29671, new edges:0\n",
            "Batch 2.0, train acc:0.9436373730128821\n",
            "num_B_prime:29971, new edges:0\n",
            "Batch 3.0, train acc:0.9394079240202838\n",
            "num_B_prime:28652, new edges:0\n",
            "Batch 4.0, train acc:0.9442821426789585\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 486, Loss: 0.0968, Loss Cls: 0.0968, Train: 88.92%, Valid: 85.86%, Test: 87.95%\n",
            "num_B_prime:29939, new edges:0\n",
            "Batch 0.0, train acc:0.9382234141892332\n",
            "num_B_prime:29774, new edges:0\n",
            "Batch 1.0, train acc:0.9368535803580629\n",
            "num_B_prime:29808, new edges:0\n",
            "Batch 2.0, train acc:0.9330529973841061\n",
            "num_B_prime:29761, new edges:0\n",
            "Batch 3.0, train acc:0.9299745719613494\n",
            "num_B_prime:28745, new edges:0\n",
            "Batch 4.0, train acc:0.927058396209282\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 487, Loss: 0.1118, Loss Cls: 0.1118, Train: 84.96%, Valid: 82.09%, Test: 84.07%\n",
            "num_B_prime:29795, new edges:0\n",
            "Batch 0.0, train acc:0.9239773503592674\n",
            "num_B_prime:29648, new edges:0\n",
            "Batch 1.0, train acc:0.923946480201943\n",
            "num_B_prime:29711, new edges:0\n",
            "Batch 2.0, train acc:0.9297069236261748\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 3.0, train acc:0.9310633608214238\n",
            "num_B_prime:29095, new edges:0\n",
            "Batch 4.0, train acc:0.9385640923257799\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 488, Loss: 0.1171, Loss Cls: 0.1171, Train: 86.34%, Valid: 83.13%, Test: 85.26%\n",
            "num_B_prime:29933, new edges:0\n",
            "Batch 0.0, train acc:0.9345596452279871\n",
            "num_B_prime:29699, new edges:0\n",
            "Batch 1.0, train acc:0.9385942315343687\n",
            "num_B_prime:29874, new edges:0\n",
            "Batch 2.0, train acc:0.9368370265801054\n",
            "num_B_prime:29769, new edges:0\n",
            "Batch 3.0, train acc:0.9411735896082412\n",
            "num_B_prime:28698, new edges:0\n",
            "Batch 4.0, train acc:0.944909288993658\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 489, Loss: 0.1007, Loss Cls: 0.1007, Train: 88.86%, Valid: 85.70%, Test: 87.88%\n",
            "num_B_prime:29809, new edges:0\n",
            "Batch 0.0, train acc:0.9448646865489629\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 1.0, train acc:0.9448130708247903\n",
            "num_B_prime:29750, new edges:0\n",
            "Batch 2.0, train acc:0.94516446034196\n",
            "num_B_prime:29906, new edges:0\n",
            "Batch 3.0, train acc:0.9442329581039206\n",
            "num_B_prime:28848, new edges:0\n",
            "Batch 4.0, train acc:0.9490139595507094\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 490, Loss: 0.0929, Loss Cls: 0.0929, Train: 90.35%, Valid: 87.15%, Test: 89.31%\n",
            "num_B_prime:29823, new edges:0\n",
            "Batch 0.0, train acc:0.9447748582642826\n",
            "num_B_prime:29822, new edges:0\n",
            "Batch 1.0, train acc:0.9481665887863017\n",
            "num_B_prime:29983, new edges:0\n",
            "Batch 2.0, train acc:0.9445375046020625\n",
            "num_B_prime:29773, new edges:0\n",
            "Batch 3.0, train acc:0.9447382571348838\n",
            "num_B_prime:28810, new edges:0\n",
            "Batch 4.0, train acc:0.9459251098234135\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 491, Loss: 0.0926, Loss Cls: 0.0926, Train: 86.97%, Valid: 83.49%, Test: 85.82%\n",
            "num_B_prime:29743, new edges:0\n",
            "Batch 0.0, train acc:0.9440253758815936\n",
            "num_B_prime:29679, new edges:0\n",
            "Batch 1.0, train acc:0.9401814281184759\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 2.0, train acc:0.9390050870843303\n",
            "num_B_prime:29936, new edges:0\n",
            "Batch 3.0, train acc:0.9371045282738196\n",
            "num_B_prime:28881, new edges:0\n",
            "Batch 4.0, train acc:0.9393875746186159\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 492, Loss: 0.0997, Loss Cls: 0.0997, Train: 85.27%, Valid: 81.89%, Test: 84.07%\n",
            "num_B_prime:29787, new edges:0\n",
            "Batch 0.0, train acc:0.9323764156080103\n",
            "num_B_prime:29778, new edges:0\n",
            "Batch 1.0, train acc:0.932410485701986\n",
            "num_B_prime:29790, new edges:0\n",
            "Batch 2.0, train acc:0.9321624292269115\n",
            "num_B_prime:30030, new edges:0\n",
            "Batch 3.0, train acc:0.9326231712629833\n",
            "num_B_prime:28523, new edges:0\n",
            "Batch 4.0, train acc:0.9310772299403566\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 493, Loss: 0.1086, Loss Cls: 0.1086, Train: 70.19%, Valid: 66.16%, Test: 69.10%\n",
            "num_B_prime:29845, new edges:0\n",
            "Batch 0.0, train acc:0.9270185065244181\n",
            "num_B_prime:29816, new edges:0\n",
            "Batch 1.0, train acc:0.9227572891792095\n",
            "num_B_prime:29762, new edges:0\n",
            "Batch 2.0, train acc:0.9225144180217305\n",
            "num_B_prime:29864, new edges:0\n",
            "Batch 3.0, train acc:0.9213583864850888\n",
            "num_B_prime:28680, new edges:0\n",
            "Batch 4.0, train acc:0.9301036731891521\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 494, Loss: 0.1216, Loss Cls: 0.1216, Train: 84.45%, Valid: 80.76%, Test: 82.92%\n",
            "num_B_prime:29693, new edges:0\n",
            "Batch 0.0, train acc:0.9277758814331961\n",
            "num_B_prime:29771, new edges:0\n",
            "Batch 1.0, train acc:0.9334681717404282\n",
            "num_B_prime:29732, new edges:0\n",
            "Batch 2.0, train acc:0.9328107966384699\n",
            "num_B_prime:29998, new edges:0\n",
            "Batch 3.0, train acc:0.9346357977888669\n",
            "num_B_prime:28790, new edges:0\n",
            "Batch 4.0, train acc:0.9370296655924097\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 495, Loss: 0.1092, Loss Cls: 0.1092, Train: 84.91%, Valid: 81.79%, Test: 83.97%\n",
            "num_B_prime:29708, new edges:0\n",
            "Batch 0.0, train acc:0.9349321790024947\n",
            "num_B_prime:29837, new edges:0\n",
            "Batch 1.0, train acc:0.9380779963561725\n",
            "num_B_prime:29966, new edges:0\n",
            "Batch 2.0, train acc:0.9376505597279297\n",
            "num_B_prime:29860, new edges:0\n",
            "Batch 3.0, train acc:0.9384518749949017\n",
            "num_B_prime:28861, new edges:0\n",
            "Batch 4.0, train acc:0.9431093808589011\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 496, Loss: 0.1020, Loss Cls: 0.1020, Train: 89.11%, Valid: 85.88%, Test: 88.04%\n",
            "num_B_prime:29765, new edges:0\n",
            "Batch 0.0, train acc:0.9414421038021199\n",
            "num_B_prime:29962, new edges:0\n",
            "Batch 1.0, train acc:0.9422964911928337\n",
            "num_B_prime:29443, new edges:0\n",
            "Batch 2.0, train acc:0.9425717021753452\n",
            "num_B_prime:29994, new edges:0\n",
            "Batch 3.0, train acc:0.9379436834218995\n",
            "num_B_prime:29005, new edges:0\n",
            "Batch 4.0, train acc:0.9431359956782144\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 497, Loss: 0.0986, Loss Cls: 0.0986, Train: 85.90%, Valid: 82.90%, Test: 84.96%\n",
            "num_B_prime:29806, new edges:0\n",
            "Batch 0.0, train acc:0.9376443418013858\n",
            "num_B_prime:29798, new edges:0\n",
            "Batch 1.0, train acc:0.9352735472906726\n",
            "num_B_prime:29985, new edges:0\n",
            "Batch 2.0, train acc:0.9385117189445613\n",
            "num_B_prime:29576, new edges:0\n",
            "Batch 3.0, train acc:0.9384767459908994\n",
            "num_B_prime:28820, new edges:0\n",
            "Batch 4.0, train acc:0.9423872643782577\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 498, Loss: 0.1034, Loss Cls: 0.1034, Train: 87.88%, Valid: 84.63%, Test: 86.73%\n",
            "num_B_prime:29739, new edges:0\n",
            "Batch 0.0, train acc:0.9408479573829072\n",
            "num_B_prime:29743, new edges:0\n",
            "Batch 1.0, train acc:0.9444833982488351\n",
            "num_B_prime:29749, new edges:0\n",
            "Batch 2.0, train acc:0.9448115501395546\n",
            "num_B_prime:29988, new edges:0\n",
            "Batch 3.0, train acc:0.944863781345866\n",
            "num_B_prime:28596, new edges:0\n",
            "Batch 4.0, train acc:0.9478750861002996\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 499, Loss: 0.0936, Loss Cls: 0.0936, Train: 89.42%, Valid: 86.52%, Test: 88.58%\n",
            "num_B_prime:29893, new edges:0\n",
            "Batch 0.0, train acc:0.9456505671993979\n",
            "num_B_prime:29612, new edges:0\n",
            "Batch 1.0, train acc:0.9477549558959919\n",
            "num_B_prime:29976, new edges:0\n",
            "Batch 2.0, train acc:0.9449932921994727\n",
            "num_B_prime:29676, new edges:0\n",
            "Batch 3.0, train acc:0.94529397577955\n",
            "num_B_prime:28629, new edges:0\n",
            "Batch 4.0, train acc:0.94513010402155\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 500, Loss: 0.0922, Loss Cls: 0.0922, Train: 89.03%, Valid: 86.10%, Test: 88.11%\n",
            "num_B_prime:29721, new edges:0\n",
            "Batch 0.0, train acc:0.9426775616208805\n",
            "num_B_prime:29660, new edges:0\n",
            "Batch 1.0, train acc:0.9401152413899477\n",
            "num_B_prime:29751, new edges:0\n",
            "Batch 2.0, train acc:0.9412041134825626\n",
            "Traceback (most recent call last):\n",
            "  File \"main_node.py\", line 311, in <module>\n",
            "    main()\n",
            "  File \"main_node.py\", line 259, in main\n",
            "    train(model, data, args.batch_size, train_bool, optimizer, device, args.commitment_cost,\n",
            "  File \"main_node.py\", line 57, in train\n",
            "    for i, batches in enumerate(loader) :\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 561, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/content/pruning-quantization/VQ-GNN/vq_gnn_v2/dataloader.py\", line 94, in __collate__\n",
            "    result_list.append((self._k_hop_subgraph(node_idx), node_idx))\n",
            "  File \"/content/pruning-quantization/VQ-GNN/vq_gnn_v2/dataloader.py\", line 119, in _k_hop_subgraph\n",
            "    subset, inv = torch.cat(subsets).unique(return_inverse=True, sorted=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 527, in unique\n",
            "    return torch.unique(self, sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py\", line 403, in fn\n",
            "    return if_true(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py\", line 405, in fn\n",
            "    return if_false(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/functional.py\", line 732, in _return_inverse\n",
            "    output, inverse_indices, _ = _unique_impl(input, sorted, return_inverse, return_counts, dim)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/functional.py\", line 636, in _unique_impl\n",
            "    output, inverse_indices, counts = torch._unique2(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd pruning-quantization && python VQ-GNN/vq_gnn_v2/main_node.py --hidden-channels 512  --lr 1e-3 --epochs 500 --batch-size 60000 \\\n",
        "  --test-batch-size 60000 --num-M 4096 --num-D 16  --conv-type GAT --sampler-type node --dataset ppi --skip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXhqhPLRSS1B",
        "outputId": "4daa147c-80f9-40e4-b625-924baee11b60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.6.\n",
            "Namespace(EMA=True, act='leaky_gelu', alpha_dropout_flag=False, batch_size=60000, bn_flag=True, ce_only=False, clip=None, cluster='vq', commitment_cost=0.0, cont_sliding_window=1, conv_type='GAT', data_root='./datasets', dataset='ppi', device=0, dropbranch=0.0, dropout=0, epochs=500, exp=False, exp_name='test', exp_tag='exp', grad_scale=[1, 1], hidden_channels=512, kmeans_init=False, kmeans_iter=100, ln_para=False, log_steps=1, lr=0.001, momentum=0.1, no_second_fc=True, num_D=16, num_M=4096, num_branch=0, num_layers=3, num_parts=1, num_workers=0, recovery_flag=True, run_idx=None, runs=1, sampler_type='node', sche=False, skip=True, split=True, test_batch_size=60000, transformer_flag=False, use_gcn=False, walk_length=5, warm_up=True, warm_up_epochs=0, weight_ahead=False)\n",
            "PPI loaded\n",
            "lsh_nodes:\n",
            "din=50\n",
            "num_functions=15\n",
            "sparsity=25\n",
            "std_of_threshold=1\n",
            "func 0, indices:[22 38 47 41 30 28 27 37  7 12 42 26 13 33 34 21 45 17  8  6 46  4 25 44\n",
            "  2] thresholds:[ 1.61495732  2.42966077  0.78804774  0.91966274  1.40539778  1.11860659\n",
            "  2.25441407  2.41910204  0.25614392 -1.5174371  -0.50709602  2.14907613\n",
            " -0.19357825  2.14104245  2.50944508  2.06777513  0.31341052  1.01487332\n",
            "  0.6243341   0.96177636  1.36797447  0.9552763   0.69762487 -1.2244036\n",
            "  1.72400636]\n",
            "func 1, indices:[ 7 40 12 44 31  5  9 42 33 15  4 29 21 28 47 37 43 25 34 26 39 23 48 45\n",
            " 13] thresholds:[ 1.35900276  2.72763912  0.13164743  0.17902242 -0.09974201  1.08672983\n",
            "  1.45628701  1.4310333   3.07257353  0.46221488 -0.3784301   0.50759575\n",
            "  3.32773811  2.80440397  0.75057867  0.17913617 -0.49333996  1.52417595\n",
            "  1.34511317  1.72437468 -1.04038084 -0.0797781   0.30657559 -1.33804615\n",
            "  2.66226234]\n",
            "func 2, indices:[24 21 22 49 30 39  6 17 15  0  4 45  5 42  8 16 41 38  1 36  7 13 46 31\n",
            " 35] thresholds:[ 2.19732198  2.88335386  1.71422382  3.28433335  2.56410258  1.61110371\n",
            "  0.12263668 -0.6210875   0.418327    0.46216605 -0.55602368  0.94553516\n",
            " -0.81127879  0.36882478  0.07184082  2.49072192  1.19549934  0.52839567\n",
            "  2.81235465 -1.29413748  1.65120935 -0.13049645  0.22265334  2.11593845\n",
            "  2.33945302]\n",
            "func 3, indices:[31  6 16 34 21  2  9 37 27  1 41 35 10 12 24 29 39 30 15 43 40  5 42 45\n",
            " 44] thresholds:[-0.76743365  1.3771362   0.3628935   0.89524682  0.84895799  1.84462603\n",
            "  1.90864239  1.98242156 -0.18095088  1.0899438   0.29375507  1.052225\n",
            " -0.34157915  2.38294233  1.38691284 -0.33245318  1.50381748  2.03291568\n",
            "  0.87777637  2.83263786  0.93426685  2.86377673  0.87630919  2.22039868\n",
            "  0.99341267]\n",
            "func 4, indices:[ 5 48 26 18 47 21 43 40 44 14 30 32 24 25 34  2 28 49 12 39 35 46 42  6\n",
            " 45] thresholds:[ 0.59028308  2.11637454  0.7490207   0.58477192  0.36091385  3.49776759\n",
            " -2.00512816  0.12600277 -1.65018924  2.12400545  0.78636299  2.13183157\n",
            "  1.03723304  2.30275033  1.24990045  0.35413229  1.47119601  0.60189671\n",
            "  0.04078481  1.54087305  0.92175454  2.83379274  2.0246933   0.91833257\n",
            " -1.62754439]\n",
            "func 5, indices:[40 42 34 21 48 18  1 43  5 38  7 11 46  0  8 10 24 16 14 49 19 31 37 12\n",
            " 25] thresholds:[ 0.64354225  1.48707415  1.14484156  0.9143901   1.7105399   1.93095988\n",
            "  1.87507402  0.28843469  0.63879096 -1.10924743 -0.09376775  2.2045055\n",
            "  1.11108051  2.96099802  1.39459838  0.17287071  1.22490418  0.84697671\n",
            "  0.75927044  1.08158307  2.23816955  3.18377828  1.19056415  0.50183305\n",
            "  1.04751241]\n",
            "func 6, indices:[32 23 34  9  0 38  2 46 11 33 19 30 39 36  4 20 24 28 42 18 29  3 47 15\n",
            " 45] thresholds:[ 0.71847365  1.56036933  1.75520898 -0.06089086  1.05447385  0.89572137\n",
            "  0.64839032  1.58979914 -0.47896813 -0.42295597  0.17353888  1.78420863\n",
            "  0.8045828  -0.26459544  1.85693318  0.50600565  1.01463666 -0.60646646\n",
            "  1.16198952  1.53503832  1.83058861  2.04362959  0.2390527   0.91456868\n",
            "  0.21003636]\n",
            "func 7, indices:[ 1  5 17 16 22 42 34 29 48 30 14 49 15 11  6 21 23  0 13 19 39  3 27 40\n",
            "  7] thresholds:[ 0.52916037  2.10300532  2.40517731 -0.71225511  1.3642798  -0.41423684\n",
            "  1.9533122   0.56878895  0.96392284 -1.02180438  1.84549916 -0.21167713\n",
            "  1.00947849  1.86038501  0.84220444  0.37622657  1.29725239  1.33684093\n",
            " -0.812277    0.2607524   2.49101888  0.74890086 -0.51813904  1.24976833\n",
            "  1.61931236]\n",
            "func 8, indices:[11  2 40 21 27 14 48 30 13  1 23 33  8 34 38  4  9 18 24 25  3 44 15 41\n",
            " 46] thresholds:[-0.10213089  1.2517392   2.14051141 -0.49341013  1.71435718  0.75893252\n",
            "  0.82404118  2.01146172 -1.74060805  2.90540978  0.73174525 -0.29785512\n",
            "  1.59605289  0.13462457 -1.00020141  1.25645775  1.0421191   1.12086284\n",
            "  0.07306961  0.36008709  0.78458045  1.48076114  2.70518672 -0.2402588\n",
            "  0.83618607]\n",
            "func 9, indices:[12 48 10 31  4 19 38  2 20  7 39 13 49 36 21 14 11 18 35 43  9 28 27 34\n",
            "  6] thresholds:[ 1.94956093  1.44463164  0.15323826  1.89327636  1.38676116  0.99486573\n",
            "  0.06986001 -0.49407352  1.46873927  1.22233415  0.79535351  0.95355648\n",
            "  0.30211626  0.88729835 -0.00826485  0.94706622  1.33300574  0.35101824\n",
            " -0.54305643  2.65946033  0.02990778  2.29233496  0.06123809 -0.2125329\n",
            "  2.67364748]\n",
            "func 10, indices:[ 0 35  9 28 12  1 18 37 27  4 36  8 45 10 13 22 44 17 39 21 30 20 41 40\n",
            " 15] thresholds:[-5.31904913e-01  1.07600218e+00  4.72680580e-01  8.45309631e-01\n",
            "  7.00727644e-01  1.70850768e+00  4.20174874e-01  2.68992749e+00\n",
            "  5.73401634e-01  8.03073084e-01 -8.68059840e-01 -3.07294048e-01\n",
            "  5.59440706e-01  1.17465711e-03 -4.85613883e-02  1.57189115e+00\n",
            "  1.15026910e+00  1.78847387e+00  3.10187965e+00  3.48823061e-01\n",
            "  1.33736087e+00 -6.24581949e-01  7.11431878e-01  6.45319975e-01\n",
            "  7.04324797e-02]\n",
            "func 11, indices:[ 8 36 35 38 40 32  9 24  2 43  5 29 20 34 46  4 17 14 26 13 41  7 23 42\n",
            " 48] thresholds:[ 1.03245805  0.58764356 -0.81030697  2.5308268   0.96674891  0.92801796\n",
            "  1.06865298  2.1655696   0.75150404  0.52051707  0.15854333  0.86565375\n",
            "  0.24275033  1.1633898   0.06019457  1.55634416 -0.46217032  0.83574556\n",
            "  1.65663668  0.19879896  0.17241466  0.42517096  0.97924842 -0.14888952\n",
            "  2.75039066]\n",
            "func 12, indices:[ 1 40 37 42 24 35 46 28 13 25 18 20 11 36  0 41 43 12 27 38 48 33  2  8\n",
            " 30] thresholds:[ 2.03440989  0.00378736 -0.21793851  0.69503636  2.02893549  0.92771299\n",
            "  0.39934244  2.55224318  1.28690449 -1.32059428  1.31716063  1.52004061\n",
            "  1.22560865  1.4497121   0.93272439 -0.31839587  0.629296    0.0543842\n",
            "  0.06725909 -0.26306835  1.45248909  1.09789615  0.55183464  0.35066207\n",
            "  0.97657689]\n",
            "func 13, indices:[ 5 35 24 14 49 18 38 20 39 11  8  3 29 25 22 27 31 23  9  6  7  4 17 15\n",
            " 41] thresholds:[ 2.07919473 -0.32275206  1.32747602  1.07440437  1.0410793   2.2596372\n",
            "  1.89166665  1.50561711  0.31658333  0.12350894  0.99438534  2.46656234\n",
            "  0.27420646 -0.73281749  1.69995928  1.03200428  1.21128828  1.08739114\n",
            "  1.65052474  0.38127491  1.08914477  1.24414862  0.15531929  0.09742383\n",
            "  1.8167717 ]\n",
            "func 14, indices:[ 6 36 45 37 14 10 12 31 11 26  0  2 29  9 39 24 43  7 49 25 33 35 16  3\n",
            " 22] thresholds:[-0.03768013  0.98809195  0.95571671  2.49951807  0.98983484  1.53730336\n",
            "  0.81935837  0.64867595  0.71658096  1.68741707  0.94478887  1.46446306\n",
            "  2.21940615  0.44050508  0.20024635  0.93804359  1.47861622  1.5418555\n",
            "  0.72380078  1.00844563  1.41793375  0.28308757  2.65127286  1.74998616\n",
            "  2.34023724]\n",
            "lsh_edges:\n",
            "None\n",
            "  0% 0/1 [00:00<?, ?it/s]Processed 1000000 / 1226368 edges (81.54159273562259 %)\n",
            "100% 1/1 [10:42<00:00, 642.89s/it]\n",
            "prunning_ratio = 0.041897701179417594\n",
            "lsh_nodes:\n",
            "din=50\n",
            "num_functions=15\n",
            "sparsity=25\n",
            "std_of_threshold=1\n",
            "func 0, indices:[47  6  2 40 44 16 18 13 39 11  3 31 12 19 34 37 45  9  8 28 35 33 42 17\n",
            " 24] thresholds:[-0.4406055   2.02332446  0.86586473  1.04672383  0.40491181 -0.94971646\n",
            "  0.46997409 -0.06035551  0.09151179  0.96502459 -0.42639726 -0.302537\n",
            " -0.19075805  0.82945718  1.81405178  0.47985371  2.93460204  0.94780428\n",
            " -0.05748566  0.84191002  0.76158848  1.2794999   2.96207776  2.24693061\n",
            "  1.18786032]\n",
            "func 1, indices:[47  9 26 43 34 19 49 21 31 32  8  7  3  5 17 42 35 23 18  6 28  0  2 20\n",
            " 44] thresholds:[ 1.3130785   1.43104085 -0.31442876  3.32129058  1.96617715  0.9634319\n",
            "  0.46863343 -0.24184898  2.36176578  1.88963404 -0.08226054  0.37941373\n",
            " -0.17082676  1.7748628   2.09381785  0.53786091  0.18332524 -0.3946153\n",
            "  1.78244165  2.04395119 -0.17002837  0.69478365  1.1760503   1.92355756\n",
            "  0.15238596]\n",
            "func 2, indices:[29 19  6  0 45 42 17 16 32  1 23 26 21 47  3 35 43 18 36 48 30 25 37  8\n",
            " 44] thresholds:[0.21672033 2.42549674 1.69600379 1.38541571 1.18193761 2.54492747\n",
            " 2.65067561 1.89795672 1.94250593 1.87976221 0.34642964 1.14823997\n",
            " 1.21457504 1.15992601 1.16022935 1.69179828 0.46614576 0.04781076\n",
            " 2.18046827 2.18595818 2.19617694 2.35290868 2.15196054 2.43088146\n",
            " 1.39934376]\n",
            "func 3, indices:[13  6 38 29 37  5 44 15 36 28  3 21  9 20 41  0 42 48 33 22  2 40 24 16\n",
            " 10] thresholds:[ 0.21957595  0.81476604  0.87387183  0.75141344  1.36215156  0.58650393\n",
            "  2.54038891  2.91435438  1.4806893   1.01230929  2.21424357  0.42578478\n",
            " -1.1229507   2.12475605  1.11206079  1.51914123  0.7890552   0.02514295\n",
            "  1.69921013  2.0161952   0.80234861  1.34198882  0.75258495  2.59205834\n",
            "  1.56292   ]\n",
            "func 4, indices:[ 3 49 11 28 37 18  7 25 14 32 29  5 33  8 13 23  9 41 24  6 44 16 36 35\n",
            " 19] thresholds:[ 1.09105967  1.78398857 -0.07868102  0.16033686  1.8045051  -0.67466007\n",
            "  1.06779238  2.34317908  2.06709778  1.06179101  0.42599928  1.94323269\n",
            "  2.91796684  0.10724733  0.27626236  1.45501865  0.39344883  1.24461961\n",
            "  2.42248468 -1.18180099  1.5077852   0.70522496  1.37019238  2.86328358\n",
            "  0.0819169 ]\n",
            "func 5, indices:[ 8 13 12 41 10 21 44 45 24 46 43  2 48 28  4  7 18 33 32 25 35 22 14 27\n",
            " 20] thresholds:[ 2.01104108  1.06282899  1.36701907  1.48415425  1.61477538  1.64928771\n",
            "  2.65034754  1.50711339  2.39109855  0.80275982  1.59621599  1.39639788\n",
            "  1.84773008  0.96021271 -0.7908126  -0.81966768 -1.14842898  3.28328668\n",
            "  1.39311886  2.86108658  3.00014027  1.50646011  0.27601217  1.03702059\n",
            "  0.40009708]\n",
            "func 6, indices:[23 36 44 33 15 49  8  4 31 10 43  1 46 13 19 35 48 42 38 37 32 12 39  9\n",
            " 29] thresholds:[ 1.87440049  0.47062953  2.44159259  1.15963806  0.67193342 -0.1451034\n",
            "  1.22938641  2.47834196  2.1967733   0.93716606  1.66376249  1.89747919\n",
            "  1.02743453  0.17486906  0.11579035  0.81357532  1.63360382  0.31031657\n",
            "  2.16972862  0.30438949 -0.02558951 -0.53038473  1.03831601  0.67593792\n",
            "  1.17534427]\n",
            "func 7, indices:[16 44 17 41 12 42 20 49  9 32 40 18 25 19 23  2 28 10 22  6 14  1 31  8\n",
            "  7] thresholds:[ 1.42496689  0.9845417   1.79633261 -0.14739829  1.85316491  0.03812843\n",
            "  2.38157017  0.3959111   1.45867203  0.19430436 -0.07496781  0.46954012\n",
            "  1.35326358  0.91820012  1.54333167  1.50278738  1.56852822  0.98247895\n",
            "  2.24968452  2.7539529   0.3710859   0.10386567 -0.03760694  0.85309494\n",
            "  1.43111328]\n",
            "func 8, indices:[23 19 48 42 33  2 41 31 39 49 10  8 30 43 47 45 15 28  4 22  7 24 32 16\n",
            " 25] thresholds:[ 1.71923033  1.7568049   0.23233618  1.0419921   1.1503982   0.68796565\n",
            "  0.61413777  0.93215958 -1.38557705  0.98468595  0.5983466  -1.6220619\n",
            " -0.02708196  1.17762265  0.92562133  2.10804421  1.63950965 -1.27469841\n",
            "  1.26502532 -0.40340214  0.2024416   2.14960351  1.15245263  0.50711421\n",
            "  2.32853835]\n",
            "func 9, indices:[ 5 13 23 24 22  2 44 14 26 32 40 19 21 33 46 35 15 38 48 31  4 20 29  7\n",
            "  0] thresholds:[ 0.45050145 -0.09857073  3.32079984  1.11709087  1.53420117  1.3178851\n",
            "  1.43480796  1.54009446  1.73242401  0.6247776   0.70835801 -0.74102281\n",
            "  0.21969559  1.2711128   2.04502338  1.59903953  0.65930766 -0.26317291\n",
            " -1.77735915  2.15173397  0.41077101  0.55153499  1.13157397 -0.40556005\n",
            "  0.65021782]\n",
            "func 10, indices:[29  3  7 17 47 34  0 22  8 24 23 32 28 15 25  9 40 11 37  5 41 14 43 38\n",
            " 18] thresholds:[ 3.02347195  0.47961996  0.65117023  0.98692532  0.01862262 -0.45062361\n",
            "  1.32015673  2.7468111   1.40732463  1.31118054  1.29976148  1.5916301\n",
            "  0.83486855  0.47515245  1.93917711 -0.58874711  2.62709233  0.78144601\n",
            "  0.04322854  1.08191889  2.21823919 -0.6113244   2.24652263  1.27057347\n",
            " -0.25243153]\n",
            "func 11, indices:[33 38 18 37 24  5 28  3 20 45  0  2 31 39  8  1 32 13 36 34 46 22 48 30\n",
            " 12] thresholds:[ 0.69836255 -1.2370097   2.86559944  0.61370471 -1.31794572  1.1113988\n",
            "  1.58158611 -0.30735878  1.84745595 -0.14701312  1.67291893  2.18000193\n",
            "  2.58708418  0.22760435  0.03126166 -0.06389001 -0.43123383 -0.86660095\n",
            " -1.13146385  1.95566836  1.36782454  1.98357763  0.77049864  1.7103582\n",
            "  1.42644556]\n",
            "func 12, indices:[19 36  4 37 28 39 10 30 40 25 44 20 47 29 46 45 24 27  2 21  3  9 41 15\n",
            " 33] thresholds:[ 2.46503946e+00  1.70073238e+00  1.81598282e+00  7.79033986e-02\n",
            "  1.12872909e+00 -9.75514993e-01  8.25046530e-01 -9.17583356e-01\n",
            "  1.11999237e+00  1.04461609e+00  1.04688312e+00  1.88539547e+00\n",
            " -6.40732117e-01  1.85096942e+00  8.54766544e-01  1.58682787e+00\n",
            "  7.21346251e-02  1.63667651e+00  2.05053416e-02  9.48361252e-01\n",
            "  2.52526110e+00 -3.02573637e-01  1.49727097e+00 -2.12149080e-03\n",
            "  9.39588334e-01]\n",
            "func 13, indices:[ 3 46 26  2 24 28 33 10 23 45 44 35  6  0 38 14 37 43 16 48 21 40  1  8\n",
            " 22] thresholds:[ 0.88143266  1.04371408 -0.63699089  0.08793105  0.69102364  0.35521661\n",
            "  0.31592726  0.98128773  1.58748393  1.71556746  1.56958269  1.84775743\n",
            "  0.53978436  1.79566807  2.31885096  0.7000972   2.07070943  0.31103929\n",
            "  1.53761823 -0.53730829  0.68067049  0.02460394  1.20822873  1.34247074\n",
            "  2.97824102]\n",
            "func 14, indices:[45 42  5 25 41 32 48 13 17  4 21 11 46  2 29 19 14 31 22 47  7 39  9 38\n",
            " 36] thresholds:[ 0.42707452  2.00449944  0.60875143  2.06304801  0.2332428   2.36475684\n",
            "  0.7697953   1.5589773   1.50783059  2.0706706   1.79220922  1.71335565\n",
            "  1.79396368 -0.25301695  0.55305977  0.51048544  1.55483096  0.76762968\n",
            "  2.04378328  1.21044119  1.62834602  3.73276455  1.66502465 -0.11610623\n",
            "  1.11201816]\n",
            "lsh_edges:\n",
            "None\n",
            "100% 1/1 [01:43<00:00, 103.78s/it]\n",
            "prunning_ratio = 0.2335863663784436\n",
            "lsh_nodes:\n",
            "din=50\n",
            "num_functions=15\n",
            "sparsity=25\n",
            "std_of_threshold=1\n",
            "func 0, indices:[15 44 46 41 18 45 40 39  0 33 42  7 12 36  8 47  1 38 37 13 43 11  3  2\n",
            " 35] thresholds:[ 1.01184512  0.50505428  2.32617234  1.18732638  0.11629119  1.74153818\n",
            "  1.53648101  2.21990842  1.09405015 -0.58037444  1.80080232  0.06105107\n",
            "  0.96838932 -0.92382684  0.90161579 -0.11664953  0.91843337  1.25985691\n",
            "  0.61008544  0.56989746  0.60671778  1.04057682  0.45616804  2.36810455\n",
            "  0.2708318 ]\n",
            "func 1, indices:[ 1  9 33 44 49 22 45 48  8 31 26 13 16 18 36 47 17 39  2  0 35  6 32 40\n",
            " 29] thresholds:[ 0.03207688  1.87972038  1.12312728  1.53787197  1.29120156  1.38749565\n",
            " -0.32345197  2.29294834  0.22901015 -1.19603524 -0.25333027  0.61521948\n",
            "  0.05548961  1.10903505  3.0856442   3.1800887   1.28150391  0.09887985\n",
            "  0.2766532   1.2324639   0.52171553 -0.27722461  2.45638083  0.80036265\n",
            "  0.61677665]\n",
            "func 2, indices:[31 41 20 14 26 45 28 30 24 19  5 12 48 40  4 16  2 39  9 23 22 32  1 49\n",
            " 29] thresholds:[ 1.49687534  2.64400413  1.54363314  1.47586663  0.71544051  2.14327687\n",
            "  1.74314154  0.86274996  0.39197899  1.23444093 -1.10572328  1.61693424\n",
            "  2.48754604  1.74622978  1.04879185  0.66427886  1.79149545  0.53432646\n",
            "  1.63658178  3.17531346  1.10480747 -0.00425714  1.43858484  1.12689098\n",
            "  1.44494905]\n",
            "func 3, indices:[18 14 41 23 34 46 24  7  6 43 49 13 20 16 45  8 33 17 26 15 38  2 12  4\n",
            " 25] thresholds:[ 1.08096559 -0.69237044  1.72934635  1.69913615  0.7012404  -0.10223019\n",
            "  0.97545058  0.16414393  0.05790641  0.89678725 -0.0513904   1.24664896\n",
            "  1.60799251  0.16036755 -0.3682451   2.5612796   0.05972976  0.34005729\n",
            "  1.21301717  1.59936937  0.74368311  1.46079433  0.59901384  0.02882934\n",
            "  2.42631686]\n",
            "func 4, indices:[24 34 22  3  2 10 19  9 47 36 32 44 21 40 46 39 28 14 23 31 43 42 35 45\n",
            " 33] thresholds:[ 1.40088568  0.99034276 -0.79716462  0.19774683  1.19321355  2.29734209\n",
            "  2.00133102  1.5972125   0.18472434  2.80121399  1.21524047 -0.00636552\n",
            "  0.81709502  1.89624843  1.0076175   1.88686469  2.10369396  1.40053068\n",
            "  0.14229738  1.13545466  1.04516586  2.85934633 -0.62632194  0.86517755\n",
            "  0.41590645]\n",
            "func 5, indices:[ 1 37 15 45 49 41 24 20 46 42 23 34 21 13 48  7 26  8  3 36 35 39 43 14\n",
            "  5] thresholds:[ 1.33510562  2.61125409  0.72816511  0.14767553  1.23016883  1.75179781\n",
            "  1.76604137  1.19045726  1.350555    0.68892209  2.09435995  1.50401364\n",
            "  0.88987976  0.82045906  2.61169184  0.63395374  0.99212238  0.83511831\n",
            " -0.55280071  1.01481473 -0.02481756  1.51777479 -0.35772829  1.16608519\n",
            "  1.96791008]\n",
            "func 6, indices:[ 5  3 33 34 16 46 45 48 47 15 22 43 24  4 18 26 14  2  6 11  0 31 42 44\n",
            " 41] thresholds:[ 0.27998011 -0.54940047  0.95459241  1.3791217   0.44790236  1.81942079\n",
            "  2.29519969  0.87348439  0.25154939  1.76922963  1.31846751 -0.62464609\n",
            "  1.75017483  1.85897974  2.34129545  2.20757833  2.30648345  0.24668589\n",
            "  2.32756335  1.47554009  1.3457694   0.61917613  1.35699638  2.73568175\n",
            "  0.56283096]\n",
            "func 7, indices:[40 12 48 20 15 30 31 25 44 26 14  0 42 34 16 29 49  3  8 23 24 11 13 21\n",
            "  6] thresholds:[ 0.73890687  1.79160153  0.70840935  1.68754595  0.64020912  0.81838754\n",
            "  1.51372854  0.42826103  0.21989262  0.06398157  3.06744707  1.78006861\n",
            "  2.34518459 -0.05146249 -0.19067963  1.15337582  2.42176975  1.234557\n",
            " -0.00781076  1.37573241  0.17775369  1.58308595  1.03848136  0.03517404\n",
            "  0.02140156]\n",
            "func 8, indices:[35  6 36  8 31 42 45 24 37 22 30 43 17 39  1 49  4 27 25 20 38  3 11 34\n",
            " 40] thresholds:[ 0.15600636  0.97014643  1.90487694  1.17958124  0.87110404  1.35341314\n",
            "  0.3491406   1.93371012  0.96558686  1.6084004   0.01378368 -0.28706536\n",
            "  1.35859553 -0.48701765  1.69625204 -0.00526544 -0.22828018  0.90189006\n",
            "  0.98164987  1.08763373 -0.08296307 -1.0951878   2.82593161 -0.59997832\n",
            "  0.74507127]\n",
            "func 9, indices:[22 20 12 33 34 35 41  2 18 36 10 37 42 15 44  3 32 40 17 43 49  4 38  5\n",
            " 21] thresholds:[-1.10814658  0.1129432   0.90294865  2.06644207  0.8707095   0.69526069\n",
            "  0.96754775  1.43345505  2.17293936  3.60832601  0.96109405  1.71081406\n",
            "  1.47457784  2.97931704  0.35380431  1.23347708  2.56411977  0.69810779\n",
            " -0.13947271  1.22473601  0.49766758  2.37564193 -0.79869174  1.39273329\n",
            " -0.87345082]\n",
            "func 10, indices:[19 49 25 33  3 44 48 41 26 36 14 28  8 40 20 30 21 18 24 39 15 12  1 37\n",
            " 38] thresholds:[ 0.66734644  0.58193591  2.18357026 -0.14320098  0.51685614  0.60200148\n",
            "  1.26889735  0.34994967  1.32889721 -1.0516602  -0.72071068  1.57131554\n",
            "  2.0602816   1.17384825  1.43148794  1.16967055  1.07165452  2.6947988\n",
            " -0.09789441 -0.37230641  1.01494763  2.33252367  1.13815904  1.00578676\n",
            "  2.13308321]\n",
            "func 11, indices:[ 0 17 31 35 39 48 43  6 38 11 22  1 25 30 49 34 40 45 26 28  7  8 36  5\n",
            " 13] thresholds:[ 2.82559167 -0.1676657   0.83079285  1.94110309  3.34704731  1.43390964\n",
            " -0.27005611 -0.19386764  0.27094248 -0.8675845   1.09322751  1.39783664\n",
            "  0.70888492  0.51589059  0.24046963 -0.4730222   0.25905883  1.65869859\n",
            "  0.29722577  0.25455389  0.67106193 -0.05777805  1.11550514  1.84727455\n",
            "  0.68383565]\n",
            "func 12, indices:[26 34  8 41 21 45 46 31 35 15 13 47 17  9 49 11 30 32 48 39 27 40 12 25\n",
            " 28] thresholds:[-0.03560573  1.14166716  0.98886437  2.34407437  1.5000167  -0.43179778\n",
            "  0.37101929  2.07007251  0.3789173   2.73457217 -0.09828943  1.57261335\n",
            "  0.13878445  0.49040487  2.09858165  0.87293284  1.81345225  1.47329059\n",
            "  1.75386568  0.11181179  0.7784256   1.42425262  0.15092713  2.62950004\n",
            "  0.22277196]\n",
            "func 13, indices:[33 34 31  9  5 21 29 16 23  2 10 11  6  4 40 38 25 42 26 13 44 49 15 47\n",
            " 39] thresholds:[ 0.69999642  2.17393209  0.39426234  0.35697735  1.25717465  1.46660526\n",
            "  1.41623699  1.70547457  1.20241045  1.91170069  0.80485036  2.48399513\n",
            "  0.7802523   2.90661885  0.76410654 -0.98196181 -0.12378047  2.17514976\n",
            "  1.63403738  0.80388225  0.65205323 -0.64468063  1.70734393  1.19418326\n",
            "  1.96277803]\n",
            "func 14, indices:[28  2  3 39 16 33  6 17 11  8 22 10 38 41  9 26 44 12 29 14 46 25 20 23\n",
            " 45] thresholds:[ 1.29898847  1.10715707  0.95415817 -0.124417    1.84876082  1.37973053\n",
            "  1.82098984  0.64511629  0.69134321  0.54892586  1.01982389  1.93554708\n",
            "  0.55430225  1.1043788   0.58952124  1.96353492  0.47101342  2.17824705\n",
            "  0.55392383  0.74496532  0.76702419 -0.79135881  0.80309788  2.31658624\n",
            "  1.041239  ]\n",
            "lsh_edges:\n",
            "None\n",
            "100% 1/1 [01:19<00:00, 79.65s/it]\n",
            "prunning_ratio = 0.2643416308588927\n",
            "{'minhash': <lsp.src.utils.minhash_tools.MinHashRep object at 0x7f372605b400>, 'nodes': {'din': 50, 'num_functions': 15, 'sparsity': 25, 'std_of_threshold': 1, 'mean_of_threshold': 1, 'random': RandomState(MT19937) at 0x7F3726121B40, 'lsh': <lsp.src.utils.lsh_euclidean_tools.LSH object at 0x7f372605bf70>}, 'edges': {'din': 0, 'num_functions': 15, 'sparsity': 25, 'std_of_threshold': 1, 'mean_of_threshold': 1, 'random': RandomState(MT19937) at 0x7F3726121B40, 'lsh': None}} 0.041897701179417594\n",
            "1\n",
            "num_B_prime:0, new edges:0\n",
            "2344.32256\n",
            "2\n",
            "num_B_prime:0, new edges:0\n",
            "2436.649472\n",
            "3\n",
            "num_B_prime:0, new edges:0\n",
            "2528.61696\n",
            "init done\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.38175753515460226\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 1, Loss: 0.7115, Loss Cls: 0.7115, Train: 41.16%, Valid: 40.19%, Test: 40.50%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.3984767518529662\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 2, Loss: 0.6778, Loss Cls: 0.6778, Train: 41.76%, Valid: 38.78%, Test: 38.71%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.40710598493872013\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 3, Loss: 0.6563, Loss Cls: 0.6563, Train: 43.30%, Valid: 42.20%, Test: 42.80%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.4510413168135921\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 4, Loss: 0.6131, Loss Cls: 0.6131, Train: 41.89%, Valid: 40.65%, Test: 40.44%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.4300030064994647\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 5, Loss: 0.5924, Loss Cls: 0.5924, Train: 46.33%, Valid: 43.92%, Test: 44.65%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.459134123234072\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 6, Loss: 0.5655, Loss Cls: 0.5655, Train: 42.84%, Valid: 42.50%, Test: 42.37%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.4299203613588807\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 7, Loss: 0.5540, Loss Cls: 0.5540, Train: 44.93%, Valid: 45.56%, Test: 46.03%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.4430403213591498\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 8, Loss: 0.5468, Loss Cls: 0.5468, Train: 42.38%, Valid: 43.12%, Test: 43.26%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.42370512805262955\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 9, Loss: 0.5435, Loss Cls: 0.5435, Train: 44.36%, Valid: 45.08%, Test: 45.47%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.4395571158520119\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 10, Loss: 0.5412, Loss Cls: 0.5412, Train: 42.91%, Valid: 43.34%, Test: 43.52%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.42925609484979327\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 11, Loss: 0.5397, Loss Cls: 0.5397, Train: 44.48%, Valid: 45.03%, Test: 45.44%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.4411139705190459\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 12, Loss: 0.5384, Loss Cls: 0.5384, Train: 42.94%, Valid: 43.21%, Test: 43.36%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.43005576000937706\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 13, Loss: 0.5375, Loss Cls: 0.5375, Train: 44.72%, Valid: 45.18%, Test: 45.61%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.44405064080351925\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 14, Loss: 0.5366, Loss Cls: 0.5366, Train: 43.23%, Valid: 43.26%, Test: 43.38%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.43372132334005814\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 15, Loss: 0.5360, Loss Cls: 0.5360, Train: 45.15%, Valid: 45.51%, Test: 45.97%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.44787109000812936\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 16, Loss: 0.5354, Loss Cls: 0.5354, Train: 43.16%, Valid: 43.10%, Test: 43.22%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.4341052617856715\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 17, Loss: 0.5351, Loss Cls: 0.5351, Train: 45.75%, Valid: 45.98%, Test: 46.47%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.4457825186331155\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 18, Loss: 0.5347, Loss Cls: 0.5347, Train: 43.03%, Valid: 42.83%, Test: 42.94%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.43595953248097996\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 19, Loss: 0.5346, Loss Cls: 0.5346, Train: 46.32%, Valid: 46.48%, Test: 47.01%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.4514746641859753\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 20, Loss: 0.5342, Loss Cls: 0.5342, Train: 42.94%, Valid: 42.61%, Test: 42.74%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.43771377430640307\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 21, Loss: 0.5340, Loss Cls: 0.5340, Train: 46.26%, Valid: 46.52%, Test: 47.12%\n",
            "num_B_prime:0, new edges:37928\n",
            "Batch 0.0, train acc:0.45597323227150127\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 22, Loss: 0.5332, Loss Cls: 0.5332, Train: 43.03%, Valid: 42.63%, Test: 42.78%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.4400765276998502\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 23, Loss: 0.5324, Loss Cls: 0.5324, Train: 46.50%, Valid: 46.63%, Test: 47.19%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.45845430785765023\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 24, Loss: 0.5312, Loss Cls: 0.5312, Train: 43.28%, Valid: 42.83%, Test: 42.99%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.44320863097967816\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 25, Loss: 0.5302, Loss Cls: 0.5302, Train: 46.64%, Valid: 46.66%, Test: 47.23%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.46025022423806766\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 26, Loss: 0.5290, Loss Cls: 0.5290, Train: 44.22%, Valid: 43.41%, Test: 43.54%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.449883236799154\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 27, Loss: 0.5280, Loss Cls: 0.5280, Train: 46.92%, Valid: 46.88%, Test: 47.46%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.46335311655204786\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 28, Loss: 0.5271, Loss Cls: 0.5271, Train: 44.10%, Valid: 43.24%, Test: 43.38%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.4515151576186899\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 29, Loss: 0.5265, Loss Cls: 0.5265, Train: 47.71%, Valid: 47.55%, Test: 48.16%\n",
            "num_B_prime:0, new edges:37921\n",
            "Batch 0.0, train acc:0.4683392213050595\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 30, Loss: 0.5260, Loss Cls: 0.5260, Train: 43.38%, Valid: 42.69%, Test: 42.86%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.45280318475957165\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 31, Loss: 0.5257, Loss Cls: 0.5257, Train: 48.23%, Valid: 47.98%, Test: 48.60%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.46994868648360255\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 32, Loss: 0.5248, Loss Cls: 0.5248, Train: 43.60%, Valid: 42.76%, Test: 42.93%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.4554127468934155\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 33, Loss: 0.5242, Loss Cls: 0.5242, Train: 48.58%, Valid: 48.31%, Test: 48.97%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.473707818212383\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 34, Loss: 0.5232, Loss Cls: 0.5232, Train: 43.85%, Valid: 42.85%, Test: 43.06%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.4596128105251962\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 35, Loss: 0.5220, Loss Cls: 0.5220, Train: 48.81%, Valid: 48.62%, Test: 49.36%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.47616611728912184\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 36, Loss: 0.5206, Loss Cls: 0.5206, Train: 44.00%, Valid: 42.90%, Test: 43.18%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.46342649410241704\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 37, Loss: 0.5202, Loss Cls: 0.5202, Train: 49.37%, Valid: 48.99%, Test: 49.69%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.47983438608899476\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 38, Loss: 0.5200, Loss Cls: 0.5200, Train: 44.29%, Valid: 43.31%, Test: 43.68%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.47067872459444343\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 39, Loss: 0.5198, Loss Cls: 0.5198, Train: 49.06%, Valid: 48.44%, Test: 49.10%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.48056178899461693\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 40, Loss: 0.5187, Loss Cls: 0.5187, Train: 45.41%, Valid: 44.61%, Test: 45.18%\n",
            "num_B_prime:0, new edges:37919\n",
            "Batch 0.0, train acc:0.47347388455273803\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 41, Loss: 0.5180, Loss Cls: 0.5180, Train: 48.61%, Valid: 47.89%, Test: 48.48%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.48053725130146485\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 42, Loss: 0.5171, Loss Cls: 0.5171, Train: 47.18%, Valid: 46.26%, Test: 46.87%\n",
            "num_B_prime:0, new edges:37922\n",
            "Batch 0.0, train acc:0.4789102809800395\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 43, Loss: 0.5173, Loss Cls: 0.5173, Train: 48.15%, Valid: 47.25%, Test: 47.79%\n",
            "num_B_prime:0, new edges:37922\n",
            "Batch 0.0, train acc:0.4823881544048559\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 44, Loss: 0.5161, Loss Cls: 0.5161, Train: 47.96%, Valid: 47.13%, Test: 47.75%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.48294186942230083\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 45, Loss: 0.5157, Loss Cls: 0.5157, Train: 47.70%, Valid: 46.80%, Test: 47.33%\n",
            "num_B_prime:0, new edges:37922\n",
            "Batch 0.0, train acc:0.4844884825377879\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 46, Loss: 0.5143, Loss Cls: 0.5143, Train: 48.83%, Valid: 47.95%, Test: 48.54%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.4864409716369384\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 47, Loss: 0.5133, Loss Cls: 0.5133, Train: 47.71%, Valid: 46.73%, Test: 47.27%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.48682912488415403\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 48, Loss: 0.5119, Loss Cls: 0.5119, Train: 49.52%, Valid: 48.54%, Test: 49.18%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.4899742152190063\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 49, Loss: 0.5110, Loss Cls: 0.5110, Train: 48.04%, Valid: 46.70%, Test: 47.24%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.4918468754922381\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 50, Loss: 0.5100, Loss Cls: 0.5100, Train: 50.28%, Valid: 49.30%, Test: 49.95%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.49474086659679406\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 51, Loss: 0.5093, Loss Cls: 0.5093, Train: 47.62%, Valid: 46.07%, Test: 46.49%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.4920434241436547\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 52, Loss: 0.5087, Loss Cls: 0.5087, Train: 50.76%, Valid: 50.04%, Test: 50.79%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.49724552499865876\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 53, Loss: 0.5082, Loss Cls: 0.5082, Train: 46.89%, Valid: 44.63%, Test: 44.91%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.49429841680571385\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 54, Loss: 0.5083, Loss Cls: 0.5083, Train: 51.68%, Valid: 51.31%, Test: 52.19%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5035592795667685\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 55, Loss: 0.5085, Loss Cls: 0.5085, Train: 45.99%, Valid: 43.45%, Test: 43.62%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.48998266214954944\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 56, Loss: 0.5099, Loss Cls: 0.5099, Train: 52.27%, Valid: 51.78%, Test: 52.69%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5069923224911059\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 57, Loss: 0.5117, Loss Cls: 0.5117, Train: 46.40%, Valid: 44.30%, Test: 44.56%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.48727262472592764\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 58, Loss: 0.5131, Loss Cls: 0.5131, Train: 51.90%, Valid: 50.57%, Test: 51.37%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5150853634926572\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 59, Loss: 0.5122, Loss Cls: 0.5122, Train: 47.78%, Valid: 46.64%, Test: 47.03%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.4961361996422421\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 60, Loss: 0.5088, Loss Cls: 0.5088, Train: 51.04%, Valid: 49.19%, Test: 50.00%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.5158366693596947\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 61, Loss: 0.5075, Loss Cls: 0.5075, Train: 49.06%, Valid: 48.24%, Test: 48.87%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.490367217654217\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 62, Loss: 0.5070, Loss Cls: 0.5070, Train: 50.42%, Valid: 48.47%, Test: 49.14%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5140024279519292\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 63, Loss: 0.5062, Loss Cls: 0.5062, Train: 49.32%, Valid: 48.34%, Test: 49.02%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.4880298686716704\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 64, Loss: 0.5045, Loss Cls: 0.5045, Train: 50.58%, Valid: 48.76%, Test: 49.45%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5120413433532313\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 65, Loss: 0.5032, Loss Cls: 0.5032, Train: 49.63%, Valid: 48.51%, Test: 49.26%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.49687062802554377\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 66, Loss: 0.5022, Loss Cls: 0.5022, Train: 50.54%, Valid: 48.91%, Test: 49.58%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5111111879426699\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 67, Loss: 0.5019, Loss Cls: 0.5019, Train: 49.89%, Valid: 48.56%, Test: 49.28%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.4967711587023227\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 68, Loss: 0.5016, Loss Cls: 0.5016, Train: 50.67%, Valid: 48.90%, Test: 49.48%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5177781884656915\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 69, Loss: 0.5014, Loss Cls: 0.5014, Train: 50.02%, Valid: 48.69%, Test: 49.47%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.4978146619181221\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 70, Loss: 0.5010, Loss Cls: 0.5010, Train: 50.57%, Valid: 48.76%, Test: 49.30%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5140217085215448\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 71, Loss: 0.5009, Loss Cls: 0.5009, Train: 50.23%, Valid: 48.80%, Test: 49.64%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.4994585005186746\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 72, Loss: 0.5002, Loss Cls: 0.5002, Train: 51.03%, Valid: 49.59%, Test: 50.20%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.517492563920622\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 73, Loss: 0.4993, Loss Cls: 0.4993, Train: 50.85%, Valid: 49.21%, Test: 49.92%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5045535122367443\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 74, Loss: 0.4978, Loss Cls: 0.4978, Train: 51.78%, Valid: 50.45%, Test: 51.15%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5222447584364034\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 75, Loss: 0.4971, Loss Cls: 0.4971, Train: 51.10%, Valid: 49.18%, Test: 49.86%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5103461551298442\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 76, Loss: 0.4965, Loss Cls: 0.4965, Train: 52.12%, Valid: 50.85%, Test: 51.56%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5208575799553564\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 77, Loss: 0.4962, Loss Cls: 0.4962, Train: 51.16%, Valid: 48.99%, Test: 49.66%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5196789886376951\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 78, Loss: 0.4960, Loss Cls: 0.4960, Train: 51.62%, Valid: 50.52%, Test: 51.21%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.51716571056257\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 79, Loss: 0.4960, Loss Cls: 0.4960, Train: 51.81%, Valid: 49.47%, Test: 50.12%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5216012078861613\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 80, Loss: 0.4960, Loss Cls: 0.4960, Train: 50.80%, Valid: 49.81%, Test: 50.58%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5147438443781583\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 81, Loss: 0.4959, Loss Cls: 0.4959, Train: 52.37%, Valid: 49.85%, Test: 50.54%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5251535703769501\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 82, Loss: 0.4955, Loss Cls: 0.4955, Train: 50.26%, Valid: 49.51%, Test: 50.34%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5131332390305468\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 83, Loss: 0.4959, Loss Cls: 0.4959, Train: 53.05%, Valid: 50.15%, Test: 50.76%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5248757970148893\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 84, Loss: 0.4957, Loss Cls: 0.4957, Train: 49.79%, Valid: 49.29%, Test: 50.28%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5149144405013736\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 85, Loss: 0.4954, Loss Cls: 0.4954, Train: 53.46%, Valid: 51.01%, Test: 51.70%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5268110243524559\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 86, Loss: 0.4938, Loss Cls: 0.4938, Train: 49.86%, Valid: 49.00%, Test: 49.94%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5147335741882013\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 87, Loss: 0.4926, Loss Cls: 0.4926, Train: 53.92%, Valid: 51.84%, Test: 52.59%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5279512438331964\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 88, Loss: 0.4918, Loss Cls: 0.4918, Train: 49.77%, Valid: 48.43%, Test: 49.33%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5171696636487492\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 89, Loss: 0.4918, Loss Cls: 0.4918, Train: 53.79%, Valid: 51.91%, Test: 52.67%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5251208725774498\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 90, Loss: 0.4921, Loss Cls: 0.4921, Train: 49.61%, Valid: 47.94%, Test: 48.83%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5166044932509298\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 91, Loss: 0.4924, Loss Cls: 0.4924, Train: 53.86%, Valid: 52.02%, Test: 52.83%\n",
            "num_B_prime:0, new edges:37929\n",
            "Batch 0.0, train acc:0.5252280887072018\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 92, Loss: 0.4915, Loss Cls: 0.4915, Train: 49.98%, Valid: 48.43%, Test: 49.19%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5194398775964907\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 93, Loss: 0.4912, Loss Cls: 0.4912, Train: 54.03%, Valid: 52.15%, Test: 52.90%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5290260734306135\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 94, Loss: 0.4905, Loss Cls: 0.4905, Train: 51.01%, Valid: 49.39%, Test: 50.17%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5195574674756668\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 95, Loss: 0.4903, Loss Cls: 0.4903, Train: 53.66%, Valid: 51.60%, Test: 52.37%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5273819867939846\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 96, Loss: 0.4904, Loss Cls: 0.4904, Train: 51.87%, Valid: 50.38%, Test: 51.24%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5230670974095933\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 97, Loss: 0.4903, Loss Cls: 0.4903, Train: 53.12%, Valid: 50.61%, Test: 51.26%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5283065043245626\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 98, Loss: 0.4902, Loss Cls: 0.4902, Train: 52.73%, Valid: 51.47%, Test: 52.36%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5245653689735306\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 99, Loss: 0.4895, Loss Cls: 0.4895, Train: 52.59%, Valid: 49.69%, Test: 50.33%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5291645306978647\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 100, Loss: 0.4891, Loss Cls: 0.4891, Train: 53.31%, Valid: 52.18%, Test: 53.06%\n",
            "num_B_prime:0, new edges:37922\n",
            "Batch 0.0, train acc:0.5229153850885827\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 101, Loss: 0.4885, Loss Cls: 0.4885, Train: 52.27%, Valid: 49.54%, Test: 50.27%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5315906385362396\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 102, Loss: 0.4882, Loss Cls: 0.4882, Train: 53.49%, Valid: 52.29%, Test: 53.18%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.524033541550427\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 103, Loss: 0.4878, Loss Cls: 0.4878, Train: 52.37%, Valid: 49.94%, Test: 50.72%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.5314051719557644\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 104, Loss: 0.4871, Loss Cls: 0.4871, Train: 53.41%, Valid: 51.94%, Test: 52.81%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.528815352918069\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 105, Loss: 0.4862, Loss Cls: 0.4862, Train: 52.85%, Valid: 50.58%, Test: 51.33%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5308808637322308\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 106, Loss: 0.4856, Loss Cls: 0.4856, Train: 53.27%, Valid: 51.63%, Test: 52.54%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5313876037780166\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 107, Loss: 0.4851, Loss Cls: 0.4851, Train: 53.29%, Valid: 50.94%, Test: 51.68%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5304009116289495\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 108, Loss: 0.4852, Loss Cls: 0.4852, Train: 52.90%, Valid: 51.34%, Test: 52.38%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5302380828038855\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 109, Loss: 0.4851, Loss Cls: 0.4851, Train: 53.59%, Valid: 51.08%, Test: 51.72%\n",
            "num_B_prime:0, new edges:37924\n",
            "Batch 0.0, train acc:0.5289923151426014\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 110, Loss: 0.4856, Loss Cls: 0.4856, Train: 52.14%, Valid: 50.88%, Test: 51.91%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5336331669631543\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 111, Loss: 0.4852, Loss Cls: 0.4852, Train: 53.58%, Valid: 51.32%, Test: 51.98%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5253861556064072\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 112, Loss: 0.4858, Loss Cls: 0.4858, Train: 51.10%, Valid: 49.58%, Test: 50.45%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.5313552938109406\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 113, Loss: 0.4856, Loss Cls: 0.4856, Train: 53.67%, Valid: 51.70%, Test: 52.37%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.5246473948079962\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 114, Loss: 0.4857, Loss Cls: 0.4857, Train: 52.03%, Valid: 49.96%, Test: 50.74%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5340258161296372\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 115, Loss: 0.4852, Loss Cls: 0.4852, Train: 53.44%, Valid: 51.43%, Test: 52.20%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5233231871471656\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 116, Loss: 0.4844, Loss Cls: 0.4844, Train: 53.46%, Valid: 51.68%, Test: 52.55%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5362151550130427\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 117, Loss: 0.4838, Loss Cls: 0.4838, Train: 53.28%, Valid: 50.90%, Test: 51.63%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5247567485473101\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 118, Loss: 0.4829, Loss Cls: 0.4829, Train: 54.41%, Valid: 52.94%, Test: 53.91%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5421802671864141\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 119, Loss: 0.4828, Loss Cls: 0.4828, Train: 52.75%, Valid: 49.99%, Test: 50.62%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.5318446996080892\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 120, Loss: 0.4832, Loss Cls: 0.4832, Train: 54.70%, Valid: 53.42%, Test: 54.47%\n",
            "num_B_prime:0, new edges:37918\n",
            "Batch 0.0, train acc:0.5366461637213923\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 121, Loss: 0.4839, Loss Cls: 0.4839, Train: 52.02%, Valid: 49.28%, Test: 49.87%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5343348722503064\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 122, Loss: 0.4846, Loss Cls: 0.4846, Train: 54.61%, Valid: 53.35%, Test: 54.37%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5398832779748166\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 123, Loss: 0.4840, Loss Cls: 0.4840, Train: 52.09%, Valid: 49.59%, Test: 50.23%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5338613567557297\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 124, Loss: 0.4831, Loss Cls: 0.4831, Train: 54.50%, Valid: 53.00%, Test: 53.93%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.539368555388866\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 125, Loss: 0.4815, Loss Cls: 0.4815, Train: 52.82%, Valid: 50.61%, Test: 51.32%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.5320009890386651\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 126, Loss: 0.4813, Loss Cls: 0.4813, Train: 54.35%, Valid: 52.52%, Test: 53.43%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5384597331136788\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 127, Loss: 0.4807, Loss Cls: 0.4807, Train: 52.95%, Valid: 50.81%, Test: 51.57%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5338872518604504\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 128, Loss: 0.4809, Loss Cls: 0.4809, Train: 54.47%, Valid: 52.59%, Test: 53.52%\n",
            "num_B_prime:0, new edges:37927\n",
            "Batch 0.0, train acc:0.5358537255665794\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 129, Loss: 0.4805, Loss Cls: 0.4805, Train: 52.75%, Valid: 50.60%, Test: 51.38%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5367029736436975\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 130, Loss: 0.4804, Loss Cls: 0.4804, Train: 54.86%, Valid: 52.99%, Test: 53.89%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5400750665864505\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 131, Loss: 0.4805, Loss Cls: 0.4805, Train: 52.08%, Valid: 50.08%, Test: 50.84%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5344579405103451\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 132, Loss: 0.4810, Loss Cls: 0.4810, Train: 55.19%, Valid: 52.97%, Test: 53.85%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5425683227611472\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 133, Loss: 0.4812, Loss Cls: 0.4812, Train: 51.85%, Valid: 50.07%, Test: 50.96%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5309587564601367\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 134, Loss: 0.4813, Loss Cls: 0.4813, Train: 55.06%, Valid: 52.58%, Test: 53.45%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5425314308052872\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 135, Loss: 0.4807, Loss Cls: 0.4807, Train: 52.43%, Valid: 51.09%, Test: 52.13%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.53229460788997\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 136, Loss: 0.4802, Loss Cls: 0.4802, Train: 54.99%, Valid: 52.04%, Test: 52.80%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5436080650441667\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 137, Loss: 0.4795, Loss Cls: 0.4795, Train: 53.00%, Valid: 51.93%, Test: 52.99%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5369287875218411\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 138, Loss: 0.4791, Loss Cls: 0.4791, Train: 54.53%, Valid: 51.41%, Test: 52.09%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.5427061260643358\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 139, Loss: 0.4787, Loss Cls: 0.4787, Train: 52.99%, Valid: 51.85%, Test: 52.89%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.5337322801791119\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 140, Loss: 0.4783, Loss Cls: 0.4783, Train: 54.34%, Valid: 51.52%, Test: 52.27%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5457486905631187\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 141, Loss: 0.4779, Loss Cls: 0.4779, Train: 53.11%, Valid: 51.66%, Test: 52.65%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5308267326885309\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 142, Loss: 0.4780, Loss Cls: 0.4780, Train: 54.36%, Valid: 51.53%, Test: 52.31%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5445121396063156\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 143, Loss: 0.4777, Loss Cls: 0.4777, Train: 53.11%, Valid: 51.62%, Test: 52.60%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5312768884934418\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 144, Loss: 0.4774, Loss Cls: 0.4774, Train: 54.52%, Valid: 51.70%, Test: 52.44%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5419837474475643\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 145, Loss: 0.4769, Loss Cls: 0.4769, Train: 53.55%, Valid: 51.99%, Test: 53.01%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5343520662586354\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 146, Loss: 0.4765, Loss Cls: 0.4765, Train: 54.46%, Valid: 51.61%, Test: 52.32%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.54227210314\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 147, Loss: 0.4767, Loss Cls: 0.4767, Train: 53.47%, Valid: 52.15%, Test: 53.17%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5380696789749849\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 148, Loss: 0.4768, Loss Cls: 0.4768, Train: 54.67%, Valid: 51.81%, Test: 52.49%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5403189214452742\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 149, Loss: 0.4773, Loss Cls: 0.4773, Train: 53.24%, Valid: 51.70%, Test: 52.70%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5418918276827189\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 150, Loss: 0.4769, Loss Cls: 0.4769, Train: 54.76%, Valid: 52.24%, Test: 52.93%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5414517860744886\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 151, Loss: 0.4771, Loss Cls: 0.4771, Train: 53.45%, Valid: 51.77%, Test: 52.80%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5412128933169518\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 152, Loss: 0.4770, Loss Cls: 0.4770, Train: 54.85%, Valid: 52.31%, Test: 52.97%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5413964359191005\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 153, Loss: 0.4779, Loss Cls: 0.4779, Train: 53.50%, Valid: 51.64%, Test: 52.69%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5437548269825654\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 154, Loss: 0.4779, Loss Cls: 0.4779, Train: 54.69%, Valid: 52.57%, Test: 53.27%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5447769921376009\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 155, Loss: 0.4781, Loss Cls: 0.4781, Train: 53.58%, Valid: 51.34%, Test: 52.29%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.5407396063281474\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 156, Loss: 0.4762, Loss Cls: 0.4762, Train: 54.45%, Valid: 52.53%, Test: 53.47%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.5488026589810477\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 157, Loss: 0.4754, Loss Cls: 0.4754, Train: 54.22%, Valid: 51.84%, Test: 52.77%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5398215112010983\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 158, Loss: 0.4748, Loss Cls: 0.4748, Train: 54.31%, Valid: 52.38%, Test: 53.34%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5487632375457664\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 159, Loss: 0.4747, Loss Cls: 0.4747, Train: 54.51%, Valid: 52.03%, Test: 52.84%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5374725684157402\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 160, Loss: 0.4745, Loss Cls: 0.4745, Train: 54.09%, Valid: 52.38%, Test: 53.37%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5516386724399551\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 161, Loss: 0.4746, Loss Cls: 0.4746, Train: 54.60%, Valid: 51.86%, Test: 52.60%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5374424968092043\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 162, Loss: 0.4748, Loss Cls: 0.4748, Train: 53.89%, Valid: 52.56%, Test: 53.61%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5524947466284786\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 163, Loss: 0.4747, Loss Cls: 0.4747, Train: 53.96%, Valid: 51.33%, Test: 52.10%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5335400468962113\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 164, Loss: 0.4747, Loss Cls: 0.4747, Train: 54.11%, Valid: 52.79%, Test: 53.80%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5516219613098597\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 165, Loss: 0.4747, Loss Cls: 0.4747, Train: 54.00%, Valid: 51.55%, Test: 52.26%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5324278694798701\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 166, Loss: 0.4748, Loss Cls: 0.4748, Train: 54.59%, Valid: 53.02%, Test: 54.10%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5449594434958313\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 167, Loss: 0.4753, Loss Cls: 0.4753, Train: 53.33%, Valid: 50.80%, Test: 51.49%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5343058112092693\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 168, Loss: 0.4751, Loss Cls: 0.4751, Train: 55.49%, Valid: 54.01%, Test: 55.04%\n",
            "num_B_prime:0, new edges:37920\n",
            "Batch 0.0, train acc:0.5488362701334544\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 169, Loss: 0.4751, Loss Cls: 0.4751, Train: 53.34%, Valid: 50.86%, Test: 51.57%\n",
            "num_B_prime:0, new edges:37927\n",
            "Batch 0.0, train acc:0.5343957115197148\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 170, Loss: 0.4751, Loss Cls: 0.4751, Train: 55.78%, Valid: 54.12%, Test: 55.17%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5472090111424206\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 171, Loss: 0.4753, Loss Cls: 0.4753, Train: 53.49%, Valid: 51.13%, Test: 51.87%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.541508537726754\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 172, Loss: 0.4732, Loss Cls: 0.4732, Train: 55.51%, Valid: 53.56%, Test: 54.56%\n",
            "num_B_prime:0, new edges:37914\n",
            "Batch 0.0, train acc:0.5474633166503202\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 173, Loss: 0.4724, Loss Cls: 0.4724, Train: 53.76%, Valid: 51.52%, Test: 52.40%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5395317019944041\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 174, Loss: 0.4722, Loss Cls: 0.4722, Train: 54.98%, Valid: 53.05%, Test: 54.10%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.5483438035408338\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 175, Loss: 0.4726, Loss Cls: 0.4726, Train: 53.94%, Valid: 51.68%, Test: 52.52%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5386884274698289\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 176, Loss: 0.4734, Loss Cls: 0.4734, Train: 54.70%, Valid: 52.79%, Test: 53.87%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5510918204604113\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 177, Loss: 0.4735, Loss Cls: 0.4735, Train: 54.32%, Valid: 52.04%, Test: 52.84%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5436595826845266\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 178, Loss: 0.4737, Loss Cls: 0.4737, Train: 54.53%, Valid: 52.44%, Test: 53.49%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5486069050758506\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 179, Loss: 0.4739, Loss Cls: 0.4739, Train: 54.66%, Valid: 52.22%, Test: 52.87%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5386147109149598\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 180, Loss: 0.4738, Loss Cls: 0.4738, Train: 54.11%, Valid: 52.00%, Test: 53.01%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5447004050573547\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 181, Loss: 0.4723, Loss Cls: 0.4723, Train: 55.25%, Valid: 53.03%, Test: 53.83%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5439268320733683\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 182, Loss: 0.4714, Loss Cls: 0.4714, Train: 53.53%, Valid: 51.45%, Test: 52.46%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5430862632597238\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 183, Loss: 0.4708, Loss Cls: 0.4708, Train: 55.84%, Valid: 53.47%, Test: 54.31%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5461953418584619\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 184, Loss: 0.4709, Loss Cls: 0.4709, Train: 53.35%, Valid: 51.60%, Test: 52.60%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5453156001713566\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 185, Loss: 0.4708, Loss Cls: 0.4708, Train: 56.21%, Valid: 53.61%, Test: 54.51%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.54814729636494\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 186, Loss: 0.4709, Loss Cls: 0.4709, Train: 53.26%, Valid: 51.89%, Test: 52.92%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.5447891726182277\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 187, Loss: 0.4712, Loss Cls: 0.4712, Train: 56.07%, Valid: 53.22%, Test: 54.07%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5484560255800469\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 188, Loss: 0.4714, Loss Cls: 0.4714, Train: 53.43%, Valid: 52.46%, Test: 53.49%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5434269281490749\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 189, Loss: 0.4719, Loss Cls: 0.4719, Train: 55.68%, Valid: 52.59%, Test: 53.38%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5472176529679232\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 190, Loss: 0.4716, Loss Cls: 0.4716, Train: 53.77%, Valid: 52.71%, Test: 53.75%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.544569682236921\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 191, Loss: 0.4711, Loss Cls: 0.4711, Train: 55.45%, Valid: 52.52%, Test: 53.32%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5471418005111766\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 192, Loss: 0.4703, Loss Cls: 0.4703, Train: 54.10%, Valid: 52.67%, Test: 53.74%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5459942002960518\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 193, Loss: 0.4700, Loss Cls: 0.4700, Train: 55.13%, Valid: 52.30%, Test: 53.09%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.5475987909954332\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 194, Loss: 0.4698, Loss Cls: 0.4698, Train: 54.45%, Valid: 52.86%, Test: 53.93%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.5469162875589092\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 195, Loss: 0.4699, Loss Cls: 0.4699, Train: 55.04%, Valid: 52.26%, Test: 53.00%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.54682612848492\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 196, Loss: 0.4701, Loss Cls: 0.4701, Train: 54.74%, Valid: 52.98%, Test: 54.08%\n",
            "num_B_prime:0, new edges:37928\n",
            "Batch 0.0, train acc:0.5477643819760356\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 197, Loss: 0.4700, Loss Cls: 0.4700, Train: 55.06%, Valid: 52.72%, Test: 53.54%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.549638699777803\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 198, Loss: 0.4699, Loss Cls: 0.4699, Train: 55.08%, Valid: 52.65%, Test: 53.67%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.5494365026307598\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 199, Loss: 0.4695, Loss Cls: 0.4695, Train: 55.03%, Valid: 53.15%, Test: 54.09%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5508323298443564\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 200, Loss: 0.4694, Loss Cls: 0.4694, Train: 55.23%, Valid: 52.47%, Test: 53.45%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5446178439450103\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 201, Loss: 0.4696, Loss Cls: 0.4696, Train: 54.80%, Valid: 53.08%, Test: 54.08%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5499254765185333\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 202, Loss: 0.4700, Loss Cls: 0.4700, Train: 55.02%, Valid: 52.61%, Test: 53.56%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5432349129800667\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 203, Loss: 0.4707, Loss Cls: 0.4707, Train: 54.72%, Valid: 52.62%, Test: 53.63%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.549807596624439\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 204, Loss: 0.4705, Loss Cls: 0.4705, Train: 54.73%, Valid: 52.77%, Test: 53.72%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5433285113873328\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 205, Loss: 0.4702, Loss Cls: 0.4702, Train: 54.93%, Valid: 52.34%, Test: 53.30%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5501375572873831\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 206, Loss: 0.4696, Loss Cls: 0.4696, Train: 54.36%, Valid: 52.69%, Test: 53.70%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5464479963765343\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 207, Loss: 0.4694, Loss Cls: 0.4694, Train: 55.31%, Valid: 52.39%, Test: 53.31%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5504647198261968\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 208, Loss: 0.4694, Loss Cls: 0.4694, Train: 54.78%, Valid: 53.07%, Test: 53.99%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5449447905251286\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 209, Loss: 0.4699, Loss Cls: 0.4699, Train: 55.52%, Valid: 52.42%, Test: 53.25%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5487034545077664\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 210, Loss: 0.4696, Loss Cls: 0.4696, Train: 54.79%, Valid: 53.16%, Test: 54.12%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5481725128811537\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 211, Loss: 0.4691, Loss Cls: 0.4691, Train: 55.37%, Valid: 52.61%, Test: 53.48%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5476185525109408\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 212, Loss: 0.4681, Loss Cls: 0.4681, Train: 54.82%, Valid: 53.18%, Test: 54.23%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.549495685961061\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 213, Loss: 0.4676, Loss Cls: 0.4676, Train: 55.15%, Valid: 52.42%, Test: 53.21%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5462600150165847\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 214, Loss: 0.4673, Loss Cls: 0.4673, Train: 55.01%, Valid: 53.43%, Test: 54.54%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.551167981559651\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 215, Loss: 0.4673, Loss Cls: 0.4673, Train: 54.96%, Valid: 51.85%, Test: 52.51%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5449663253489364\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 216, Loss: 0.4674, Loss Cls: 0.4674, Train: 55.19%, Valid: 53.87%, Test: 55.10%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5529249072623225\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 217, Loss: 0.4678, Loss Cls: 0.4678, Train: 54.60%, Valid: 51.10%, Test: 51.63%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5431750737874744\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 218, Loss: 0.4679, Loss Cls: 0.4679, Train: 55.27%, Valid: 54.16%, Test: 55.39%\n",
            "num_B_prime:0, new edges:37925\n",
            "Batch 0.0, train acc:0.5529092452117346\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 219, Loss: 0.4681, Loss Cls: 0.4681, Train: 54.65%, Valid: 51.37%, Test: 51.95%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.5475228035343354\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 220, Loss: 0.4682, Loss Cls: 0.4682, Train: 55.21%, Valid: 53.62%, Test: 54.77%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5499399289998074\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 221, Loss: 0.4679, Loss Cls: 0.4679, Train: 54.54%, Valid: 51.94%, Test: 52.65%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5485664998720933\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 222, Loss: 0.4681, Loss Cls: 0.4681, Train: 55.20%, Valid: 53.14%, Test: 54.18%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5511800440029136\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 223, Loss: 0.4681, Loss Cls: 0.4681, Train: 54.48%, Valid: 52.18%, Test: 52.99%\n",
            "num_B_prime:0, new edges:37922\n",
            "Batch 0.0, train acc:0.5492319008376008\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 224, Loss: 0.4682, Loss Cls: 0.4682, Train: 55.56%, Valid: 53.34%, Test: 54.43%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5539172608299292\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 225, Loss: 0.4677, Loss Cls: 0.4677, Train: 54.31%, Valid: 52.09%, Test: 52.94%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5454831751788864\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 226, Loss: 0.4681, Loss Cls: 0.4681, Train: 55.41%, Valid: 53.27%, Test: 54.34%\n",
            "num_B_prime:0, new edges:37929\n",
            "Batch 0.0, train acc:0.5578216770070257\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 227, Loss: 0.4684, Loss Cls: 0.4684, Train: 54.33%, Valid: 51.77%, Test: 52.51%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.545905726046639\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 228, Loss: 0.4684, Loss Cls: 0.4684, Train: 55.74%, Valid: 53.88%, Test: 54.88%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5552758885111599\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 229, Loss: 0.4673, Loss Cls: 0.4673, Train: 54.09%, Valid: 51.64%, Test: 52.51%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5450941094956967\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 230, Loss: 0.4661, Loss Cls: 0.4661, Train: 56.10%, Valid: 54.27%, Test: 55.31%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5602403806717031\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 231, Loss: 0.4665, Loss Cls: 0.4665, Train: 53.67%, Valid: 51.02%, Test: 51.79%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5471941097339998\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 232, Loss: 0.4675, Loss Cls: 0.4675, Train: 56.42%, Valid: 54.62%, Test: 55.72%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5566750583061486\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 233, Loss: 0.4685, Loss Cls: 0.4685, Train: 52.83%, Valid: 49.89%, Test: 50.54%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5491339260065845\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 234, Loss: 0.4684, Loss Cls: 0.4684, Train: 56.44%, Valid: 54.69%, Test: 55.73%\n",
            "num_B_prime:0, new edges:37920\n",
            "Batch 0.0, train acc:0.5522832131536856\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 235, Loss: 0.4678, Loss Cls: 0.4678, Train: 52.11%, Valid: 49.25%, Test: 49.94%\n",
            "num_B_prime:0, new edges:37923\n",
            "Batch 0.0, train acc:0.5481210647602112\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 236, Loss: 0.4679, Loss Cls: 0.4679, Train: 56.35%, Valid: 54.45%, Test: 55.49%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5523268621445778\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 237, Loss: 0.4673, Loss Cls: 0.4673, Train: 52.58%, Valid: 49.92%, Test: 50.69%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.545855508208514\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 238, Loss: 0.4669, Loss Cls: 0.4669, Train: 56.29%, Valid: 54.21%, Test: 55.23%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5565861479893028\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 239, Loss: 0.4665, Loss Cls: 0.4665, Train: 53.52%, Valid: 51.30%, Test: 52.09%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5485757367062186\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 240, Loss: 0.4664, Loss Cls: 0.4664, Train: 55.91%, Valid: 53.62%, Test: 54.58%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5554899219274337\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 241, Loss: 0.4668, Loss Cls: 0.4668, Train: 54.35%, Valid: 52.43%, Test: 53.27%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5490677689867606\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 242, Loss: 0.4671, Loss Cls: 0.4671, Train: 55.44%, Valid: 52.74%, Test: 53.66%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.557331864308065\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 243, Loss: 0.4673, Loss Cls: 0.4673, Train: 54.66%, Valid: 52.92%, Test: 53.84%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5384963957234304\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 244, Loss: 0.4673, Loss Cls: 0.4673, Train: 54.84%, Valid: 51.66%, Test: 52.58%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5540914398332828\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 245, Loss: 0.4668, Loss Cls: 0.4668, Train: 54.87%, Valid: 53.19%, Test: 54.17%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5396680539537683\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 246, Loss: 0.4662, Loss Cls: 0.4662, Train: 55.06%, Valid: 51.61%, Test: 52.42%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5536906594167893\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 247, Loss: 0.4656, Loss Cls: 0.4656, Train: 54.86%, Valid: 53.19%, Test: 54.24%\n",
            "num_B_prime:0, new edges:37926\n",
            "Batch 0.0, train acc:0.5438300629290069\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 248, Loss: 0.4650, Loss Cls: 0.4650, Train: 55.15%, Valid: 51.60%, Test: 52.40%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5551093802651396\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 249, Loss: 0.4649, Loss Cls: 0.4649, Train: 54.73%, Valid: 53.22%, Test: 54.36%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5438438701968675\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 250, Loss: 0.4649, Loss Cls: 0.4649, Train: 55.39%, Valid: 51.49%, Test: 52.09%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5549824997312245\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 251, Loss: 0.4657, Loss Cls: 0.4657, Train: 54.23%, Valid: 53.20%, Test: 54.50%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5439691688342443\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 252, Loss: 0.4664, Loss Cls: 0.4664, Train: 55.73%, Valid: 51.89%, Test: 52.46%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5549243976473638\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 253, Loss: 0.4672, Loss Cls: 0.4672, Train: 54.10%, Valid: 52.80%, Test: 54.05%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5506430549798146\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 254, Loss: 0.4660, Loss Cls: 0.4660, Train: 55.99%, Valid: 53.18%, Test: 53.91%\n",
            "num_B_prime:0, new edges:37923\n",
            "Batch 0.0, train acc:0.5531547357305043\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 255, Loss: 0.4655, Loss Cls: 0.4655, Train: 54.34%, Valid: 52.25%, Test: 53.43%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.551316595223515\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 256, Loss: 0.4644, Loss Cls: 0.4644, Train: 55.91%, Valid: 53.56%, Test: 54.44%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5555361721130412\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 257, Loss: 0.4641, Loss Cls: 0.4641, Train: 54.79%, Valid: 52.45%, Test: 53.52%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5518374365648251\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 258, Loss: 0.4640, Loss Cls: 0.4640, Train: 55.66%, Valid: 53.40%, Test: 54.29%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5575975071968384\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 259, Loss: 0.4641, Loss Cls: 0.4641, Train: 55.02%, Valid: 52.69%, Test: 53.69%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5469017224034527\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 260, Loss: 0.4643, Loss Cls: 0.4643, Train: 55.32%, Valid: 53.13%, Test: 53.97%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5582107339677042\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 261, Loss: 0.4643, Loss Cls: 0.4643, Train: 55.30%, Valid: 53.03%, Test: 54.05%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.547959736116138\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 262, Loss: 0.4642, Loss Cls: 0.4642, Train: 55.34%, Valid: 52.97%, Test: 53.86%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5575844452531808\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 263, Loss: 0.4639, Loss Cls: 0.4639, Train: 55.44%, Valid: 53.27%, Test: 54.32%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5515684269614078\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 264, Loss: 0.4635, Loss Cls: 0.4635, Train: 55.50%, Valid: 52.91%, Test: 53.80%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5535806030794025\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 265, Loss: 0.4633, Loss Cls: 0.4633, Train: 55.74%, Valid: 53.59%, Test: 54.65%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5530857199498135\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 266, Loss: 0.4632, Loss Cls: 0.4632, Train: 55.27%, Valid: 52.53%, Test: 53.43%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.553688063359172\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 267, Loss: 0.4634, Loss Cls: 0.4634, Train: 55.63%, Valid: 53.89%, Test: 55.03%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5518293281612763\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 268, Loss: 0.4638, Loss Cls: 0.4638, Train: 55.41%, Valid: 52.33%, Test: 53.07%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5524982109460036\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 269, Loss: 0.4646, Loss Cls: 0.4646, Train: 55.08%, Valid: 53.56%, Test: 54.63%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5539092499296117\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 270, Loss: 0.4649, Loss Cls: 0.4649, Train: 55.59%, Valid: 52.50%, Test: 53.24%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5536793192877597\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 271, Loss: 0.4646, Loss Cls: 0.4646, Train: 54.67%, Valid: 52.96%, Test: 54.03%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5540737915711499\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 272, Loss: 0.4640, Loss Cls: 0.4640, Train: 56.09%, Valid: 52.95%, Test: 53.78%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5516289532493983\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 273, Loss: 0.4634, Loss Cls: 0.4634, Train: 54.68%, Valid: 52.79%, Test: 53.81%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5598679041318169\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 274, Loss: 0.4634, Loss Cls: 0.4634, Train: 56.14%, Valid: 53.03%, Test: 53.90%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5540138393742823\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 275, Loss: 0.4633, Loss Cls: 0.4633, Train: 54.78%, Valid: 52.76%, Test: 53.81%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5515236655727684\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 276, Loss: 0.4637, Loss Cls: 0.4637, Train: 56.32%, Valid: 53.36%, Test: 54.24%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5548532193956582\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 277, Loss: 0.4639, Loss Cls: 0.4639, Train: 54.64%, Valid: 52.38%, Test: 53.42%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5526090180224271\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 278, Loss: 0.4644, Loss Cls: 0.4644, Train: 56.29%, Valid: 53.71%, Test: 54.66%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5542802929634567\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 279, Loss: 0.4641, Loss Cls: 0.4641, Train: 54.49%, Valid: 52.06%, Test: 53.06%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5528808298926895\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 280, Loss: 0.4641, Loss Cls: 0.4641, Train: 56.28%, Valid: 53.89%, Test: 54.85%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.553922775702394\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 281, Loss: 0.4639, Loss Cls: 0.4639, Train: 54.23%, Valid: 51.55%, Test: 52.53%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5518262593825547\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 282, Loss: 0.4642, Loss Cls: 0.4642, Train: 55.87%, Valid: 53.81%, Test: 54.75%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5536238896761484\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 283, Loss: 0.4640, Loss Cls: 0.4640, Train: 54.50%, Valid: 51.66%, Test: 52.63%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5527604101891529\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 284, Loss: 0.4636, Loss Cls: 0.4636, Train: 55.69%, Valid: 53.49%, Test: 54.41%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5519014800724042\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 285, Loss: 0.4631, Loss Cls: 0.4631, Train: 54.45%, Valid: 51.96%, Test: 53.06%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5569523612971151\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 286, Loss: 0.4627, Loss Cls: 0.4627, Train: 55.73%, Valid: 53.14%, Test: 53.94%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5511313796626891\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 287, Loss: 0.4627, Loss Cls: 0.4627, Train: 54.79%, Valid: 52.60%, Test: 53.76%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5558082632931433\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 288, Loss: 0.4629, Loss Cls: 0.4629, Train: 55.46%, Valid: 52.41%, Test: 53.19%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.555233835830093\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 289, Loss: 0.4638, Loss Cls: 0.4638, Train: 55.06%, Valid: 53.12%, Test: 54.26%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.556884047700394\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 290, Loss: 0.4641, Loss Cls: 0.4641, Train: 54.98%, Valid: 51.79%, Test: 52.50%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5533018239039769\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 291, Loss: 0.4643, Loss Cls: 0.4643, Train: 55.30%, Valid: 53.49%, Test: 54.67%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5559342567993284\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 292, Loss: 0.4633, Loss Cls: 0.4633, Train: 54.94%, Valid: 51.68%, Test: 52.38%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5520638960850739\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 293, Loss: 0.4626, Loss Cls: 0.4626, Train: 55.72%, Valid: 53.84%, Test: 54.97%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5548953781995304\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 294, Loss: 0.4620, Loss Cls: 0.4620, Train: 55.18%, Valid: 51.76%, Test: 52.45%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5533296009126825\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 295, Loss: 0.4617, Loss Cls: 0.4617, Train: 55.67%, Valid: 53.94%, Test: 55.10%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5551675486732683\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 296, Loss: 0.4615, Loss Cls: 0.4615, Train: 55.35%, Valid: 51.89%, Test: 52.62%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5554078898571702\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 297, Loss: 0.4617, Loss Cls: 0.4617, Train: 55.62%, Valid: 53.91%, Test: 55.12%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5530954551491807\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 298, Loss: 0.4619, Loss Cls: 0.4619, Train: 55.44%, Valid: 52.00%, Test: 52.74%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5563937851441537\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 299, Loss: 0.4622, Loss Cls: 0.4622, Train: 55.55%, Valid: 53.89%, Test: 55.09%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5546719031992975\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 300, Loss: 0.4626, Loss Cls: 0.4626, Train: 55.10%, Valid: 51.90%, Test: 52.68%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5549576366929079\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 301, Loss: 0.4629, Loss Cls: 0.4629, Train: 55.14%, Valid: 53.08%, Test: 54.20%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5527633453527423\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 302, Loss: 0.4630, Loss Cls: 0.4630, Train: 55.01%, Valid: 52.20%, Test: 53.03%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5515772909963901\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 303, Loss: 0.4625, Loss Cls: 0.4625, Train: 54.82%, Valid: 52.15%, Test: 53.21%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5504392638185788\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 304, Loss: 0.4621, Loss Cls: 0.4621, Train: 55.27%, Valid: 53.00%, Test: 53.87%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5529370038704747\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 305, Loss: 0.4615, Loss Cls: 0.4615, Train: 54.96%, Valid: 52.10%, Test: 53.19%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5544114501256512\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 306, Loss: 0.4615, Loss Cls: 0.4615, Train: 55.58%, Valid: 53.47%, Test: 54.34%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5581341899762334\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 307, Loss: 0.4615, Loss Cls: 0.4615, Train: 55.09%, Valid: 52.42%, Test: 53.59%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5550835643051029\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 308, Loss: 0.4616, Loss Cls: 0.4616, Train: 55.99%, Valid: 53.64%, Test: 54.48%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5577927632352025\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 309, Loss: 0.4620, Loss Cls: 0.4620, Train: 55.13%, Valid: 52.52%, Test: 53.75%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5589577182827539\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 310, Loss: 0.4620, Loss Cls: 0.4620, Train: 56.13%, Valid: 53.45%, Test: 54.20%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.5576791923410365\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 311, Loss: 0.4626, Loss Cls: 0.4626, Train: 55.03%, Valid: 52.60%, Test: 53.76%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5594802237111672\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 312, Loss: 0.4627, Loss Cls: 0.4627, Train: 56.26%, Valid: 53.26%, Test: 53.96%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5545757713597435\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 313, Loss: 0.4640, Loss Cls: 0.4640, Train: 54.52%, Valid: 52.46%, Test: 53.70%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5552111607975782\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 314, Loss: 0.4636, Loss Cls: 0.4636, Train: 56.18%, Valid: 52.94%, Test: 53.71%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5569501984502337\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 315, Loss: 0.4635, Loss Cls: 0.4635, Train: 54.98%, Valid: 53.06%, Test: 54.34%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5540555491155089\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 316, Loss: 0.4621, Loss Cls: 0.4621, Train: 55.91%, Valid: 52.61%, Test: 53.44%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5590997259424424\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 317, Loss: 0.4614, Loss Cls: 0.4614, Train: 55.71%, Valid: 53.86%, Test: 55.03%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5564268123013995\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 318, Loss: 0.4609, Loss Cls: 0.4609, Train: 55.33%, Valid: 51.77%, Test: 52.68%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5609174664192851\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 319, Loss: 0.4606, Loss Cls: 0.4606, Train: 55.98%, Valid: 54.32%, Test: 55.48%\n",
            "num_B_prime:0, new edges:37930\n",
            "Batch 0.0, train acc:0.5551964353310521\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 320, Loss: 0.4609, Loss Cls: 0.4609, Train: 55.02%, Valid: 50.99%, Test: 51.82%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.5617311233477817\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 321, Loss: 0.4610, Loss Cls: 0.4610, Train: 55.90%, Valid: 54.45%, Test: 55.56%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5537515811731833\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 322, Loss: 0.4615, Loss Cls: 0.4615, Train: 54.58%, Valid: 50.54%, Test: 51.25%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5606096205793863\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 323, Loss: 0.4616, Loss Cls: 0.4616, Train: 55.86%, Valid: 54.44%, Test: 55.52%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5509522351604852\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 324, Loss: 0.4617, Loss Cls: 0.4617, Train: 54.74%, Valid: 51.19%, Test: 51.92%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5619902848542102\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 325, Loss: 0.4612, Loss Cls: 0.4612, Train: 56.01%, Valid: 54.13%, Test: 55.21%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5506744214824898\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 326, Loss: 0.4608, Loss Cls: 0.4608, Train: 55.27%, Valid: 52.27%, Test: 53.09%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5591722312207705\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 327, Loss: 0.4605, Loss Cls: 0.4605, Train: 55.97%, Valid: 53.80%, Test: 54.93%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.555981054420334\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 328, Loss: 0.4605, Loss Cls: 0.4605, Train: 55.73%, Valid: 52.81%, Test: 53.71%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5605607954876715\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 329, Loss: 0.4607, Loss Cls: 0.4607, Train: 55.59%, Valid: 53.36%, Test: 54.47%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5597784089198439\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 330, Loss: 0.4609, Loss Cls: 0.4609, Train: 56.08%, Valid: 53.13%, Test: 54.00%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5578313784119598\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 331, Loss: 0.4613, Loss Cls: 0.4613, Train: 55.14%, Valid: 53.03%, Test: 54.22%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5610425799788855\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 332, Loss: 0.4609, Loss Cls: 0.4609, Train: 56.10%, Valid: 53.30%, Test: 54.25%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5541928921483804\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 333, Loss: 0.4612, Loss Cls: 0.4612, Train: 54.77%, Valid: 52.27%, Test: 53.46%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5626427591664858\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 334, Loss: 0.4615, Loss Cls: 0.4615, Train: 55.96%, Valid: 53.41%, Test: 54.26%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5508351311179168\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 335, Loss: 0.4616, Loss Cls: 0.4616, Train: 54.72%, Valid: 52.14%, Test: 53.37%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.558780842885507\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 336, Loss: 0.4603, Loss Cls: 0.4603, Train: 55.96%, Valid: 53.39%, Test: 54.34%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.550924149982951\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 337, Loss: 0.4596, Loss Cls: 0.4596, Train: 55.39%, Valid: 52.62%, Test: 53.82%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5604814539167772\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 338, Loss: 0.4589, Loss Cls: 0.4589, Train: 56.07%, Valid: 53.35%, Test: 54.33%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5528717882041467\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 339, Loss: 0.4590, Loss Cls: 0.4590, Train: 55.59%, Valid: 53.12%, Test: 54.28%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5624002062558836\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 340, Loss: 0.4590, Loss Cls: 0.4590, Train: 55.77%, Valid: 52.93%, Test: 53.91%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5549201758558908\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 341, Loss: 0.4594, Loss Cls: 0.4594, Train: 56.03%, Valid: 53.63%, Test: 54.72%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.56343441248783\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 342, Loss: 0.4594, Loss Cls: 0.4594, Train: 55.40%, Valid: 52.43%, Test: 53.48%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.554846957118021\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 343, Loss: 0.4598, Loss Cls: 0.4598, Train: 56.55%, Valid: 54.18%, Test: 55.23%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5591319103064561\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 344, Loss: 0.4603, Loss Cls: 0.4603, Train: 54.90%, Valid: 51.97%, Test: 53.12%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5545075517084963\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 345, Loss: 0.4609, Loss Cls: 0.4609, Train: 56.80%, Valid: 54.22%, Test: 55.10%\n",
            "num_B_prime:0, new edges:37925\n",
            "Batch 0.0, train acc:0.5619011722164252\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 346, Loss: 0.4620, Loss Cls: 0.4620, Train: 54.52%, Valid: 52.01%, Test: 53.12%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5521071790730294\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 347, Loss: 0.4616, Loss Cls: 0.4616, Train: 56.86%, Valid: 53.77%, Test: 54.64%\n",
            "num_B_prime:0, new edges:37926\n",
            "Batch 0.0, train acc:0.5643095242391954\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 348, Loss: 0.4612, Loss Cls: 0.4612, Train: 54.30%, Valid: 52.27%, Test: 53.41%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.552787721611766\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 349, Loss: 0.4607, Loss Cls: 0.4607, Train: 56.59%, Valid: 53.26%, Test: 54.13%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5615889000234457\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 350, Loss: 0.4605, Loss Cls: 0.4605, Train: 54.28%, Valid: 52.39%, Test: 53.50%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5533442275641183\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 351, Loss: 0.4608, Loss Cls: 0.4608, Train: 56.54%, Valid: 53.02%, Test: 53.93%\n",
            "num_B_prime:0, new edges:37927\n",
            "Batch 0.0, train acc:0.5614083083053316\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 352, Loss: 0.4608, Loss Cls: 0.4608, Train: 54.11%, Valid: 52.34%, Test: 53.55%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5509109972351354\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 353, Loss: 0.4608, Loss Cls: 0.4608, Train: 56.73%, Valid: 53.07%, Test: 53.90%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5607236662300262\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 354, Loss: 0.4604, Loss Cls: 0.4604, Train: 54.55%, Valid: 52.80%, Test: 53.96%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5522269470991531\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 355, Loss: 0.4601, Loss Cls: 0.4601, Train: 56.27%, Valid: 52.70%, Test: 53.56%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5595412308659155\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 356, Loss: 0.4595, Loss Cls: 0.4595, Train: 54.75%, Valid: 53.17%, Test: 54.32%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5543880506597505\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 357, Loss: 0.4593, Loss Cls: 0.4593, Train: 56.00%, Valid: 52.31%, Test: 53.11%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5579339767500284\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 358, Loss: 0.4589, Loss Cls: 0.4589, Train: 55.31%, Valid: 53.70%, Test: 54.87%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5591307293391948\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 359, Loss: 0.4591, Loss Cls: 0.4591, Train: 55.72%, Valid: 51.86%, Test: 52.64%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5527520535959348\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 360, Loss: 0.4593, Loss Cls: 0.4593, Train: 55.52%, Valid: 53.88%, Test: 54.96%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5599475972131245\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 361, Loss: 0.4604, Loss Cls: 0.4604, Train: 55.59%, Valid: 51.63%, Test: 52.36%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5502888985706322\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 362, Loss: 0.4603, Loss Cls: 0.4603, Train: 55.92%, Valid: 53.77%, Test: 54.81%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5591070924327564\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 363, Loss: 0.4593, Loss Cls: 0.4593, Train: 56.07%, Valid: 52.65%, Test: 53.55%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.5562524726392684\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 364, Loss: 0.4588, Loss Cls: 0.4588, Train: 55.54%, Valid: 52.81%, Test: 53.73%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5587807913141929\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 365, Loss: 0.4588, Loss Cls: 0.4588, Train: 56.29%, Valid: 53.35%, Test: 54.50%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5608089399581802\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 366, Loss: 0.4590, Loss Cls: 0.4590, Train: 55.28%, Valid: 51.95%, Test: 52.72%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.553622171973059\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 367, Loss: 0.4597, Loss Cls: 0.4597, Train: 56.36%, Valid: 53.92%, Test: 55.07%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5628632636609405\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 368, Loss: 0.4590, Loss Cls: 0.4590, Train: 55.47%, Valid: 52.07%, Test: 52.78%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5522686368442746\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 369, Loss: 0.4590, Loss Cls: 0.4590, Train: 56.06%, Valid: 53.88%, Test: 55.04%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5625716568227324\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 370, Loss: 0.4590, Loss Cls: 0.4590, Train: 55.55%, Valid: 51.94%, Test: 52.66%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5521048190068611\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 371, Loss: 0.4600, Loss Cls: 0.4600, Train: 55.43%, Valid: 53.37%, Test: 54.58%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5603360639145428\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 372, Loss: 0.4608, Loss Cls: 0.4608, Train: 55.64%, Valid: 52.03%, Test: 52.68%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5475359727569569\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 373, Loss: 0.4612, Loss Cls: 0.4612, Train: 55.14%, Valid: 53.03%, Test: 54.19%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.564386273752633\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 374, Loss: 0.4595, Loss Cls: 0.4595, Train: 56.10%, Valid: 53.44%, Test: 54.31%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5532333190239622\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 375, Loss: 0.4587, Loss Cls: 0.4587, Train: 55.01%, Valid: 52.11%, Test: 53.17%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5624834035567919\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 376, Loss: 0.4583, Loss Cls: 0.4583, Train: 56.10%, Valid: 53.72%, Test: 54.64%\n",
            "num_B_prime:0, new edges:37925\n",
            "Batch 0.0, train acc:0.5575650553430669\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 377, Loss: 0.4580, Loss Cls: 0.4580, Train: 55.39%, Valid: 52.56%, Test: 53.59%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5559823976489855\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 378, Loss: 0.4577, Loss Cls: 0.4577, Train: 56.03%, Valid: 53.41%, Test: 54.34%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5615458603320314\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 379, Loss: 0.4579, Loss Cls: 0.4579, Train: 55.81%, Valid: 53.03%, Test: 54.04%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5535994567803527\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 380, Loss: 0.4582, Loss Cls: 0.4582, Train: 55.59%, Valid: 52.93%, Test: 53.87%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5594338117217686\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 381, Loss: 0.4593, Loss Cls: 0.4593, Train: 56.09%, Valid: 53.48%, Test: 54.49%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5517781594269677\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 382, Loss: 0.4595, Loss Cls: 0.4595, Train: 55.19%, Valid: 52.50%, Test: 53.48%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5645789152654926\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 383, Loss: 0.4599, Loss Cls: 0.4599, Train: 56.18%, Valid: 53.65%, Test: 54.70%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5538128656614059\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 384, Loss: 0.4588, Loss Cls: 0.4588, Train: 55.52%, Valid: 52.64%, Test: 53.64%\n",
            "num_B_prime:0, new edges:37926\n",
            "Batch 0.0, train acc:0.5645565238826056\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 385, Loss: 0.4579, Loss Cls: 0.4579, Train: 55.95%, Valid: 53.69%, Test: 54.85%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5586415794377302\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 386, Loss: 0.4574, Loss Cls: 0.4574, Train: 55.61%, Valid: 52.45%, Test: 53.36%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5651367238300012\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 387, Loss: 0.4574, Loss Cls: 0.4574, Train: 56.07%, Valid: 53.80%, Test: 54.95%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5593680656072131\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 388, Loss: 0.4579, Loss Cls: 0.4579, Train: 55.76%, Valid: 52.11%, Test: 52.98%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5651889420210483\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 389, Loss: 0.4584, Loss Cls: 0.4584, Train: 55.79%, Valid: 53.92%, Test: 55.11%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5600538609713677\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 390, Loss: 0.4587, Loss Cls: 0.4587, Train: 56.14%, Valid: 52.13%, Test: 53.01%\n",
            "num_B_prime:0, new edges:37931\n",
            "Batch 0.0, train acc:0.562164929913036\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 391, Loss: 0.4584, Loss Cls: 0.4584, Train: 55.56%, Valid: 53.64%, Test: 54.87%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5568161596765777\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 392, Loss: 0.4589, Loss Cls: 0.4589, Train: 56.29%, Valid: 51.85%, Test: 52.58%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5569404122834318\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 393, Loss: 0.4590, Loss Cls: 0.4590, Train: 55.59%, Valid: 53.87%, Test: 55.15%\n",
            "num_B_prime:0, new edges:37933\n",
            "Batch 0.0, train acc:0.5581766418595843\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 394, Loss: 0.4584, Loss Cls: 0.4584, Train: 56.47%, Valid: 52.54%, Test: 53.36%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5577628700149224\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 395, Loss: 0.4587, Loss Cls: 0.4587, Train: 55.17%, Valid: 53.13%, Test: 54.33%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5602511048253509\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 396, Loss: 0.4592, Loss Cls: 0.4592, Train: 56.32%, Valid: 52.79%, Test: 53.60%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5584484986842259\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 397, Loss: 0.4596, Loss Cls: 0.4596, Train: 55.16%, Valid: 53.01%, Test: 54.13%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5646785611763175\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 398, Loss: 0.4592, Loss Cls: 0.4592, Train: 56.16%, Valid: 52.65%, Test: 53.46%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5601219894584385\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 399, Loss: 0.4588, Loss Cls: 0.4588, Train: 55.73%, Valid: 53.31%, Test: 54.32%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5637931487275696\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 400, Loss: 0.4582, Loss Cls: 0.4582, Train: 55.68%, Valid: 52.12%, Test: 53.04%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5585758670241078\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 401, Loss: 0.4580, Loss Cls: 0.4580, Train: 55.94%, Valid: 53.54%, Test: 54.66%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5583033721702094\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 402, Loss: 0.4578, Loss Cls: 0.4578, Train: 55.56%, Valid: 52.08%, Test: 52.96%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5573927694835109\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 403, Loss: 0.4580, Loss Cls: 0.4580, Train: 55.91%, Valid: 53.45%, Test: 54.52%\n",
            "num_B_prime:0, new edges:37922\n",
            "Batch 0.0, train acc:0.5565615977572163\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 404, Loss: 0.4576, Loss Cls: 0.4576, Train: 55.71%, Valid: 52.48%, Test: 53.44%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5585392124167395\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 405, Loss: 0.4573, Loss Cls: 0.4573, Train: 56.00%, Valid: 53.47%, Test: 54.51%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5618439928272564\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 406, Loss: 0.4574, Loss Cls: 0.4574, Train: 56.13%, Valid: 52.77%, Test: 53.82%\n",
            "num_B_prime:0, new edges:37926\n",
            "Batch 0.0, train acc:0.5574858570820528\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 407, Loss: 0.4585, Loss Cls: 0.4585, Train: 55.55%, Valid: 52.48%, Test: 53.59%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5661709057823546\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 408, Loss: 0.4606, Loss Cls: 0.4606, Train: 55.77%, Valid: 52.73%, Test: 53.70%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.554044019433389\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 409, Loss: 0.4606, Loss Cls: 0.4606, Train: 55.71%, Valid: 53.06%, Test: 54.13%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5677219927038704\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 410, Loss: 0.4575, Loss Cls: 0.4575, Train: 56.52%, Valid: 53.49%, Test: 54.41%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5556692840226252\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 411, Loss: 0.4558, Loss Cls: 0.4558, Train: 55.91%, Valid: 53.03%, Test: 54.12%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5674602896029718\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 412, Loss: 0.4555, Loss Cls: 0.4555, Train: 56.48%, Valid: 53.43%, Test: 54.32%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5557967482940709\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 413, Loss: 0.4556, Loss Cls: 0.4556, Train: 56.01%, Valid: 53.46%, Test: 54.57%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5671851744861498\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 414, Loss: 0.4560, Loss Cls: 0.4560, Train: 56.39%, Valid: 52.84%, Test: 53.72%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5543716214806992\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 415, Loss: 0.4569, Loss Cls: 0.4569, Train: 56.01%, Valid: 53.63%, Test: 54.92%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5674357753644357\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 416, Loss: 0.4577, Loss Cls: 0.4577, Train: 56.18%, Valid: 52.21%, Test: 52.95%\n",
            "num_B_prime:0, new edges:37928\n",
            "Batch 0.0, train acc:0.5521693961776084\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 417, Loss: 0.4583, Loss Cls: 0.4583, Train: 56.18%, Valid: 54.13%, Test: 55.36%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5670774138550255\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 418, Loss: 0.4586, Loss Cls: 0.4586, Train: 55.70%, Valid: 51.87%, Test: 52.63%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5505048521402307\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 419, Loss: 0.4585, Loss Cls: 0.4585, Train: 56.29%, Valid: 53.91%, Test: 55.05%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5688049074651086\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 420, Loss: 0.4581, Loss Cls: 0.4581, Train: 55.72%, Valid: 52.42%, Test: 53.24%\n",
            "num_B_prime:0, new edges:37927\n",
            "Batch 0.0, train acc:0.5523540095264566\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 421, Loss: 0.4574, Loss Cls: 0.4574, Train: 56.40%, Valid: 53.62%, Test: 54.68%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.566316651964819\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 422, Loss: 0.4568, Loss Cls: 0.4568, Train: 55.44%, Valid: 52.63%, Test: 53.61%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.55711251243103\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 423, Loss: 0.4565, Loss Cls: 0.4565, Train: 56.52%, Valid: 53.41%, Test: 54.49%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5646496950265117\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 424, Loss: 0.4559, Loss Cls: 0.4559, Train: 55.44%, Valid: 52.86%, Test: 53.90%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5593563170965754\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 425, Loss: 0.4555, Loss Cls: 0.4555, Train: 56.52%, Valid: 53.35%, Test: 54.44%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5654856988245823\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 426, Loss: 0.4552, Loss Cls: 0.4552, Train: 55.48%, Valid: 52.83%, Test: 53.90%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5586560433224765\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 427, Loss: 0.4552, Loss Cls: 0.4552, Train: 56.86%, Valid: 53.52%, Test: 54.57%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5636801017718351\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 428, Loss: 0.4555, Loss Cls: 0.4555, Train: 54.92%, Valid: 52.36%, Test: 53.50%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5605474572284996\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 429, Loss: 0.4561, Loss Cls: 0.4561, Train: 57.00%, Valid: 53.57%, Test: 54.54%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.559581464693673\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 430, Loss: 0.4568, Loss Cls: 0.4568, Train: 54.35%, Valid: 52.00%, Test: 53.18%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.560950225669631\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 431, Loss: 0.4575, Loss Cls: 0.4575, Train: 57.17%, Valid: 53.47%, Test: 54.31%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5629063937609494\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 432, Loss: 0.4574, Loss Cls: 0.4574, Train: 54.53%, Valid: 52.38%, Test: 53.55%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5615437722890321\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 433, Loss: 0.4573, Loss Cls: 0.4573, Train: 56.80%, Valid: 52.86%, Test: 53.72%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5662534051796391\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 434, Loss: 0.4574, Loss Cls: 0.4574, Train: 55.15%, Valid: 52.95%, Test: 54.14%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5559129586308045\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 435, Loss: 0.4575, Loss Cls: 0.4575, Train: 56.61%, Valid: 52.52%, Test: 53.39%\n",
            "num_B_prime:0, new edges:37935\n",
            "Batch 0.0, train acc:0.5635838697498224\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 436, Loss: 0.4580, Loss Cls: 0.4580, Train: 55.65%, Valid: 53.35%, Test: 54.54%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5583121850589183\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 437, Loss: 0.4574, Loss Cls: 0.4574, Train: 56.09%, Valid: 52.28%, Test: 53.14%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5651586823167548\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 438, Loss: 0.4575, Loss Cls: 0.4575, Train: 56.12%, Valid: 53.60%, Test: 54.80%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5550403351457674\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 439, Loss: 0.4564, Loss Cls: 0.4564, Train: 55.70%, Valid: 52.21%, Test: 53.08%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.56643540983849\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 440, Loss: 0.4563, Loss Cls: 0.4563, Train: 56.47%, Valid: 53.81%, Test: 54.93%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5554184697961484\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 441, Loss: 0.4558, Loss Cls: 0.4558, Train: 55.58%, Valid: 52.16%, Test: 53.09%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5651218022462848\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 442, Loss: 0.4559, Loss Cls: 0.4559, Train: 56.72%, Valid: 54.10%, Test: 55.16%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5593185222241979\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 443, Loss: 0.4557, Loss Cls: 0.4557, Train: 55.64%, Valid: 52.07%, Test: 53.09%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5627169149803214\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 444, Loss: 0.4555, Loss Cls: 0.4555, Train: 56.84%, Valid: 54.32%, Test: 55.36%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5603875895196407\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 445, Loss: 0.4551, Loss Cls: 0.4551, Train: 55.79%, Valid: 52.02%, Test: 53.02%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.562582658876705\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 446, Loss: 0.4550, Loss Cls: 0.4550, Train: 56.51%, Valid: 54.28%, Test: 55.34%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5634609850622438\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 447, Loss: 0.4552, Loss Cls: 0.4552, Train: 56.24%, Valid: 52.08%, Test: 53.04%\n",
            "num_B_prime:0, new edges:37936\n",
            "Batch 0.0, train acc:0.5600031797015056\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 448, Loss: 0.4557, Loss Cls: 0.4557, Train: 56.25%, Valid: 54.19%, Test: 55.29%\n",
            "num_B_prime:0, new edges:37932\n",
            "Batch 0.0, train acc:0.5652199113206271\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 449, Loss: 0.4561, Loss Cls: 0.4561, Train: 56.40%, Valid: 52.16%, Test: 53.04%\n",
            "num_B_prime:0, new edges:37923\n",
            "Batch 0.0, train acc:0.5559360264626334\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 450, Loss: 0.4565, Loss Cls: 0.4565, Train: 55.74%, Valid: 53.88%, Test: 54.99%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5620453381698437\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 451, Loss: 0.4563, Loss Cls: 0.4563, Train: 56.35%, Valid: 52.41%, Test: 53.26%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5557374702863491\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 452, Loss: 0.4559, Loss Cls: 0.4559, Train: 55.88%, Valid: 53.70%, Test: 54.85%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5610339242791734\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 453, Loss: 0.4554, Loss Cls: 0.4554, Train: 55.87%, Valid: 52.35%, Test: 53.24%\n",
            "num_B_prime:0, new edges:37940\n",
            "Batch 0.0, train acc:0.5558887558362171\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 454, Loss: 0.4551, Loss Cls: 0.4551, Train: 55.65%, Valid: 53.44%, Test: 54.69%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5617816048823101\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 455, Loss: 0.4550, Loss Cls: 0.4550, Train: 56.10%, Valid: 52.45%, Test: 53.34%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5594256622892759\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 456, Loss: 0.4554, Loss Cls: 0.4554, Train: 55.63%, Valid: 53.36%, Test: 54.70%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5590211725549663\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 457, Loss: 0.4558, Loss Cls: 0.4558, Train: 56.17%, Valid: 52.40%, Test: 53.29%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5557986260464586\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 458, Loss: 0.4567, Loss Cls: 0.4567, Train: 55.55%, Valid: 53.32%, Test: 54.63%\n",
            "num_B_prime:0, new edges:37929\n",
            "Batch 0.0, train acc:0.5588170373500938\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 459, Loss: 0.4567, Loss Cls: 0.4567, Train: 56.22%, Valid: 52.41%, Test: 53.30%\n",
            "num_B_prime:0, new edges:37938\n",
            "Batch 0.0, train acc:0.5641558641958136\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 460, Loss: 0.4570, Loss Cls: 0.4570, Train: 55.72%, Valid: 53.26%, Test: 54.45%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5604885670717376\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 461, Loss: 0.4564, Loss Cls: 0.4564, Train: 56.31%, Valid: 52.60%, Test: 53.50%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5635868674680848\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 462, Loss: 0.4560, Loss Cls: 0.4560, Train: 55.87%, Valid: 53.37%, Test: 54.50%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5629775918849108\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 463, Loss: 0.4556, Loss Cls: 0.4556, Train: 56.43%, Valid: 52.65%, Test: 53.61%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.563394188530206\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 464, Loss: 0.4554, Loss Cls: 0.4554, Train: 55.59%, Valid: 53.11%, Test: 54.26%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5630656604347822\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 465, Loss: 0.4555, Loss Cls: 0.4555, Train: 56.76%, Valid: 52.89%, Test: 53.86%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5633643596183722\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 466, Loss: 0.4553, Loss Cls: 0.4553, Train: 55.62%, Valid: 53.20%, Test: 54.28%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5658028113222874\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 467, Loss: 0.4557, Loss Cls: 0.4557, Train: 56.74%, Valid: 52.80%, Test: 53.86%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5644286468519248\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 468, Loss: 0.4556, Loss Cls: 0.4556, Train: 55.57%, Valid: 52.99%, Test: 54.15%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5670263707401908\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 469, Loss: 0.4557, Loss Cls: 0.4557, Train: 56.57%, Valid: 52.83%, Test: 53.94%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5609942493861652\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 470, Loss: 0.4553, Loss Cls: 0.4553, Train: 55.93%, Valid: 53.16%, Test: 54.20%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.566630031903391\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 471, Loss: 0.4550, Loss Cls: 0.4550, Train: 56.46%, Valid: 53.03%, Test: 54.08%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5642185397299371\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 472, Loss: 0.4549, Loss Cls: 0.4549, Train: 55.98%, Valid: 53.08%, Test: 54.15%\n",
            "num_B_prime:0, new edges:37939\n",
            "Batch 0.0, train acc:0.5643258212974954\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 473, Loss: 0.4546, Loss Cls: 0.4546, Train: 56.38%, Valid: 53.09%, Test: 54.10%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.5608644252885869\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 474, Loss: 0.4544, Loss Cls: 0.4544, Train: 55.69%, Valid: 52.85%, Test: 53.93%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5640344833380947\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 475, Loss: 0.4545, Loss Cls: 0.4545, Train: 56.20%, Valid: 52.98%, Test: 54.03%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5590405194017282\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 476, Loss: 0.4543, Loss Cls: 0.4543, Train: 55.73%, Valid: 52.80%, Test: 53.97%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5611592419302188\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 477, Loss: 0.4545, Loss Cls: 0.4545, Train: 56.77%, Valid: 53.36%, Test: 54.38%\n",
            "num_B_prime:0, new edges:37937\n",
            "Batch 0.0, train acc:0.559208886452022\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 478, Loss: 0.4543, Loss Cls: 0.4543, Train: 55.75%, Valid: 52.72%, Test: 53.89%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5635546622618733\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 479, Loss: 0.4546, Loss Cls: 0.4546, Train: 56.95%, Valid: 53.66%, Test: 54.70%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.5573586585277231\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 480, Loss: 0.4545, Loss Cls: 0.4545, Train: 55.46%, Valid: 52.32%, Test: 53.41%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5632259030152327\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 481, Loss: 0.4547, Loss Cls: 0.4547, Train: 57.01%, Valid: 53.96%, Test: 55.10%\n",
            "num_B_prime:0, new edges:37934\n",
            "Batch 0.0, train acc:0.5619018665105299\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 482, Loss: 0.4543, Loss Cls: 0.4543, Train: 55.63%, Valid: 51.91%, Test: 52.78%\n",
            "num_B_prime:0, new edges:37944\n",
            "Batch 0.0, train acc:0.566010779583926\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 483, Loss: 0.4543, Loss Cls: 0.4543, Train: 56.87%, Valid: 54.18%, Test: 55.50%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5620293893754419\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 484, Loss: 0.4543, Loss Cls: 0.4543, Train: 55.60%, Valid: 51.25%, Test: 52.07%\n",
            "num_B_prime:0, new edges:37928\n",
            "Batch 0.0, train acc:0.5614169358078613\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 485, Loss: 0.4550, Loss Cls: 0.4550, Train: 56.45%, Valid: 54.23%, Test: 55.54%\n",
            "num_B_prime:0, new edges:37928\n",
            "Batch 0.0, train acc:0.563802417694227\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 486, Loss: 0.4558, Loss Cls: 0.4558, Train: 56.28%, Valid: 51.55%, Test: 52.35%\n",
            "num_B_prime:0, new edges:37919\n",
            "Batch 0.0, train acc:0.5513294346978558\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 487, Loss: 0.4569, Loss Cls: 0.4569, Train: 55.57%, Valid: 53.52%, Test: 54.90%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5656652296825031\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 488, Loss: 0.4569, Loss Cls: 0.4569, Train: 56.67%, Valid: 52.61%, Test: 53.47%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5537578632199474\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 489, Loss: 0.4574, Loss Cls: 0.4574, Train: 55.27%, Valid: 52.76%, Test: 53.95%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5659118120009318\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 490, Loss: 0.4562, Loss Cls: 0.4562, Train: 57.02%, Valid: 53.45%, Test: 54.38%\n",
            "num_B_prime:0, new edges:37942\n",
            "Batch 0.0, train acc:0.5638575634686962\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 491, Loss: 0.4558, Loss Cls: 0.4558, Train: 55.78%, Valid: 52.79%, Test: 53.90%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5633354987905053\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 492, Loss: 0.4545, Loss Cls: 0.4545, Train: 56.83%, Valid: 53.47%, Test: 54.48%\n",
            "num_B_prime:0, new edges:37943\n",
            "Batch 0.0, train acc:0.5662078631535795\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 493, Loss: 0.4543, Loss Cls: 0.4543, Train: 55.77%, Valid: 52.80%, Test: 53.84%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5632493758907485\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 494, Loss: 0.4541, Loss Cls: 0.4541, Train: 56.40%, Valid: 53.13%, Test: 54.18%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5670764595934599\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 495, Loss: 0.4544, Loss Cls: 0.4544, Train: 55.56%, Valid: 52.68%, Test: 53.63%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.560374277291803\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 496, Loss: 0.4551, Loss Cls: 0.4551, Train: 55.90%, Valid: 52.65%, Test: 53.71%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.565873737083971\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 497, Loss: 0.4554, Loss Cls: 0.4554, Train: 55.22%, Valid: 52.47%, Test: 53.40%\n",
            "num_B_prime:0, new edges:37941\n",
            "Batch 0.0, train acc:0.5637998637791409\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 498, Loss: 0.4558, Loss Cls: 0.4558, Train: 56.26%, Valid: 52.93%, Test: 53.98%\n",
            "num_B_prime:0, new edges:37946\n",
            "Batch 0.0, train acc:0.5667948252233518\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 499, Loss: 0.4545, Loss Cls: 0.4545, Train: 55.38%, Valid: 52.43%, Test: 53.42%\n",
            "num_B_prime:0, new edges:37945\n",
            "Batch 0.0, train acc:0.5626963342923557\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "num_B_prime:0, new edges:0\n",
            "Run: 1, Epoch: 500, Loss: 0.4537, Loss Cls: 0.4537, Train: 56.89%, Valid: 53.48%, Test: 54.58%\n",
            "Run 01:\n",
            "Highest Train: 57.17\n",
            "Highest Valid: 54.69\n",
            "  Final Train: 56.44\n",
            "   Final Test: 55.73\n",
            "All runs:\n",
            "Highest Train: 57.17 ± nan\n",
            "Highest Valid: 54.69 ± nan\n",
            "  Final Train: 56.44 ± nan\n",
            "   Final Test: 55.73 ± nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/devnkong/VQ-GNN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqqXe-u9l3Vn",
        "outputId": "51c75e0d-f0f0-4df5-ca62-88b8ae2e79ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VQ-GNN'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 36 (delta 10), reused 29 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), 40.82 KiB | 2.92 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd VQ-GNN/vq_gnn_v2 && python main_node.py --num-D 4 --conv-type SAGE --dataset arxiv --num-parts 20 \\\n",
        "--batch-size 10000 --test-batch-size 10000 --lr 1e-3 --sampler-type cluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiP5LoXkl9GX",
        "outputId": "1354c686-354b-46d1-9d70-8562bee5b80f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.6.\n",
            "Namespace(EMA=True, act='leaky_gelu', alpha_dropout_flag=False, batch_size=10000, bn_flag=True, ce_only=False, clip=None, cluster='vq', commitment_cost=0.0, cont_sliding_window=1, conv_type='SAGE', data_root='/cmlscratch/kong/datasets', dataset='arxiv', device=0, dropbranch=0.0, dropout=0, epochs=500, exp=False, exp_name='test', exp_tag='exp', grad_scale=[1, 1], hidden_channels=128, kmeans_init=False, kmeans_iter=100, ln_para=False, log_steps=1, lr=0.001, momentum=0.1, no_second_fc=True, num_D=4, num_M=256, num_branch=0, num_layers=3, num_parts=20, num_workers=0, recovery_flag=True, run_idx=None, runs=1, sampler_type='cluster', sche=False, skip=False, split=True, test_batch_size=10000, transformer_flag=False, use_gcn=False, walk_length=5, warm_up=True, warm_up_epochs=0, weight_ahead=False)\n",
            "Computing METIS partitioning with 20 parts... Done! [1.25s]\n",
            "Permuting data... Done! [1.33s]\n",
            "inter over intra:  0.34392915636973986\n",
            "1\n",
            "/content/VQ-GNN/vq_gnn_v2/dataloader.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx)\n",
            "num_B_prime:0, new edges:169343\n",
            "694.4256\n",
            "2\n",
            "num_B_prime:0, new edges:169343\n",
            "781.807616\n",
            "3\n",
            "num_B_prime:0, new edges:169343\n",
            "869.865984\n",
            "init done\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.02051879790193642\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.70, avg inference:0.42, Epoch train time:0:00:00.701007, inference time:0:00:00.417711, \n",
            "Run: 1, Epoch: 1, Loss: 3.9656, Loss Cls: 3.9656, Train: 31.42%, Valid: 37.31%, Test: 37.72%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.46851255209421494\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.70, avg inference:0.41, Epoch train time:0:00:00.696087, inference time:0:00:00.407881, \n",
            "Run: 1, Epoch: 2, Loss: 2.3396, Loss Cls: 2.3396, Train: 28.00%, Valid: 39.69%, Test: 43.98%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.5098470436876656\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.71, avg inference:0.46, Epoch train time:0:00:00.720063, inference time:0:00:00.567830, \n",
            "Run: 1, Epoch: 3, Loss: 1.9785, Loss Cls: 1.9785, Train: 28.20%, Valid: 33.13%, Test: 37.50%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.5193257166734476\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.80, avg inference:0.51, Epoch train time:0:00:01.066748, inference time:0:00:00.633390, \n",
            "Run: 1, Epoch: 4, Loss: 1.9271, Loss Cls: 1.9271, Train: 33.16%, Valid: 32.56%, Test: 36.94%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.581871763011183\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.53, Epoch train time:0:00:01.054839, inference time:0:00:00.601326, \n",
            "Run: 1, Epoch: 5, Loss: 1.6571, Loss Cls: 1.6571, Train: 25.76%, Valid: 27.98%, Test: 32.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.5956939114370856\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.54, Epoch train time:0:00:01.012223, inference time:0:00:00.612394, \n",
            "Run: 1, Epoch: 6, Loss: 1.5291, Loss Cls: 1.5291, Train: 25.90%, Valid: 24.85%, Test: 29.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6077566774062304\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.55, Epoch train time:0:00:00.994293, inference time:0:00:00.617126, \n",
            "Run: 1, Epoch: 7, Loss: 1.4733, Loss Cls: 1.4733, Train: 22.76%, Valid: 24.92%, Test: 30.01%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6176532037254924\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.91, avg inference:0.56, Epoch train time:0:00:01.027945, inference time:0:00:00.638842, \n",
            "Run: 1, Epoch: 8, Loss: 1.4046, Loss Cls: 1.4046, Train: 24.98%, Valid: 24.99%, Test: 29.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6270768960095007\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.92, avg inference:0.57, Epoch train time:0:00:01.010765, inference time:0:00:00.617429, \n",
            "Run: 1, Epoch: 9, Loss: 1.3714, Loss Cls: 1.3714, Train: 21.75%, Valid: 22.90%, Test: 28.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6269229500445344\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.92, avg inference:0.55, Epoch train time:0:00:00.908701, inference time:0:00:00.416633, \n",
            "Run: 1, Epoch: 10, Loss: 1.3473, Loss Cls: 1.3473, Train: 27.12%, Valid: 29.15%, Test: 33.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.630595660923016\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.90, avg inference:0.54, Epoch train time:0:00:00.698986, inference time:0:00:00.417858, \n",
            "Run: 1, Epoch: 11, Loss: 1.3251, Loss Cls: 1.3251, Train: 21.44%, Valid: 22.19%, Test: 27.30%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.635917792854708\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.735885, inference time:0:00:00.417138, \n",
            "Run: 1, Epoch: 12, Loss: 1.3027, Loss Cls: 1.3027, Train: 30.22%, Valid: 34.13%, Test: 38.17%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6393815770664497\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.698734, inference time:0:00:00.419878, \n",
            "Run: 1, Epoch: 13, Loss: 1.2751, Loss Cls: 1.2751, Train: 22.31%, Valid: 22.85%, Test: 27.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6482444661923665\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.690221, inference time:0:00:00.410915, \n",
            "Run: 1, Epoch: 14, Loss: 1.2517, Loss Cls: 1.2517, Train: 31.46%, Valid: 34.63%, Test: 38.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6496079875963536\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:00.737891, inference time:0:00:00.421675, \n",
            "Run: 1, Epoch: 15, Loss: 1.2287, Loss Cls: 1.2287, Train: 24.47%, Valid: 24.91%, Test: 29.97%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6578880812834695\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.685096, inference time:0:00:00.404297, \n",
            "Run: 1, Epoch: 16, Loss: 1.2112, Loss Cls: 1.2112, Train: 32.56%, Valid: 34.82%, Test: 38.94%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.656414598475935\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.83, avg inference:0.50, Epoch train time:0:00:00.738839, inference time:0:00:00.427613, \n",
            "Run: 1, Epoch: 17, Loss: 1.1960, Loss Cls: 1.1960, Train: 27.36%, Valid: 27.89%, Test: 32.90%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.663979943039993\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.83, avg inference:0.49, Epoch train time:0:00:00.692386, inference time:0:00:00.408546, \n",
            "Run: 1, Epoch: 18, Loss: 1.1839, Loss Cls: 1.1839, Train: 34.45%, Valid: 36.25%, Test: 40.10%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6610329774249238\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.83, avg inference:0.50, Epoch train time:0:00:00.978501, inference time:0:00:00.617780, \n",
            "Run: 1, Epoch: 19, Loss: 1.1739, Loss Cls: 1.1739, Train: 30.60%, Valid: 31.53%, Test: 36.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6660692097073927\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.50, Epoch train time:0:00:01.082020, inference time:0:00:00.613077, \n",
            "Run: 1, Epoch: 20, Loss: 1.1651, Loss Cls: 1.1651, Train: 36.48%, Valid: 37.96%, Test: 41.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6638589854960909\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:01.034781, inference time:0:00:00.598964, \n",
            "Run: 1, Epoch: 21, Loss: 1.1549, Loss Cls: 1.1549, Train: 34.60%, Valid: 35.95%, Test: 39.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6700608086561617\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:01.063970, inference time:0:00:00.620775, \n",
            "Run: 1, Epoch: 22, Loss: 1.1462, Loss Cls: 1.1462, Train: 38.70%, Valid: 39.71%, Test: 43.13%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6686423065504008\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.988441, inference time:0:00:00.609996, \n",
            "Run: 1, Epoch: 23, Loss: 1.1341, Loss Cls: 1.1341, Train: 39.04%, Valid: 40.51%, Test: 43.97%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6746901837455054\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.973638, inference time:0:00:00.610796, \n",
            "Run: 1, Epoch: 24, Loss: 1.1253, Loss Cls: 1.1253, Train: 41.32%, Valid: 41.96%, Test: 45.01%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6745472339208938\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.030251, inference time:0:00:00.455052, \n",
            "Run: 1, Epoch: 25, Loss: 1.1145, Loss Cls: 1.1145, Train: 43.55%, Valid: 45.00%, Test: 48.01%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6795614739226532\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.51, Epoch train time:0:00:00.689426, inference time:0:00:00.404247, \n",
            "Run: 1, Epoch: 26, Loss: 1.1065, Loss Cls: 1.1065, Train: 44.64%, Valid: 45.12%, Test: 47.89%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6791546167295279\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.51, Epoch train time:0:00:00.675862, inference time:0:00:00.406267, \n",
            "Run: 1, Epoch: 27, Loss: 1.0979, Loss Cls: 1.0979, Train: 48.06%, Valid: 49.50%, Test: 52.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.683267173222199\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.698891, inference time:0:00:00.402711, \n",
            "Run: 1, Epoch: 28, Loss: 1.0915, Loss Cls: 1.0915, Train: 48.34%, Valid: 48.64%, Test: 50.99%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6823215051516918\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.50, Epoch train time:0:00:00.685027, inference time:0:00:00.414902, \n",
            "Run: 1, Epoch: 29, Loss: 1.0853, Loss Cls: 1.0853, Train: 52.38%, Valid: 53.74%, Test: 55.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6850925325210852\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.50, Epoch train time:0:00:00.674785, inference time:0:00:00.407854, \n",
            "Run: 1, Epoch: 30, Loss: 1.0812, Loss Cls: 1.0812, Train: 51.62%, Valid: 52.00%, Test: 54.06%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6836300458539053\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.687528, inference time:0:00:00.420066, \n",
            "Run: 1, Epoch: 31, Loss: 1.0782, Loss Cls: 1.0782, Train: 56.33%, Valid: 57.50%, Test: 59.12%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.685884254626626\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.718245, inference time:0:00:00.421952, \n",
            "Run: 1, Epoch: 32, Loss: 1.0753, Loss Cls: 1.0753, Train: 54.20%, Valid: 54.85%, Test: 56.80%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.68364104199426\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.49, Epoch train time:0:00:00.725211, inference time:0:00:00.426318, \n",
            "Run: 1, Epoch: 33, Loss: 1.0739, Loss Cls: 1.0739, Train: 59.48%, Valid: 60.40%, Test: 61.74%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6877096139255121\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.83, avg inference:0.50, Epoch train time:0:00:00.686997, inference time:0:00:00.571106, \n",
            "Run: 1, Epoch: 34, Loss: 1.0673, Loss Cls: 1.0673, Train: 57.13%, Valid: 58.01%, Test: 59.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6864120693636534\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:01.114963, inference time:0:00:00.627812, \n",
            "Run: 1, Epoch: 35, Loss: 1.0627, Loss Cls: 1.0627, Train: 62.02%, Valid: 62.54%, Test: 63.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6914812900671864\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.963381, inference time:0:00:00.614285, \n",
            "Run: 1, Epoch: 36, Loss: 1.0538, Loss Cls: 1.0538, Train: 60.15%, Valid: 60.95%, Test: 62.58%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6907225563827096\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:00.986471, inference time:0:00:00.621502, \n",
            "Run: 1, Epoch: 37, Loss: 1.0475, Loss Cls: 1.0475, Train: 63.92%, Valid: 64.04%, Test: 65.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6949670665596376\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:01.138206, inference time:0:00:00.636542, \n",
            "Run: 1, Epoch: 38, Loss: 1.0402, Loss Cls: 1.0402, Train: 62.85%, Valid: 63.39%, Test: 64.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.693746494980262\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:01.056045, inference time:0:00:00.626024, \n",
            "Run: 1, Epoch: 39, Loss: 1.0352, Loss Cls: 1.0352, Train: 65.24%, Valid: 65.30%, Test: 66.13%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6975071749815814\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.981516, inference time:0:00:00.610078, \n",
            "Run: 1, Epoch: 40, Loss: 1.0303, Loss Cls: 1.0303, Train: 64.86%, Valid: 65.22%, Test: 66.03%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6951320086649586\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.847334, inference time:0:00:00.388382, \n",
            "Run: 1, Epoch: 41, Loss: 1.0280, Loss Cls: 1.0280, Train: 66.05%, Valid: 65.93%, Test: 66.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6982659086660582\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.666028, inference time:0:00:00.409060, \n",
            "Run: 1, Epoch: 42, Loss: 1.0264, Loss Cls: 1.0264, Train: 66.21%, Valid: 66.23%, Test: 66.50%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6951430048053133\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:00.697638, inference time:0:00:00.424510, \n",
            "Run: 1, Epoch: 43, Loss: 1.0251, Loss Cls: 1.0251, Train: 66.61%, Valid: 66.49%, Test: 67.28%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6974741865605173\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:00.724245, inference time:0:00:00.425047, \n",
            "Run: 1, Epoch: 44, Loss: 1.0239, Loss Cls: 1.0239, Train: 67.24%, Valid: 66.93%, Test: 66.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6974521942798078\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.50, Epoch train time:0:00:00.725346, inference time:0:00:00.435744, \n",
            "Run: 1, Epoch: 45, Loss: 1.0193, Loss Cls: 1.0193, Train: 66.92%, Valid: 67.04%, Test: 67.57%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6983318855081866\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.50, Epoch train time:0:00:00.705867, inference time:0:00:00.435782, \n",
            "Run: 1, Epoch: 46, Loss: 1.0163, Loss Cls: 1.0163, Train: 68.09%, Valid: 67.46%, Test: 66.99%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6989476693680519\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.735026, inference time:0:00:00.446033, \n",
            "Run: 1, Epoch: 47, Loss: 1.0149, Loss Cls: 1.0149, Train: 67.22%, Valid: 67.48%, Test: 67.92%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6973752212973247\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.726566, inference time:0:00:00.429787, \n",
            "Run: 1, Epoch: 48, Loss: 1.0119, Loss Cls: 1.0119, Train: 68.64%, Valid: 67.78%, Test: 67.17%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6994644879647244\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:00.713655, inference time:0:00:00.443910, \n",
            "Run: 1, Epoch: 49, Loss: 1.0131, Loss Cls: 1.0131, Train: 67.80%, Valid: 67.97%, Test: 68.33%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.6978260630518688\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.84, avg inference:0.50, Epoch train time:0:00:01.043125, inference time:0:00:00.643367, \n",
            "Run: 1, Epoch: 50, Loss: 1.0053, Loss Cls: 1.0053, Train: 69.18%, Valid: 68.21%, Test: 67.68%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7020485809480872\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.50, Epoch train time:0:00:01.053103, inference time:0:00:00.608775, \n",
            "Run: 1, Epoch: 51, Loss: 1.0033, Loss Cls: 1.0033, Train: 68.57%, Valid: 68.59%, Test: 68.73%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7005641020001979\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:01.017805, inference time:0:00:00.620921, \n",
            "Run: 1, Epoch: 52, Loss: 0.9960, Loss Cls: 0.9960, Train: 69.71%, Valid: 68.56%, Test: 67.89%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7047426353349974\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.85, avg inference:0.51, Epoch train time:0:00:01.148622, inference time:0:00:00.644393, \n",
            "Run: 1, Epoch: 53, Loss: 0.9932, Loss Cls: 0.9932, Train: 68.93%, Valid: 68.90%, Test: 69.06%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7032471602467534\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:01.078396, inference time:0:00:00.665615, \n",
            "Run: 1, Epoch: 54, Loss: 0.9895, Loss Cls: 0.9895, Train: 70.03%, Valid: 68.55%, Test: 67.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7056113304230215\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:01.097871, inference time:0:00:00.643594, \n",
            "Run: 1, Epoch: 55, Loss: 0.9885, Loss Cls: 0.9885, Train: 68.96%, Valid: 68.94%, Test: 69.12%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7048525967385447\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.51, Epoch train time:0:00:01.005368, inference time:0:00:00.446414, \n",
            "Run: 1, Epoch: 56, Loss: 0.9864, Loss Cls: 0.9864, Train: 70.10%, Valid: 68.25%, Test: 67.18%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7054903728791194\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.742636, inference time:0:00:00.459389, \n",
            "Run: 1, Epoch: 57, Loss: 0.9888, Loss Cls: 0.9888, Train: 68.71%, Valid: 68.73%, Test: 69.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7053914076159268\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.86, avg inference:0.51, Epoch train time:0:00:00.760621, inference time:0:00:00.660619, \n",
            "Run: 1, Epoch: 58, Loss: 0.9871, Loss Cls: 0.9871, Train: 69.73%, Valid: 68.08%, Test: 66.48%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7028842876150471\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.154392, inference time:0:00:00.644729, \n",
            "Run: 1, Epoch: 59, Loss: 0.9923, Loss Cls: 0.9923, Train: 68.35%, Valid: 68.42%, Test: 68.98%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7021035616498609\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.058281, inference time:0:00:00.670052, \n",
            "Run: 1, Epoch: 60, Loss: 0.9944, Loss Cls: 0.9944, Train: 69.47%, Valid: 68.07%, Test: 66.07%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7001242563860085\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.018277, inference time:0:00:00.646690, \n",
            "Run: 1, Epoch: 61, Loss: 0.9942, Loss Cls: 0.9942, Train: 68.48%, Valid: 68.27%, Test: 69.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7012458627021916\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.032382, inference time:0:00:00.668935, \n",
            "Run: 1, Epoch: 62, Loss: 0.9950, Loss Cls: 0.9950, Train: 69.99%, Valid: 68.53%, Test: 66.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7041598398961965\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.148830, inference time:0:00:00.758987, \n",
            "Run: 1, Epoch: 63, Loss: 0.9823, Loss Cls: 0.9823, Train: 69.40%, Valid: 68.72%, Test: 69.41%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.706589986914593\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.160142, inference time:0:00:00.718389, \n",
            "Run: 1, Epoch: 64, Loss: 0.9769, Loss Cls: 0.9769, Train: 70.69%, Valid: 69.05%, Test: 67.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7090971069154727\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.397010, inference time:0:00:00.616963, \n",
            "Run: 1, Epoch: 65, Loss: 0.9682, Loss Cls: 0.9682, Train: 70.25%, Valid: 69.32%, Test: 69.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7106365665651356\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.036239, inference time:0:00:00.603033, \n",
            "Run: 1, Epoch: 66, Loss: 0.9631, Loss Cls: 0.9631, Train: 71.17%, Valid: 69.54%, Test: 68.36%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7133196248116911\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.90, avg inference:0.53, Epoch train time:0:00:00.982505, inference time:0:00:00.616174, \n",
            "Run: 1, Epoch: 67, Loss: 0.9575, Loss Cls: 0.9575, Train: 70.72%, Valid: 69.68%, Test: 69.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7130447213028227\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.90, avg inference:0.53, Epoch train time:0:00:01.103509, inference time:0:00:00.604652, \n",
            "Run: 1, Epoch: 68, Loss: 0.9547, Loss Cls: 0.9547, Train: 71.33%, Valid: 69.81%, Test: 68.94%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7153978953387361\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.90, avg inference:0.54, Epoch train time:0:00:00.985998, inference time:0:00:00.602536, \n",
            "Run: 1, Epoch: 69, Loss: 0.9510, Loss Cls: 0.9510, Train: 70.90%, Valid: 69.60%, Test: 69.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7138254472680089\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.90, avg inference:0.53, Epoch train time:0:00:00.837300, inference time:0:00:00.420286, \n",
            "Run: 1, Epoch: 70, Loss: 0.9501, Loss Cls: 0.9501, Train: 71.34%, Valid: 69.88%, Test: 69.30%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.716398544111017\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.90, avg inference:0.53, Epoch train time:0:00:00.724124, inference time:0:00:00.408640, \n",
            "Run: 1, Epoch: 71, Loss: 0.9475, Loss Cls: 0.9475, Train: 70.81%, Valid: 69.23%, Test: 68.33%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7135835321802048\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.705641, inference time:0:00:00.417710, \n",
            "Run: 1, Epoch: 72, Loss: 0.9481, Loss Cls: 0.9481, Train: 71.35%, Valid: 69.87%, Test: 69.57%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7165085055145644\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.689440, inference time:0:00:00.445843, \n",
            "Run: 1, Epoch: 73, Loss: 0.9462, Loss Cls: 0.9462, Train: 70.64%, Valid: 68.86%, Test: 67.40%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7126488602500523\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.720780, inference time:0:00:00.433965, \n",
            "Run: 1, Epoch: 74, Loss: 0.9475, Loss Cls: 0.9475, Train: 71.14%, Valid: 69.73%, Test: 69.54%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7157057872686687\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.711967, inference time:0:00:00.416837, \n",
            "Run: 1, Epoch: 75, Loss: 0.9463, Loss Cls: 0.9463, Train: 70.53%, Valid: 68.56%, Test: 66.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.711703192179545\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.755447, inference time:0:00:00.413699, \n",
            "Run: 1, Epoch: 76, Loss: 0.9465, Loss Cls: 0.9465, Train: 71.10%, Valid: 69.73%, Test: 69.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7157717641107971\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.714594, inference time:0:00:00.429924, \n",
            "Run: 1, Epoch: 77, Loss: 0.9452, Loss Cls: 0.9452, Train: 70.81%, Valid: 68.70%, Test: 66.68%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7136715013030426\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.701248, inference time:0:00:00.447148, \n",
            "Run: 1, Epoch: 78, Loss: 0.9421, Loss Cls: 0.9421, Train: 71.20%, Valid: 69.93%, Test: 69.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7171132932340748\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.036588, inference time:0:00:00.619898, \n",
            "Run: 1, Epoch: 79, Loss: 0.9399, Loss Cls: 0.9399, Train: 71.15%, Valid: 69.03%, Test: 67.05%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7156288142861855\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.052041, inference time:0:00:00.600606, \n",
            "Run: 1, Epoch: 80, Loss: 0.9364, Loss Cls: 0.9364, Train: 71.36%, Valid: 70.14%, Test: 69.91%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7180259728835179\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.098284, inference time:0:00:00.634893, \n",
            "Run: 1, Epoch: 81, Loss: 0.9363, Loss Cls: 0.9363, Train: 71.42%, Valid: 69.19%, Test: 67.42%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7160686599003749\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.039129, inference time:0:00:00.617984, \n",
            "Run: 1, Epoch: 82, Loss: 0.9379, Loss Cls: 0.9379, Train: 71.17%, Valid: 69.91%, Test: 69.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7146391616542593\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.986573, inference time:0:00:00.619986, \n",
            "Run: 1, Epoch: 83, Loss: 0.9471, Loss Cls: 0.9471, Train: 71.35%, Valid: 69.39%, Test: 67.75%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7150350227070298\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.079539, inference time:0:00:00.633384, \n",
            "Run: 1, Epoch: 84, Loss: 0.9428, Loss Cls: 0.9428, Train: 71.36%, Valid: 69.85%, Test: 69.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7144302349875193\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.031263, inference time:0:00:00.436412, \n",
            "Run: 1, Epoch: 85, Loss: 0.9464, Loss Cls: 0.9464, Train: 71.61%, Valid: 69.94%, Test: 68.71%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7192355483225388\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.741768, inference time:0:00:00.418540, \n",
            "Run: 1, Epoch: 86, Loss: 0.9284, Loss Cls: 0.9284, Train: 71.81%, Valid: 70.08%, Test: 69.19%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7200272704280798\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.696099, inference time:0:00:00.439194, \n",
            "Run: 1, Epoch: 87, Loss: 0.9248, Loss Cls: 0.9248, Train: 71.89%, Valid: 70.14%, Test: 69.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7210609076214248\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.721831, inference time:0:00:00.436153, \n",
            "Run: 1, Epoch: 88, Loss: 0.9214, Loss Cls: 0.9214, Train: 71.59%, Valid: 69.29%, Test: 67.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7197193784981472\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.52, Epoch train time:0:00:00.707788, inference time:0:00:00.411998, \n",
            "Run: 1, Epoch: 89, Loss: 0.9213, Loss Cls: 0.9213, Train: 71.52%, Valid: 69.76%, Test: 69.88%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7204561199019144\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.701836, inference time:0:00:00.420550, \n",
            "Run: 1, Epoch: 90, Loss: 0.9219, Loss Cls: 0.9219, Train: 71.18%, Valid: 67.80%, Test: 65.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.718102945866001\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.700786, inference time:0:00:00.432655, \n",
            "Run: 1, Epoch: 91, Loss: 0.9231, Loss Cls: 0.9231, Train: 71.08%, Valid: 68.97%, Test: 69.58%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7198953167438229\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.721298, inference time:0:00:00.418483, \n",
            "Run: 1, Epoch: 92, Loss: 0.9218, Loss Cls: 0.9218, Train: 70.96%, Valid: 66.94%, Test: 63.60%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7187517181469304\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.716656, inference time:0:00:00.421469, \n",
            "Run: 1, Epoch: 93, Loss: 0.9215, Loss Cls: 0.9215, Train: 70.89%, Valid: 68.72%, Test: 69.38%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7206650465686544\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.848186, inference time:0:00:00.656011, \n",
            "Run: 1, Epoch: 94, Loss: 0.9178, Loss Cls: 0.9178, Train: 71.19%, Valid: 67.10%, Test: 63.50%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7195654325331808\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.085347, inference time:0:00:00.606365, \n",
            "Run: 1, Epoch: 95, Loss: 0.9179, Loss Cls: 0.9179, Train: 70.78%, Valid: 68.90%, Test: 69.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7202581893755292\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.066590, inference time:0:00:00.644972, \n",
            "Run: 1, Epoch: 96, Loss: 0.9165, Loss Cls: 0.9165, Train: 71.44%, Valid: 67.73%, Test: 64.48%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7186967374451567\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.034134, inference time:0:00:00.626904, \n",
            "Run: 1, Epoch: 97, Loss: 0.9188, Loss Cls: 0.9188, Train: 70.86%, Valid: 69.33%, Test: 69.91%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7189496486733157\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.013338, inference time:0:00:00.630902, \n",
            "Run: 1, Epoch: 98, Loss: 0.9175, Loss Cls: 0.9175, Train: 71.65%, Valid: 68.81%, Test: 66.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7190816023575725\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.013387, inference time:0:00:00.632149, \n",
            "Run: 1, Epoch: 99, Loss: 0.9178, Loss Cls: 0.9178, Train: 71.44%, Valid: 69.79%, Test: 70.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7214017879724217\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.078960, inference time:0:00:00.501706, \n",
            "Run: 1, Epoch: 100, Loss: 0.9111, Loss Cls: 0.9111, Train: 72.03%, Valid: 69.70%, Test: 67.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7224574174464763\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.733678, inference time:0:00:00.421796, \n",
            "Run: 1, Epoch: 101, Loss: 0.9078, Loss Cls: 0.9078, Train: 72.04%, Valid: 70.27%, Test: 70.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.725129479552677\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.52, Epoch train time:0:00:00.752990, inference time:0:00:00.447436, \n",
            "Run: 1, Epoch: 102, Loss: 0.9026, Loss Cls: 0.9026, Train: 72.35%, Valid: 70.20%, Test: 68.83%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7251844602544507\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.686107, inference time:0:00:00.433710, \n",
            "Run: 1, Epoch: 103, Loss: 0.8998, Loss Cls: 0.8998, Train: 72.42%, Valid: 70.31%, Test: 70.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7275156420096546\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.700053, inference time:0:00:00.415230, \n",
            "Run: 1, Epoch: 104, Loss: 0.8972, Loss Cls: 0.8972, Train: 72.52%, Valid: 70.40%, Test: 69.32%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7270648002551104\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.680369, inference time:0:00:00.418448, \n",
            "Run: 1, Epoch: 105, Loss: 0.8952, Loss Cls: 0.8952, Train: 72.58%, Valid: 70.37%, Test: 70.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.728538283062645\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.734629, inference time:0:00:00.420960, \n",
            "Run: 1, Epoch: 106, Loss: 0.8941, Loss Cls: 0.8941, Train: 72.60%, Valid: 70.46%, Test: 69.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7272627307814957\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.748572, inference time:0:00:00.422782, \n",
            "Run: 1, Epoch: 107, Loss: 0.8925, Loss Cls: 0.8925, Train: 72.58%, Valid: 70.33%, Test: 69.79%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7290990862207365\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.720006, inference time:0:00:00.428154, \n",
            "Run: 1, Epoch: 108, Loss: 0.8925, Loss Cls: 0.8925, Train: 72.53%, Valid: 70.32%, Test: 69.30%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7278675185010062\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.747020, inference time:0:00:00.641802, \n",
            "Run: 1, Epoch: 109, Loss: 0.8913, Loss Cls: 0.8913, Train: 72.52%, Valid: 70.20%, Test: 69.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7290770939400271\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.056297, inference time:0:00:00.650380, \n",
            "Run: 1, Epoch: 110, Loss: 0.8925, Loss Cls: 0.8925, Train: 72.39%, Valid: 70.07%, Test: 68.62%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7267898967462421\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.069980, inference time:0:00:00.634969, \n",
            "Run: 1, Epoch: 111, Loss: 0.8924, Loss Cls: 0.8924, Train: 72.25%, Valid: 70.18%, Test: 69.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.727999472185263\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.060695, inference time:0:00:00.621340, \n",
            "Run: 1, Epoch: 112, Loss: 0.8952, Loss Cls: 0.8952, Train: 71.97%, Valid: 69.54%, Test: 67.57%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7246346532367139\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.978358, inference time:0:00:00.604072, \n",
            "Run: 1, Epoch: 113, Loss: 0.8973, Loss Cls: 0.8973, Train: 71.93%, Valid: 70.26%, Test: 70.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7265919662198568\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.040697, inference time:0:00:00.629093, \n",
            "Run: 1, Epoch: 114, Loss: 0.8997, Loss Cls: 0.8997, Train: 71.75%, Valid: 69.04%, Test: 66.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7221935100779626\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.047786, inference time:0:00:00.626959, \n",
            "Run: 1, Epoch: 115, Loss: 0.9013, Loss Cls: 0.9013, Train: 71.62%, Valid: 69.88%, Test: 70.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7260091707810559\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.777057, inference time:0:00:00.418766, \n",
            "Run: 1, Epoch: 116, Loss: 0.8992, Loss Cls: 0.8992, Train: 71.92%, Valid: 68.71%, Test: 65.99%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7238209388504635\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.742980, inference time:0:00:00.415566, \n",
            "Run: 1, Epoch: 117, Loss: 0.8953, Loss Cls: 0.8953, Train: 71.75%, Valid: 69.82%, Test: 70.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7276585918342662\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.721482, inference time:0:00:00.419156, \n",
            "Run: 1, Epoch: 118, Loss: 0.8901, Loss Cls: 0.8901, Train: 72.16%, Valid: 68.22%, Test: 65.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7282413872730672\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.694314, inference time:0:00:00.430897, \n",
            "Run: 1, Epoch: 119, Loss: 0.8857, Loss Cls: 0.8857, Train: 72.03%, Valid: 69.81%, Test: 70.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7305175883264974\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.754971, inference time:0:00:00.421116, \n",
            "Run: 1, Epoch: 120, Loss: 0.8810, Loss Cls: 0.8810, Train: 72.36%, Valid: 68.21%, Test: 65.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7310234107828152\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.739745, inference time:0:00:00.425125, \n",
            "Run: 1, Epoch: 121, Loss: 0.8788, Loss Cls: 0.8788, Train: 72.34%, Valid: 70.09%, Test: 70.36%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7318701135901299\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.769249, inference time:0:00:00.410455, \n",
            "Run: 1, Epoch: 122, Loss: 0.8755, Loss Cls: 0.8755, Train: 72.67%, Valid: 68.61%, Test: 66.28%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7328597662220561\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.750098, inference time:0:00:00.425623, \n",
            "Run: 1, Epoch: 123, Loss: 0.8744, Loss Cls: 0.8744, Train: 72.54%, Valid: 70.35%, Test: 70.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7326288472746066\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.779362, inference time:0:00:00.658650, \n",
            "Run: 1, Epoch: 124, Loss: 0.8727, Loss Cls: 0.8727, Train: 72.96%, Valid: 69.38%, Test: 67.22%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.734234283766398\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.072534, inference time:0:00:00.640668, \n",
            "Run: 1, Epoch: 125, Loss: 0.8725, Loss Cls: 0.8725, Train: 72.69%, Valid: 70.62%, Test: 70.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7321670093797077\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.089362, inference time:0:00:00.636182, \n",
            "Run: 1, Epoch: 126, Loss: 0.8733, Loss Cls: 0.8733, Train: 73.15%, Valid: 69.92%, Test: 68.22%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7335085385029855\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.160093, inference time:0:00:00.655013, \n",
            "Run: 1, Epoch: 127, Loss: 0.8736, Loss Cls: 0.8736, Train: 72.73%, Valid: 70.75%, Test: 70.36%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7308364763967847\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.131839, inference time:0:00:00.659232, \n",
            "Run: 1, Epoch: 128, Loss: 0.8754, Loss Cls: 0.8754, Train: 73.25%, Valid: 70.39%, Test: 69.43%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7330686928887961\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.071845, inference time:0:00:00.630383, \n",
            "Run: 1, Epoch: 129, Loss: 0.8746, Loss Cls: 0.8746, Train: 72.84%, Valid: 70.57%, Test: 69.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7301547156947912\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.065613, inference time:0:00:00.636688, \n",
            "Run: 1, Epoch: 130, Loss: 0.8750, Loss Cls: 0.8750, Train: 73.32%, Valid: 70.71%, Test: 70.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7326288472746066\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.733821, inference time:0:00:00.423308, \n",
            "Run: 1, Epoch: 131, Loss: 0.8730, Loss Cls: 0.8730, Train: 72.95%, Valid: 70.10%, Test: 68.68%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7311333721863625\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.748843, inference time:0:00:00.423292, \n",
            "Run: 1, Epoch: 132, Loss: 0.8724, Loss Cls: 0.8724, Train: 73.23%, Valid: 70.77%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7334535578012118\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.740584, inference time:0:00:00.438941, \n",
            "Run: 1, Epoch: 133, Loss: 0.8682, Loss Cls: 0.8682, Train: 73.10%, Valid: 69.75%, Test: 67.91%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7332886156958908\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.714228, inference time:0:00:00.437029, \n",
            "Run: 1, Epoch: 134, Loss: 0.8665, Loss Cls: 0.8665, Train: 73.19%, Valid: 70.70%, Test: 70.72%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7354108707843547\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.696689, inference time:0:00:00.420373, \n",
            "Run: 1, Epoch: 135, Loss: 0.8619, Loss Cls: 0.8619, Train: 73.16%, Valid: 69.39%, Test: 67.16%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7353888785036452\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.813017, inference time:0:00:00.421134, \n",
            "Run: 1, Epoch: 136, Loss: 0.8603, Loss Cls: 0.8603, Train: 73.14%, Valid: 70.59%, Test: 70.73%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7367194114865682\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.721641, inference time:0:00:00.429106, \n",
            "Run: 1, Epoch: 137, Loss: 0.8572, Loss Cls: 0.8572, Train: 73.12%, Valid: 69.03%, Test: 66.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.736730407626923\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.728169, inference time:0:00:00.420203, \n",
            "Run: 1, Epoch: 138, Loss: 0.8569, Loss Cls: 0.8569, Train: 73.03%, Valid: 70.50%, Test: 70.71%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7373351953464334\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.748691, inference time:0:00:00.671588, \n",
            "Run: 1, Epoch: 139, Loss: 0.8554, Loss Cls: 0.8554, Train: 72.99%, Valid: 68.50%, Test: 65.82%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7357847395564157\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.076730, inference time:0:00:00.626785, \n",
            "Run: 1, Epoch: 140, Loss: 0.8567, Loss Cls: 0.8567, Train: 72.77%, Valid: 70.24%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7365544693812471\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.041014, inference time:0:00:00.619916, \n",
            "Run: 1, Epoch: 141, Loss: 0.8570, Loss Cls: 0.8570, Train: 72.76%, Valid: 68.15%, Test: 65.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7345091872752664\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.061846, inference time:0:00:00.671748, \n",
            "Run: 1, Epoch: 142, Loss: 0.8592, Loss Cls: 0.8592, Train: 72.62%, Valid: 70.14%, Test: 70.53%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7355318283282568\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.145728, inference time:0:00:00.633150, \n",
            "Run: 1, Epoch: 143, Loss: 0.8604, Loss Cls: 0.8604, Train: 72.78%, Valid: 68.41%, Test: 65.60%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7336294960468875\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.054991, inference time:0:00:00.620920, \n",
            "Run: 1, Epoch: 144, Loss: 0.8601, Loss Cls: 0.8601, Train: 72.90%, Valid: 70.28%, Test: 70.65%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7365544693812471\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.043616, inference time:0:00:00.609959, \n",
            "Run: 1, Epoch: 145, Loss: 0.8583, Loss Cls: 0.8583, Train: 73.16%, Valid: 69.23%, Test: 66.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7351029788544221\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.733737, inference time:0:00:00.415864, \n",
            "Run: 1, Epoch: 146, Loss: 0.8549, Loss Cls: 0.8549, Train: 73.44%, Valid: 70.74%, Test: 70.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7389626241189342\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.754220, inference time:0:00:00.417743, \n",
            "Run: 1, Epoch: 147, Loss: 0.8510, Loss Cls: 0.8510, Train: 73.51%, Valid: 70.01%, Test: 68.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7370163072761461\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.709988, inference time:0:00:00.430707, \n",
            "Run: 1, Epoch: 148, Loss: 0.8496, Loss Cls: 0.8496, Train: 73.72%, Valid: 70.88%, Test: 70.66%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7396333886805732\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.707711, inference time:0:00:00.427645, \n",
            "Run: 1, Epoch: 149, Loss: 0.8479, Loss Cls: 0.8479, Train: 73.43%, Valid: 70.44%, Test: 69.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7361256199074125\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.707519, inference time:0:00:00.414531, \n",
            "Run: 1, Epoch: 150, Loss: 0.8493, Loss Cls: 0.8493, Train: 73.56%, Valid: 70.57%, Test: 69.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7381928942941027\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.693951, inference time:0:00:00.419862, \n",
            "Run: 1, Epoch: 151, Loss: 0.8522, Loss Cls: 0.8522, Train: 73.30%, Valid: 70.69%, Test: 69.89%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7341023300821412\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.718710, inference time:0:00:00.418949, \n",
            "Run: 1, Epoch: 152, Loss: 0.8517, Loss Cls: 0.8517, Train: 73.24%, Valid: 70.05%, Test: 68.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7355208321879021\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.732240, inference time:0:00:00.406106, \n",
            "Run: 1, Epoch: 153, Loss: 0.8573, Loss Cls: 0.8573, Train: 73.34%, Valid: 70.91%, Test: 70.48%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7356417897318042\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.730036, inference time:0:00:00.529194, \n",
            "Run: 1, Epoch: 154, Loss: 0.8507, Loss Cls: 0.8507, Train: 73.19%, Valid: 69.62%, Test: 67.88%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7361256199074125\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.128121, inference time:0:00:00.634915, \n",
            "Run: 1, Epoch: 155, Loss: 0.8549, Loss Cls: 0.8549, Train: 73.62%, Valid: 71.01%, Test: 70.82%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7391605546453195\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.040434, inference time:0:00:00.644345, \n",
            "Run: 1, Epoch: 156, Loss: 0.8452, Loss Cls: 0.8452, Train: 73.48%, Valid: 69.61%, Test: 67.71%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7387317051714848\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.005085, inference time:0:00:00.653817, \n",
            "Run: 1, Epoch: 157, Loss: 0.8463, Loss Cls: 0.8463, Train: 73.88%, Valid: 70.96%, Test: 70.93%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7421075202603886\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.007364, inference time:0:00:00.609976, \n",
            "Run: 1, Epoch: 158, Loss: 0.8387, Loss Cls: 0.8387, Train: 73.64%, Valid: 69.65%, Test: 67.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7402711648211477\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.048720, inference time:0:00:00.614702, \n",
            "Run: 1, Epoch: 159, Loss: 0.8397, Loss Cls: 0.8397, Train: 73.92%, Valid: 70.96%, Test: 70.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7435480146468589\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.011748, inference time:0:00:00.597019, \n",
            "Run: 1, Epoch: 160, Loss: 0.8367, Loss Cls: 0.8367, Train: 73.33%, Valid: 69.12%, Test: 67.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7388196742943227\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.963066, inference time:0:00:00.409975, \n",
            "Run: 1, Epoch: 161, Loss: 0.8403, Loss Cls: 0.8403, Train: 73.61%, Valid: 70.38%, Test: 70.30%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7420525395586149\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.706599, inference time:0:00:00.424531, \n",
            "Run: 1, Epoch: 162, Loss: 0.8407, Loss Cls: 0.8407, Train: 72.65%, Valid: 68.12%, Test: 65.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7349710251701653\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.695636, inference time:0:00:00.420366, \n",
            "Run: 1, Epoch: 163, Loss: 0.8459, Loss Cls: 0.8459, Train: 73.10%, Valid: 69.74%, Test: 69.54%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7395454195577352\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.718200, inference time:0:00:00.418018, \n",
            "Run: 1, Epoch: 164, Loss: 0.8463, Loss Cls: 0.8463, Train: 72.30%, Valid: 67.25%, Test: 64.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.733816430432918\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.696706, inference time:0:00:00.406200, \n",
            "Run: 1, Epoch: 165, Loss: 0.8473, Loss Cls: 0.8473, Train: 72.99%, Valid: 69.42%, Test: 69.13%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7393254967506405\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.702068, inference time:0:00:00.413518, \n",
            "Run: 1, Epoch: 166, Loss: 0.8448, Loss Cls: 0.8448, Train: 72.69%, Valid: 67.43%, Test: 64.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7365764616619567\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.723194, inference time:0:00:00.418805, \n",
            "Run: 1, Epoch: 167, Loss: 0.8410, Loss Cls: 0.8410, Train: 73.26%, Valid: 69.66%, Test: 69.44%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7413157981548476\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.700623, inference time:0:00:00.428559, \n",
            "Run: 1, Epoch: 168, Loss: 0.8388, Loss Cls: 0.8388, Train: 73.37%, Valid: 68.06%, Test: 65.68%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7392265314874479\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.728253, inference time:0:00:00.421677, \n",
            "Run: 1, Epoch: 169, Loss: 0.8364, Loss Cls: 0.8364, Train: 73.33%, Valid: 69.75%, Test: 69.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7414807402601686\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:00.945614, inference time:0:00:00.648037, \n",
            "Run: 1, Epoch: 170, Loss: 0.8375, Loss Cls: 0.8375, Train: 73.72%, Valid: 68.76%, Test: 66.42%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7410738830670435\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.134612, inference time:0:00:00.624102, \n",
            "Run: 1, Epoch: 171, Loss: 0.8359, Loss Cls: 0.8359, Train: 73.45%, Valid: 70.28%, Test: 70.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7404580992071783\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.87, avg inference:0.52, Epoch train time:0:00:01.027174, inference time:0:00:00.612004, \n",
            "Run: 1, Epoch: 172, Loss: 0.8374, Loss Cls: 0.8374, Train: 73.93%, Valid: 69.33%, Test: 67.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7422944546464191\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.035172, inference time:0:00:00.627534, \n",
            "Run: 1, Epoch: 173, Loss: 0.8329, Loss Cls: 0.8329, Train: 73.79%, Valid: 70.84%, Test: 70.66%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7427013118395444\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.002443, inference time:0:00:00.626410, \n",
            "Run: 1, Epoch: 174, Loss: 0.8310, Loss Cls: 0.8310, Train: 74.32%, Valid: 70.03%, Test: 67.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7449005399104914\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.997556, inference time:0:00:00.692363, \n",
            "Run: 1, Epoch: 175, Loss: 0.8258, Loss Cls: 0.8258, Train: 74.19%, Valid: 71.08%, Test: 70.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7451314588579409\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.130605, inference time:0:00:00.737853, \n",
            "Run: 1, Epoch: 176, Loss: 0.8230, Loss Cls: 0.8230, Train: 74.59%, Valid: 70.41%, Test: 68.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7464619918408638\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.141385, inference time:0:00:00.614601, \n",
            "Run: 1, Epoch: 177, Loss: 0.8199, Loss Cls: 0.8199, Train: 74.39%, Valid: 71.11%, Test: 70.60%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7461101153495123\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.036816, inference time:0:00:00.615544, \n",
            "Run: 1, Epoch: 178, Loss: 0.8191, Loss Cls: 0.8191, Train: 74.62%, Valid: 70.66%, Test: 69.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7465719532444112\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.038571, inference time:0:00:00.623051, \n",
            "Run: 1, Epoch: 179, Loss: 0.8189, Loss Cls: 0.8189, Train: 74.16%, Valid: 70.86%, Test: 70.19%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7454723392089376\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.139184, inference time:0:00:00.623208, \n",
            "Run: 1, Epoch: 180, Loss: 0.8203, Loss Cls: 0.8203, Train: 74.38%, Valid: 70.67%, Test: 69.52%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7440978216645957\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.032281, inference time:0:00:00.634889, \n",
            "Run: 1, Epoch: 181, Loss: 0.8229, Loss Cls: 0.8229, Train: 73.83%, Valid: 70.25%, Test: 69.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7438009258750179\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.070785, inference time:0:00:00.493293, \n",
            "Run: 1, Epoch: 182, Loss: 0.8246, Loss Cls: 0.8246, Train: 74.05%, Valid: 70.57%, Test: 69.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7430641844712506\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.692278, inference time:0:00:00.596982, \n",
            "Run: 1, Epoch: 183, Loss: 0.8272, Loss Cls: 0.8272, Train: 73.56%, Valid: 69.40%, Test: 67.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7442737599102714\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.065826, inference time:0:00:00.657438, \n",
            "Run: 1, Epoch: 184, Loss: 0.8246, Loss Cls: 0.8246, Train: 73.84%, Valid: 70.24%, Test: 70.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7443617290331094\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.021858, inference time:0:00:00.623194, \n",
            "Run: 1, Epoch: 185, Loss: 0.8234, Loss Cls: 0.8234, Train: 73.75%, Valid: 68.97%, Test: 66.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7464949802619281\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.041134, inference time:0:00:00.608755, \n",
            "Run: 1, Epoch: 186, Loss: 0.8189, Loss Cls: 0.8189, Train: 73.72%, Valid: 70.19%, Test: 70.52%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7463080458758976\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.030114, inference time:0:00:00.605623, \n",
            "Run: 1, Epoch: 187, Loss: 0.8177, Loss Cls: 0.8177, Train: 73.83%, Valid: 68.76%, Test: 65.93%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7468688490339891\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.039439, inference time:0:00:00.611162, \n",
            "Run: 1, Epoch: 188, Loss: 0.8174, Loss Cls: 0.8174, Train: 73.43%, Valid: 69.91%, Test: 70.54%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7451644472790051\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.982637, inference time:0:00:00.633814, \n",
            "Run: 1, Epoch: 189, Loss: 0.8196, Loss Cls: 0.8196, Train: 73.52%, Valid: 68.30%, Test: 64.89%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7433390879801189\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.049146, inference time:0:00:00.418781, \n",
            "Run: 1, Epoch: 190, Loss: 0.8246, Loss Cls: 0.8246, Train: 73.01%, Valid: 69.66%, Test: 70.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7432951034187001\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.749493, inference time:0:00:00.433818, \n",
            "Run: 1, Epoch: 191, Loss: 0.8239, Loss Cls: 0.8239, Train: 73.32%, Valid: 68.18%, Test: 64.52%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7419425781550676\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.715467, inference time:0:00:00.447449, \n",
            "Run: 1, Epoch: 192, Loss: 0.8271, Loss Cls: 0.8271, Train: 73.16%, Valid: 69.83%, Test: 70.45%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7444716904366567\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.752997, inference time:0:00:00.418218, \n",
            "Run: 1, Epoch: 193, Loss: 0.8223, Loss Cls: 0.8223, Train: 73.56%, Valid: 68.32%, Test: 65.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7429432269273485\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.727972, inference time:0:00:00.429767, \n",
            "Run: 1, Epoch: 194, Loss: 0.8224, Loss Cls: 0.8224, Train: 73.64%, Valid: 70.20%, Test: 70.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7460331423670292\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.746523, inference time:0:00:00.430285, \n",
            "Run: 1, Epoch: 195, Loss: 0.8189, Loss Cls: 0.8189, Train: 74.01%, Valid: 68.93%, Test: 66.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7446586248226872\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.756245, inference time:0:00:00.428772, \n",
            "Run: 1, Epoch: 196, Loss: 0.8158, Loss Cls: 0.8158, Train: 74.20%, Valid: 70.71%, Test: 70.93%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.74828735113975\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.752080, inference time:0:00:00.433868, \n",
            "Run: 1, Epoch: 197, Loss: 0.8115, Loss Cls: 0.8115, Train: 74.49%, Valid: 69.61%, Test: 67.34%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7480234437712363\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.703497, inference time:0:00:00.480737, \n",
            "Run: 1, Epoch: 198, Loss: 0.8066, Loss Cls: 0.8066, Train: 74.79%, Valid: 71.06%, Test: 70.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7517291430707822\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.049884, inference time:0:00:00.722238, \n",
            "Run: 1, Epoch: 199, Loss: 0.8016, Loss Cls: 0.8016, Train: 74.81%, Valid: 70.15%, Test: 68.32%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.750739490438856\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.101178, inference time:0:00:00.631657, \n",
            "Run: 1, Epoch: 200, Loss: 0.7978, Loss Cls: 0.7978, Train: 75.18%, Valid: 71.19%, Test: 70.82%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7544012051769828\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.014908, inference time:0:00:00.648465, \n",
            "Run: 1, Epoch: 201, Loss: 0.7946, Loss Cls: 0.7946, Train: 75.07%, Valid: 70.55%, Test: 68.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7522899462288737\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.060618, inference time:0:00:00.609333, \n",
            "Run: 1, Epoch: 202, Loss: 0.7926, Loss Cls: 0.7926, Train: 75.30%, Valid: 71.20%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7556767574581322\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.098143, inference time:0:00:00.617996, \n",
            "Run: 1, Epoch: 203, Loss: 0.7912, Loss Cls: 0.7912, Train: 75.11%, Valid: 70.77%, Test: 69.49%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7535874907907325\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.039256, inference time:0:00:00.624278, \n",
            "Run: 1, Epoch: 204, Loss: 0.7907, Loss Cls: 0.7907, Train: 75.23%, Valid: 71.01%, Test: 70.13%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7548300546508175\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.875073, inference time:0:00:00.414635, \n",
            "Run: 1, Epoch: 205, Loss: 0.7913, Loss Cls: 0.7913, Train: 74.96%, Valid: 70.72%, Test: 69.73%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7525208651763231\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.727147, inference time:0:00:00.419404, \n",
            "Run: 1, Epoch: 206, Loss: 0.7934, Loss Cls: 0.7934, Train: 74.90%, Valid: 70.49%, Test: 69.17%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7525428574570325\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.734214, inference time:0:00:00.408715, \n",
            "Run: 1, Epoch: 207, Loss: 0.7980, Loss Cls: 0.7980, Train: 74.51%, Valid: 70.60%, Test: 70.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7485182700871994\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.716547, inference time:0:00:00.423079, \n",
            "Run: 1, Epoch: 208, Loss: 0.8047, Loss Cls: 0.8047, Train: 73.93%, Valid: 69.19%, Test: 66.93%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7458022234195797\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.693017, inference time:0:00:00.419223, \n",
            "Run: 1, Epoch: 209, Loss: 0.8146, Loss Cls: 0.8146, Train: 73.80%, Valid: 70.00%, Test: 70.10%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7430201999098317\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.732250, inference time:0:00:00.435558, \n",
            "Run: 1, Epoch: 210, Loss: 0.8167, Loss Cls: 0.8167, Train: 73.32%, Valid: 67.75%, Test: 64.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7424374044710307\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.701317, inference time:0:00:00.430565, \n",
            "Run: 1, Epoch: 211, Loss: 0.8203, Loss Cls: 0.8203, Train: 73.94%, Valid: 69.89%, Test: 70.38%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7468798451743438\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.738219, inference time:0:00:00.408426, \n",
            "Run: 1, Epoch: 212, Loss: 0.8065, Loss Cls: 0.8065, Train: 73.71%, Valid: 67.49%, Test: 64.18%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7473416830692426\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.736640, inference time:0:00:00.432825, \n",
            "Run: 1, Epoch: 213, Loss: 0.8029, Loss Cls: 0.8029, Train: 74.42%, Valid: 70.28%, Test: 70.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7527957686851915\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.047750, inference time:0:00:00.633619, \n",
            "Run: 1, Epoch: 214, Loss: 0.7929, Loss Cls: 0.7929, Train: 74.16%, Valid: 67.58%, Test: 64.28%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7515751971058159\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.065902, inference time:0:00:00.623486, \n",
            "Run: 1, Epoch: 215, Loss: 0.7910, Loss Cls: 0.7910, Train: 74.57%, Valid: 70.30%, Test: 70.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7549400160543649\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.032228, inference time:0:00:00.617177, \n",
            "Run: 1, Epoch: 216, Loss: 0.7876, Loss Cls: 0.7876, Train: 74.29%, Valid: 67.58%, Test: 64.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7523559230710021\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.045656, inference time:0:00:00.636953, \n",
            "Run: 1, Epoch: 217, Loss: 0.7886, Loss Cls: 0.7886, Train: 74.41%, Valid: 70.18%, Test: 70.62%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7534005564047019\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.030327, inference time:0:00:00.624399, \n",
            "Run: 1, Epoch: 218, Loss: 0.7892, Loss Cls: 0.7892, Train: 74.26%, Valid: 67.68%, Test: 64.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7509154286845318\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.007032, inference time:0:00:00.630607, \n",
            "Run: 1, Epoch: 219, Loss: 0.7930, Loss Cls: 0.7930, Train: 74.03%, Valid: 70.03%, Test: 70.47%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7509814055266602\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.108474, inference time:0:00:00.413727, \n",
            "Run: 1, Epoch: 220, Loss: 0.7954, Loss Cls: 0.7954, Train: 74.33%, Valid: 68.20%, Test: 64.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7490570809645815\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.686464, inference time:0:00:00.423928, \n",
            "Run: 1, Epoch: 221, Loss: 0.7980, Loss Cls: 0.7980, Train: 74.11%, Valid: 70.24%, Test: 70.66%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7502446641228928\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.759912, inference time:0:00:00.430787, \n",
            "Run: 1, Epoch: 222, Loss: 0.7960, Loss Cls: 0.7960, Train: 74.73%, Valid: 69.05%, Test: 66.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.751487227982978\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.742579, inference time:0:00:00.410083, \n",
            "Run: 1, Epoch: 223, Loss: 0.7935, Loss Cls: 0.7935, Train: 74.63%, Valid: 70.66%, Test: 70.99%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7521799848253263\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.715965, inference time:0:00:00.434364, \n",
            "Run: 1, Epoch: 224, Loss: 0.7898, Loss Cls: 0.7898, Train: 75.18%, Valid: 69.74%, Test: 67.29%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7545881395630134\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.706349, inference time:0:00:00.426915, \n",
            "Run: 1, Epoch: 225, Loss: 0.7858, Loss Cls: 0.7858, Train: 75.06%, Valid: 71.00%, Test: 70.85%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7545331588612397\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.689076, inference time:0:00:00.418225, \n",
            "Run: 1, Epoch: 226, Loss: 0.7843, Loss Cls: 0.7843, Train: 75.42%, Valid: 70.30%, Test: 68.13%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7563475220197711\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.708344, inference time:0:00:00.429643, \n",
            "Run: 1, Epoch: 227, Loss: 0.7822, Loss Cls: 0.7822, Train: 75.04%, Valid: 70.63%, Test: 70.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7549840006157839\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.717888, inference time:0:00:00.418156, \n",
            "Run: 1, Epoch: 228, Loss: 0.7844, Loss Cls: 0.7844, Train: 75.24%, Valid: 70.43%, Test: 68.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7549510121947196\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.869801, inference time:0:00:00.649360, \n",
            "Run: 1, Epoch: 229, Loss: 0.7867, Loss Cls: 0.7867, Train: 74.53%, Valid: 69.99%, Test: 69.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7516741623690085\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.079659, inference time:0:00:00.627851, \n",
            "Run: 1, Epoch: 230, Loss: 0.7934, Loss Cls: 0.7934, Train: 75.05%, Valid: 70.42%, Test: 68.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7512343167548191\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.059309, inference time:0:00:00.655128, \n",
            "Run: 1, Epoch: 231, Loss: 0.7945, Loss Cls: 0.7945, Train: 74.45%, Valid: 69.93%, Test: 69.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7507174981581465\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.020997, inference time:0:00:00.627289, \n",
            "Run: 1, Epoch: 232, Loss: 0.7956, Loss Cls: 0.7956, Train: 75.24%, Valid: 70.62%, Test: 69.32%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7531586413168978\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.044881, inference time:0:00:00.645191, \n",
            "Run: 1, Epoch: 233, Loss: 0.7874, Loss Cls: 0.7874, Train: 75.18%, Valid: 70.81%, Test: 70.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.755225915703588\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.124704, inference time:0:00:00.598373, \n",
            "Run: 1, Epoch: 234, Loss: 0.7819, Loss Cls: 0.7819, Train: 75.50%, Valid: 70.69%, Test: 69.19%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7564025027215447\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.016361, inference time:0:00:00.539048, \n",
            "Run: 1, Epoch: 235, Loss: 0.7765, Loss Cls: 0.7765, Train: 75.53%, Valid: 71.07%, Test: 70.53%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7576010820202109\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.682765, inference time:0:00:00.430265, \n",
            "Run: 1, Epoch: 236, Loss: 0.7747, Loss Cls: 0.7747, Train: 75.25%, Valid: 70.14%, Test: 68.36%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7553688655281996\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.690065, inference time:0:00:00.430497, \n",
            "Run: 1, Epoch: 237, Loss: 0.7761, Loss Cls: 0.7761, Train: 75.29%, Valid: 70.43%, Test: 70.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7554678307913922\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.754344, inference time:0:00:00.419845, \n",
            "Run: 1, Epoch: 238, Loss: 0.7814, Loss Cls: 0.7814, Train: 74.37%, Valid: 68.37%, Test: 66.18%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7507284942985012\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.737463, inference time:0:00:00.440804, \n",
            "Run: 1, Epoch: 239, Loss: 0.7868, Loss Cls: 0.7868, Train: 74.65%, Valid: 69.54%, Test: 69.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.751652170088299\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.733251, inference time:0:00:00.418314, \n",
            "Run: 1, Epoch: 240, Loss: 0.7940, Loss Cls: 0.7940, Train: 74.16%, Valid: 67.74%, Test: 65.52%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7507065020177918\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.702666, inference time:0:00:00.414969, \n",
            "Run: 1, Epoch: 241, Loss: 0.7879, Loss Cls: 0.7879, Train: 74.97%, Valid: 69.94%, Test: 69.71%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7546101318437228\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.732239, inference time:0:00:00.418191, \n",
            "Run: 1, Epoch: 242, Loss: 0.7832, Loss Cls: 0.7832, Train: 74.89%, Valid: 69.14%, Test: 67.14%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7553578693878449\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.740318, inference time:0:00:00.428598, \n",
            "Run: 1, Epoch: 243, Loss: 0.7752, Loss Cls: 0.7752, Train: 75.66%, Valid: 70.71%, Test: 70.17%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7581838774590118\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.709303, inference time:0:00:00.632287, \n",
            "Run: 1, Epoch: 244, Loss: 0.7712, Loss Cls: 0.7712, Train: 75.48%, Valid: 70.36%, Test: 68.75%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7583158311432687\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.110783, inference time:0:00:00.653424, \n",
            "Run: 1, Epoch: 245, Loss: 0.7669, Loss Cls: 0.7669, Train: 75.99%, Valid: 70.90%, Test: 69.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7598113062315127\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.086402, inference time:0:00:00.630826, \n",
            "Run: 1, Epoch: 246, Loss: 0.7666, Loss Cls: 0.7666, Train: 75.57%, Valid: 71.06%, Test: 70.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7590195841259718\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.085519, inference time:0:00:00.623974, \n",
            "Run: 1, Epoch: 247, Loss: 0.7654, Loss Cls: 0.7654, Train: 75.81%, Valid: 70.31%, Test: 68.65%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7597453293893843\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.023664, inference time:0:00:00.633403, \n",
            "Run: 1, Epoch: 248, Loss: 0.7674, Loss Cls: 0.7674, Train: 75.14%, Valid: 70.85%, Test: 70.82%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7585577462310729\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.003978, inference time:0:00:00.638059, \n",
            "Run: 1, Epoch: 249, Loss: 0.7690, Loss Cls: 0.7690, Train: 75.03%, Valid: 68.76%, Test: 65.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7579969430729814\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.124125, inference time:0:00:00.621683, \n",
            "Run: 1, Epoch: 250, Loss: 0.7713, Loss Cls: 0.7713, Train: 74.24%, Valid: 69.89%, Test: 70.36%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7564025027215447\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.792446, inference time:0:00:00.433971, \n",
            "Run: 1, Epoch: 251, Loss: 0.7730, Loss Cls: 0.7730, Train: 74.47%, Valid: 67.25%, Test: 63.54%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7569962943007005\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.691818, inference time:0:00:00.425675, \n",
            "Run: 1, Epoch: 252, Loss: 0.7729, Loss Cls: 0.7729, Train: 73.89%, Valid: 69.07%, Test: 69.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7563255297390616\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.738976, inference time:0:00:00.406444, \n",
            "Run: 1, Epoch: 253, Loss: 0.7712, Loss Cls: 0.7712, Train: 74.57%, Valid: 67.10%, Test: 63.07%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7579859469326267\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.740540, inference time:0:00:00.423504, \n",
            "Run: 1, Epoch: 254, Loss: 0.7706, Loss Cls: 0.7706, Train: 74.07%, Valid: 69.23%, Test: 70.03%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.757557097458792\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.699334, inference time:0:00:00.421633, \n",
            "Run: 1, Epoch: 255, Loss: 0.7684, Loss Cls: 0.7684, Train: 74.96%, Valid: 67.71%, Test: 64.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7586237230732014\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.718125, inference time:0:00:00.426932, \n",
            "Run: 1, Epoch: 256, Loss: 0.7683, Loss Cls: 0.7683, Train: 74.48%, Valid: 69.85%, Test: 70.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7579529585115624\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.697226, inference time:0:00:00.412347, \n",
            "Run: 1, Epoch: 257, Loss: 0.7667, Loss Cls: 0.7667, Train: 75.27%, Valid: 68.73%, Test: 65.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7593494683366139\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.710785, inference time:0:00:00.440057, \n",
            "Run: 1, Epoch: 258, Loss: 0.7661, Loss Cls: 0.7661, Train: 74.99%, Valid: 70.26%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7588546420206508\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.704756, inference time:0:00:00.439210, \n",
            "Run: 1, Epoch: 259, Loss: 0.7652, Loss Cls: 0.7652, Train: 75.54%, Valid: 69.56%, Test: 66.88%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7596683564069012\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.080609, inference time:0:00:00.631785, \n",
            "Run: 1, Epoch: 260, Loss: 0.7640, Loss Cls: 0.7640, Train: 75.40%, Valid: 70.70%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7596683564069012\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.051155, inference time:0:00:00.658319, \n",
            "Run: 1, Epoch: 261, Loss: 0.7643, Loss Cls: 0.7643, Train: 75.75%, Valid: 70.28%, Test: 68.34%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7595254065822896\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.089587, inference time:0:00:00.634589, \n",
            "Run: 1, Epoch: 262, Loss: 0.7620, Loss Cls: 0.7620, Train: 75.69%, Valid: 70.66%, Test: 70.32%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7607019936002463\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.051036, inference time:0:00:00.645644, \n",
            "Run: 1, Epoch: 263, Loss: 0.7627, Loss Cls: 0.7627, Train: 75.96%, Valid: 70.68%, Test: 69.32%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7607239858809558\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.013625, inference time:0:00:00.616354, \n",
            "Run: 1, Epoch: 264, Loss: 0.7581, Loss Cls: 0.7581, Train: 76.01%, Valid: 70.50%, Test: 69.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7621974686884904\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.097430, inference time:0:00:00.611090, \n",
            "Run: 1, Epoch: 265, Loss: 0.7578, Loss Cls: 0.7578, Train: 76.04%, Valid: 70.91%, Test: 69.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7623624107938114\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.962560, inference time:0:00:00.419697, \n",
            "Run: 1, Epoch: 266, Loss: 0.7536, Loss Cls: 0.7536, Train: 76.26%, Valid: 70.22%, Test: 68.92%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7634730209696396\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.711105, inference time:0:00:00.411026, \n",
            "Run: 1, Epoch: 267, Loss: 0.7529, Loss Cls: 0.7529, Train: 76.05%, Valid: 71.00%, Test: 70.10%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7628682332501292\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.708125, inference time:0:00:00.416348, \n",
            "Run: 1, Epoch: 268, Loss: 0.7513, Loss Cls: 0.7513, Train: 76.26%, Valid: 70.18%, Test: 68.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7633190750046733\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.700106, inference time:0:00:00.419763, \n",
            "Run: 1, Epoch: 269, Loss: 0.7511, Loss Cls: 0.7511, Train: 75.91%, Valid: 70.95%, Test: 70.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.762087507284943\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.722231, inference time:0:00:00.414471, \n",
            "Run: 1, Epoch: 270, Loss: 0.7514, Loss Cls: 0.7514, Train: 76.28%, Valid: 70.34%, Test: 68.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7632860865836092\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.702518, inference time:0:00:00.416765, \n",
            "Run: 1, Epoch: 271, Loss: 0.7515, Loss Cls: 0.7515, Train: 75.81%, Valid: 70.92%, Test: 70.31%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7615596925479157\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.740031, inference time:0:00:00.425707, \n",
            "Run: 1, Epoch: 272, Loss: 0.7517, Loss Cls: 0.7517, Train: 76.26%, Valid: 70.50%, Test: 68.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7633630595660923\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.725934, inference time:0:00:00.413977, \n",
            "Run: 1, Epoch: 273, Loss: 0.7522, Loss Cls: 0.7522, Train: 75.77%, Valid: 70.91%, Test: 70.22%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7610758623723073\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.693689, inference time:0:00:00.413718, \n",
            "Run: 1, Epoch: 274, Loss: 0.7529, Loss Cls: 0.7529, Train: 76.20%, Valid: 70.31%, Test: 68.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7623404185131019\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.850765, inference time:0:00:00.670627, \n",
            "Run: 1, Epoch: 275, Loss: 0.7538, Loss Cls: 0.7538, Train: 75.47%, Valid: 70.70%, Test: 70.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7604930669335064\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.085829, inference time:0:00:00.627501, \n",
            "Run: 1, Epoch: 276, Loss: 0.7573, Loss Cls: 0.7573, Train: 75.79%, Valid: 69.94%, Test: 68.31%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7604710746527968\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.044526, inference time:0:00:00.622749, \n",
            "Run: 1, Epoch: 277, Loss: 0.7580, Loss Cls: 0.7580, Train: 75.03%, Valid: 70.38%, Test: 69.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7596463641261917\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.057348, inference time:0:00:00.663025, \n",
            "Run: 1, Epoch: 278, Loss: 0.7621, Loss Cls: 0.7621, Train: 75.45%, Valid: 69.57%, Test: 67.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7588986265820697\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.032726, inference time:0:00:00.669908, \n",
            "Run: 1, Epoch: 279, Loss: 0.7626, Loss Cls: 0.7626, Train: 74.88%, Valid: 70.46%, Test: 69.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7604820707931516\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.100780, inference time:0:00:00.609943, \n",
            "Run: 1, Epoch: 280, Loss: 0.7625, Loss Cls: 0.7625, Train: 75.44%, Valid: 69.39%, Test: 67.18%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7593604644769686\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.020730, inference time:0:00:00.428181, \n",
            "Run: 1, Epoch: 281, Loss: 0.7627, Loss Cls: 0.7627, Train: 75.24%, Valid: 70.66%, Test: 70.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7617246346532367\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.718453, inference time:0:00:00.419222, \n",
            "Run: 1, Epoch: 282, Loss: 0.7596, Loss Cls: 0.7596, Train: 75.80%, Valid: 69.55%, Test: 67.34%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7610428739512431\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.727001, inference time:0:00:00.443830, \n",
            "Run: 1, Epoch: 283, Loss: 0.7574, Loss Cls: 0.7574, Train: 75.70%, Valid: 71.08%, Test: 70.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7622854378113282\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.716873, inference time:0:00:00.417667, \n",
            "Run: 1, Epoch: 284, Loss: 0.7561, Loss Cls: 0.7561, Train: 75.88%, Valid: 69.71%, Test: 67.27%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7616146732496893\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.696733, inference time:0:00:00.424151, \n",
            "Run: 1, Epoch: 285, Loss: 0.7540, Loss Cls: 0.7540, Train: 75.52%, Valid: 70.83%, Test: 70.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7617246346532367\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.723995, inference time:0:00:00.413998, \n",
            "Run: 1, Epoch: 286, Loss: 0.7553, Loss Cls: 0.7553, Train: 75.74%, Valid: 69.38%, Test: 66.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7616586578111083\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.707706, inference time:0:00:00.421256, \n",
            "Run: 1, Epoch: 287, Loss: 0.7549, Loss Cls: 0.7549, Train: 75.22%, Valid: 70.50%, Test: 70.27%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7621204957060072\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.684254, inference time:0:00:00.433765, \n",
            "Run: 1, Epoch: 288, Loss: 0.7530, Loss Cls: 0.7530, Train: 75.67%, Valid: 68.81%, Test: 65.88%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7634840171099944\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.763963, inference time:0:00:00.462138, \n",
            "Run: 1, Epoch: 289, Loss: 0.7516, Loss Cls: 0.7516, Train: 75.06%, Valid: 70.18%, Test: 70.14%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7630991521975786\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.845084, inference time:0:00:00.635866, \n",
            "Run: 1, Epoch: 290, Loss: 0.7463, Loss Cls: 0.7463, Train: 75.70%, Valid: 68.24%, Test: 64.97%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7653753532510089\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.033030, inference time:0:00:00.643842, \n",
            "Run: 1, Epoch: 291, Loss: 0.7445, Loss Cls: 0.7445, Train: 75.18%, Valid: 69.84%, Test: 70.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7641327893909238\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.041185, inference time:0:00:00.635364, \n",
            "Run: 1, Epoch: 292, Loss: 0.7415, Loss Cls: 0.7415, Train: 75.57%, Valid: 67.53%, Test: 63.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7663650058829351\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.100471, inference time:0:00:00.636480, \n",
            "Run: 1, Epoch: 293, Loss: 0.7398, Loss Cls: 0.7398, Train: 75.27%, Valid: 69.62%, Test: 70.22%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7656722490405867\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.029289, inference time:0:00:00.723102, \n",
            "Run: 1, Epoch: 294, Loss: 0.7381, Loss Cls: 0.7381, Train: 75.55%, Valid: 67.15%, Test: 63.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7672117086902497\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.109670, inference time:0:00:00.840292, \n",
            "Run: 1, Epoch: 295, Loss: 0.7372, Loss Cls: 0.7372, Train: 75.45%, Valid: 69.64%, Test: 70.34%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7659361564091004\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.151339, inference time:0:00:00.653742, \n",
            "Run: 1, Epoch: 296, Loss: 0.7359, Loss Cls: 0.7359, Train: 75.57%, Valid: 67.19%, Test: 63.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7670137781638645\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.055965, inference time:0:00:00.638872, \n",
            "Run: 1, Epoch: 297, Loss: 0.7362, Loss Cls: 0.7362, Train: 75.62%, Valid: 69.88%, Test: 70.50%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7665519402689656\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.155129, inference time:0:00:00.607074, \n",
            "Run: 1, Epoch: 298, Loss: 0.7357, Loss Cls: 0.7357, Train: 75.66%, Valid: 67.48%, Test: 63.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7664309827250635\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.050622, inference time:0:00:00.617565, \n",
            "Run: 1, Epoch: 299, Loss: 0.7377, Loss Cls: 0.7377, Train: 75.64%, Valid: 70.05%, Test: 70.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7670247743042192\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.015353, inference time:0:00:00.648734, \n",
            "Run: 1, Epoch: 300, Loss: 0.7392, Loss Cls: 0.7392, Train: 75.50%, Valid: 68.08%, Test: 64.65%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7637039399170891\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.017206, inference time:0:00:00.605681, \n",
            "Run: 1, Epoch: 301, Loss: 0.7431, Loss Cls: 0.7431, Train: 75.65%, Valid: 70.12%, Test: 70.43%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7648145500929174\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.720679, inference time:0:00:00.432646, \n",
            "Run: 1, Epoch: 302, Loss: 0.7451, Loss Cls: 0.7451, Train: 75.53%, Valid: 68.77%, Test: 66.16%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7619445574603314\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.737276, inference time:0:00:00.427065, \n",
            "Run: 1, Epoch: 303, Loss: 0.7452, Loss Cls: 0.7452, Train: 75.95%, Valid: 70.28%, Test: 70.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.766079106233712\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.027330, inference time:0:00:00.662277, \n",
            "Run: 1, Epoch: 304, Loss: 0.7437, Loss Cls: 0.7437, Train: 76.15%, Valid: 70.01%, Test: 68.42%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7642867353558901\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.155291, inference time:0:00:00.630086, \n",
            "Run: 1, Epoch: 305, Loss: 0.7368, Loss Cls: 0.7368, Train: 76.56%, Valid: 70.55%, Test: 69.62%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7695208981647442\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.042784, inference time:0:00:00.653633, \n",
            "Run: 1, Epoch: 306, Loss: 0.7340, Loss Cls: 0.7340, Train: 76.55%, Valid: 70.82%, Test: 69.90%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.767827492550115\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.096197, inference time:0:00:00.612229, \n",
            "Run: 1, Epoch: 307, Loss: 0.7275, Loss Cls: 0.7275, Train: 76.81%, Valid: 70.34%, Test: 68.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7704445739545419\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.088500, inference time:0:00:00.642865, \n",
            "Run: 1, Epoch: 308, Loss: 0.7270, Loss Cls: 0.7270, Train: 76.48%, Valid: 70.81%, Test: 70.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7687291760592032\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.019915, inference time:0:00:00.630510, \n",
            "Run: 1, Epoch: 309, Loss: 0.7257, Loss Cls: 0.7257, Train: 76.43%, Valid: 69.67%, Test: 67.28%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7685972223749464\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.951484, inference time:0:00:00.411122, \n",
            "Run: 1, Epoch: 310, Loss: 0.7297, Loss Cls: 0.7297, Train: 75.88%, Valid: 70.27%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7646496079875964\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.725682, inference time:0:00:00.427768, \n",
            "Run: 1, Epoch: 311, Loss: 0.7338, Loss Cls: 0.7338, Train: 75.67%, Valid: 68.78%, Test: 65.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7647705655314985\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.722588, inference time:0:00:00.418784, \n",
            "Run: 1, Epoch: 312, Loss: 0.7406, Loss Cls: 0.7406, Train: 75.36%, Valid: 69.83%, Test: 70.30%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7629781946536766\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.698132, inference time:0:00:00.424418, \n",
            "Run: 1, Epoch: 313, Loss: 0.7411, Loss Cls: 0.7411, Train: 75.50%, Valid: 68.44%, Test: 65.02%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.764209762373407\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.713725, inference time:0:00:00.417665, \n",
            "Run: 1, Epoch: 314, Loss: 0.7395, Loss Cls: 0.7395, Train: 75.75%, Valid: 69.93%, Test: 70.47%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7665299479882561\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.728608, inference time:0:00:00.420809, \n",
            "Run: 1, Epoch: 315, Loss: 0.7345, Loss Cls: 0.7345, Train: 75.97%, Valid: 68.85%, Test: 65.61%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7670027820235098\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.688223, inference time:0:00:00.432867, \n",
            "Run: 1, Epoch: 316, Loss: 0.7304, Loss Cls: 0.7304, Train: 76.32%, Valid: 70.37%, Test: 70.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7698067978139673\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.730372, inference time:0:00:00.435625, \n",
            "Run: 1, Epoch: 317, Loss: 0.7261, Loss Cls: 0.7261, Train: 76.39%, Valid: 69.25%, Test: 66.25%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7696198634279368\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.731608, inference time:0:00:00.425003, \n",
            "Run: 1, Epoch: 318, Loss: 0.7244, Loss Cls: 0.7244, Train: 76.60%, Valid: 70.74%, Test: 70.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7713242651829207\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.900635, inference time:0:00:00.633150, \n",
            "Run: 1, Epoch: 319, Loss: 0.7227, Loss Cls: 0.7227, Train: 76.50%, Valid: 69.67%, Test: 66.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7697078325507747\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.054570, inference time:0:00:00.627525, \n",
            "Run: 1, Epoch: 320, Loss: 0.7229, Loss Cls: 0.7229, Train: 76.59%, Valid: 70.81%, Test: 70.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7703676009720588\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.014975, inference time:0:00:00.618712, \n",
            "Run: 1, Epoch: 321, Loss: 0.7244, Loss Cls: 0.7244, Train: 76.43%, Valid: 69.79%, Test: 67.12%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7683772995678517\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.013644, inference time:0:00:00.611888, \n",
            "Run: 1, Epoch: 322, Loss: 0.7256, Loss Cls: 0.7256, Train: 76.40%, Valid: 70.76%, Test: 70.61%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.769114040971619\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.109465, inference time:0:00:00.618524, \n",
            "Run: 1, Epoch: 323, Loss: 0.7288, Loss Cls: 0.7288, Train: 76.33%, Valid: 69.65%, Test: 67.12%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7682233536028854\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.016928, inference time:0:00:00.619543, \n",
            "Run: 1, Epoch: 324, Loss: 0.7291, Loss Cls: 0.7291, Train: 76.27%, Valid: 70.60%, Test: 70.63%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.769234998515521\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.109831, inference time:0:00:00.483790, \n",
            "Run: 1, Epoch: 325, Loss: 0.7292, Loss Cls: 0.7292, Train: 76.47%, Valid: 69.57%, Test: 67.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.769399940620842\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.739648, inference time:0:00:00.408913, \n",
            "Run: 1, Epoch: 326, Loss: 0.7271, Loss Cls: 0.7271, Train: 76.17%, Valid: 70.50%, Test: 70.71%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7713902420250492\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.716605, inference time:0:00:00.416076, \n",
            "Run: 1, Epoch: 327, Loss: 0.7240, Loss Cls: 0.7240, Train: 76.50%, Valid: 69.31%, Test: 66.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7703456086913494\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.763156, inference time:0:00:00.450305, \n",
            "Run: 1, Epoch: 328, Loss: 0.7231, Loss Cls: 0.7231, Train: 76.04%, Valid: 70.31%, Test: 70.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7712912767618566\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.698535, inference time:0:00:00.428596, \n",
            "Run: 1, Epoch: 329, Loss: 0.7220, Loss Cls: 0.7220, Train: 76.25%, Valid: 68.84%, Test: 65.69%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.769234998515521\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.719413, inference time:0:00:00.428008, \n",
            "Run: 1, Epoch: 330, Loss: 0.7259, Loss Cls: 0.7259, Train: 75.48%, Valid: 69.64%, Test: 70.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7689930834277169\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.718566, inference time:0:00:00.446222, \n",
            "Run: 1, Epoch: 331, Loss: 0.7272, Loss Cls: 0.7272, Train: 75.75%, Valid: 67.90%, Test: 64.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7662000637776141\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.741391, inference time:0:00:00.420734, \n",
            "Run: 1, Epoch: 332, Loss: 0.7338, Loss Cls: 0.7338, Train: 75.19%, Valid: 69.14%, Test: 69.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7683113227257232\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.736710, inference time:0:00:00.412162, \n",
            "Run: 1, Epoch: 333, Loss: 0.7298, Loss Cls: 0.7298, Train: 75.85%, Valid: 67.79%, Test: 64.37%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7670907511463476\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.780715, inference time:0:00:00.658861, \n",
            "Run: 1, Epoch: 334, Loss: 0.7306, Loss Cls: 0.7306, Train: 75.71%, Valid: 69.63%, Test: 70.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.771148326937245\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.055152, inference time:0:00:00.594534, \n",
            "Run: 1, Epoch: 335, Loss: 0.7210, Loss Cls: 0.7210, Train: 76.51%, Valid: 68.63%, Test: 65.58%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7718410837795934\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.025358, inference time:0:00:00.610028, \n",
            "Run: 1, Epoch: 336, Loss: 0.7169, Loss Cls: 0.7169, Train: 76.56%, Valid: 70.32%, Test: 70.38%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7748650223771456\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.025756, inference time:0:00:00.603421, \n",
            "Run: 1, Epoch: 337, Loss: 0.7100, Loss Cls: 0.7100, Train: 77.00%, Valid: 69.40%, Test: 66.74%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.775183910447433\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.088849, inference time:0:00:00.621489, \n",
            "Run: 1, Epoch: 338, Loss: 0.7069, Loss Cls: 0.7069, Train: 77.03%, Valid: 70.61%, Test: 70.45%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7773281578166064\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.042003, inference time:0:00:00.632542, \n",
            "Run: 1, Epoch: 339, Loss: 0.7038, Loss Cls: 0.7038, Train: 77.21%, Valid: 69.67%, Test: 67.24%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7761625669390044\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.990450, inference time:0:00:00.623829, \n",
            "Run: 1, Epoch: 340, Loss: 0.7030, Loss Cls: 0.7030, Train: 77.09%, Valid: 70.60%, Test: 70.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7769103044831264\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.724810, inference time:0:00:00.420459, \n",
            "Run: 1, Epoch: 341, Loss: 0.7028, Loss Cls: 0.7028, Train: 77.09%, Valid: 69.66%, Test: 67.29%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7751289297456593\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.707670, inference time:0:00:00.432337, \n",
            "Run: 1, Epoch: 342, Loss: 0.7041, Loss Cls: 0.7041, Train: 76.89%, Valid: 70.35%, Test: 69.88%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7753598486931087\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.728914, inference time:0:00:00.423522, \n",
            "Run: 1, Epoch: 343, Loss: 0.7063, Loss Cls: 0.7063, Train: 76.72%, Valid: 69.48%, Test: 67.18%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7733695472889016\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.735665, inference time:0:00:00.437818, \n",
            "Run: 1, Epoch: 344, Loss: 0.7090, Loss Cls: 0.7090, Train: 76.66%, Valid: 70.15%, Test: 69.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7747330686928888\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.740578, inference time:0:00:00.428061, \n",
            "Run: 1, Epoch: 345, Loss: 0.7124, Loss Cls: 0.7124, Train: 76.54%, Valid: 69.52%, Test: 67.33%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7711703192179545\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.746875, inference time:0:00:00.436479, \n",
            "Run: 1, Epoch: 346, Loss: 0.7138, Loss Cls: 0.7138, Train: 76.78%, Valid: 70.13%, Test: 69.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7735674778152868\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.713301, inference time:0:00:00.428552, \n",
            "Run: 1, Epoch: 347, Loss: 0.7156, Loss Cls: 0.7156, Train: 76.83%, Valid: 70.13%, Test: 68.37%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7708734234283766\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.719836, inference time:0:00:00.440015, \n",
            "Run: 1, Epoch: 348, Loss: 0.7138, Loss Cls: 0.7138, Train: 77.01%, Valid: 70.18%, Test: 69.10%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7737434160609626\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.746534, inference time:0:00:00.646085, \n",
            "Run: 1, Epoch: 349, Loss: 0.7142, Loss Cls: 0.7142, Train: 77.16%, Valid: 70.93%, Test: 69.41%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.772148975709526\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.093849, inference time:0:00:00.675736, \n",
            "Run: 1, Epoch: 350, Loss: 0.7120, Loss Cls: 0.7120, Train: 77.12%, Valid: 70.15%, Test: 68.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7734135318503206\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.075414, inference time:0:00:00.656438, \n",
            "Run: 1, Epoch: 351, Loss: 0.7144, Loss Cls: 0.7144, Train: 77.37%, Valid: 70.98%, Test: 69.71%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7733475550081921\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.098357, inference time:0:00:00.601053, \n",
            "Run: 1, Epoch: 352, Loss: 0.7112, Loss Cls: 0.7112, Train: 77.05%, Valid: 70.05%, Test: 68.49%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7733585511485469\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.040335, inference time:0:00:00.588895, \n",
            "Run: 1, Epoch: 353, Loss: 0.7137, Loss Cls: 0.7137, Train: 77.18%, Valid: 70.74%, Test: 69.33%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.77301767079755\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.088328, inference time:0:00:00.610428, \n",
            "Run: 1, Epoch: 354, Loss: 0.7098, Loss Cls: 0.7098, Train: 76.84%, Valid: 69.98%, Test: 68.35%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7731936090432259\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.994083, inference time:0:00:00.604288, \n",
            "Run: 1, Epoch: 355, Loss: 0.7127, Loss Cls: 0.7127, Train: 76.91%, Valid: 70.39%, Test: 69.10%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7714782111478871\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.738173, inference time:0:00:00.440050, \n",
            "Run: 1, Epoch: 356, Loss: 0.7124, Loss Cls: 0.7124, Train: 76.41%, Valid: 69.61%, Test: 67.73%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7695868750068726\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.701278, inference time:0:00:00.427621, \n",
            "Run: 1, Epoch: 357, Loss: 0.7160, Loss Cls: 0.7160, Train: 76.73%, Valid: 70.24%, Test: 68.93%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7706425044809272\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.708134, inference time:0:00:00.432759, \n",
            "Run: 1, Epoch: 358, Loss: 0.7139, Loss Cls: 0.7139, Train: 76.56%, Valid: 69.59%, Test: 67.50%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7715002034285966\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.715734, inference time:0:00:00.437307, \n",
            "Run: 1, Epoch: 359, Loss: 0.7103, Loss Cls: 0.7103, Train: 77.13%, Valid: 70.16%, Test: 69.05%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.774930999219274\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.707467, inference time:0:00:00.433528, \n",
            "Run: 1, Epoch: 360, Loss: 0.7032, Loss Cls: 0.7032, Train: 77.16%, Valid: 69.70%, Test: 67.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7764374704478728\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.713752, inference time:0:00:00.458340, \n",
            "Run: 1, Epoch: 361, Loss: 0.6981, Loss Cls: 0.6981, Train: 77.60%, Valid: 70.37%, Test: 69.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7789995711505262\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.731411, inference time:0:00:00.443603, \n",
            "Run: 1, Epoch: 362, Loss: 0.6932, Loss Cls: 0.6932, Train: 77.61%, Valid: 70.00%, Test: 68.00%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7792634785190398\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.719340, inference time:0:00:00.454699, \n",
            "Run: 1, Epoch: 363, Loss: 0.6921, Loss Cls: 0.6921, Train: 77.80%, Valid: 70.49%, Test: 69.51%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7803960809755776\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.743119, inference time:0:00:00.537098, \n",
            "Run: 1, Epoch: 364, Loss: 0.6901, Loss Cls: 0.6901, Train: 77.74%, Valid: 69.96%, Test: 67.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7790985364137187\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.112546, inference time:0:00:00.672506, \n",
            "Run: 1, Epoch: 365, Loss: 0.6926, Loss Cls: 0.6926, Train: 77.82%, Valid: 70.60%, Test: 69.54%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7791975016769114\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:01.111686, inference time:0:00:00.647358, \n",
            "Run: 1, Epoch: 366, Loss: 0.6923, Loss Cls: 0.6923, Train: 77.65%, Valid: 69.95%, Test: 67.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7766244048339033\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.993229, inference time:0:00:00.644276, \n",
            "Run: 1, Epoch: 367, Loss: 0.6979, Loss Cls: 0.6979, Train: 77.65%, Valid: 70.65%, Test: 69.53%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7772511848341233\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.012149, inference time:0:00:00.651574, \n",
            "Run: 1, Epoch: 368, Loss: 0.6980, Loss Cls: 0.6980, Train: 77.44%, Valid: 69.93%, Test: 68.01%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7739413465873478\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.066050, inference time:0:00:00.669390, \n",
            "Run: 1, Epoch: 369, Loss: 0.7048, Loss Cls: 0.7048, Train: 77.55%, Valid: 70.73%, Test: 69.59%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.775469810096656\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.134565, inference time:0:00:00.651751, \n",
            "Run: 1, Epoch: 370, Loss: 0.7043, Loss Cls: 0.7043, Train: 77.38%, Valid: 70.01%, Test: 68.33%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7730506592186143\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.851164, inference time:0:00:00.448777, \n",
            "Run: 1, Epoch: 371, Loss: 0.7079, Loss Cls: 0.7079, Train: 77.40%, Valid: 70.79%, Test: 69.52%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7749200030789193\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.704803, inference time:0:00:00.447508, \n",
            "Run: 1, Epoch: 372, Loss: 0.7065, Loss Cls: 0.7065, Train: 77.30%, Valid: 69.87%, Test: 68.53%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7742272462365709\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.745261, inference time:0:00:00.433976, \n",
            "Run: 1, Epoch: 373, Loss: 0.7063, Loss Cls: 0.7063, Train: 77.23%, Valid: 70.64%, Test: 69.19%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7751179336053046\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.760933, inference time:0:00:00.428855, \n",
            "Run: 1, Epoch: 374, Loss: 0.7065, Loss Cls: 0.7065, Train: 76.95%, Valid: 69.64%, Test: 68.61%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7739633388680573\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.735828, inference time:0:00:00.422824, \n",
            "Run: 1, Epoch: 375, Loss: 0.7075, Loss Cls: 0.7075, Train: 76.96%, Valid: 70.40%, Test: 68.77%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7752278950088519\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.747102, inference time:0:00:00.439278, \n",
            "Run: 1, Epoch: 376, Loss: 0.7054, Loss Cls: 0.7054, Train: 77.05%, Valid: 69.72%, Test: 68.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7747330686928888\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.719526, inference time:0:00:00.449857, \n",
            "Run: 1, Epoch: 377, Loss: 0.7039, Loss Cls: 0.7039, Train: 77.28%, Valid: 70.26%, Test: 68.40%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7780648992203737\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.711809, inference time:0:00:00.434970, \n",
            "Run: 1, Epoch: 378, Loss: 0.6966, Loss Cls: 0.6966, Train: 77.64%, Valid: 70.05%, Test: 69.41%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7788016406241409\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.52, Epoch train time:0:00:00.772978, inference time:0:00:00.605671, \n",
            "Run: 1, Epoch: 379, Loss: 0.6927, Loss Cls: 0.6927, Train: 77.66%, Valid: 69.98%, Test: 67.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7804290693966418\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.113046, inference time:0:00:00.659624, \n",
            "Run: 1, Epoch: 380, Loss: 0.6892, Loss Cls: 0.6892, Train: 77.77%, Valid: 69.97%, Test: 69.28%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7800552006245808\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.076751, inference time:0:00:00.649302, \n",
            "Run: 1, Epoch: 381, Loss: 0.6884, Loss Cls: 0.6884, Train: 77.39%, Valid: 69.11%, Test: 66.16%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7809788764143786\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.109525, inference time:0:00:00.677213, \n",
            "Run: 1, Epoch: 382, Loss: 0.6895, Loss Cls: 0.6895, Train: 77.23%, Valid: 69.28%, Test: 68.62%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7777240188693768\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.040820, inference time:0:00:00.643882, \n",
            "Run: 1, Epoch: 383, Loss: 0.6927, Loss Cls: 0.6927, Train: 76.63%, Valid: 67.69%, Test: 64.46%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7784607602731441\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.037569, inference time:0:00:00.628289, \n",
            "Run: 1, Epoch: 384, Loss: 0.6964, Loss Cls: 0.6964, Train: 76.46%, Valid: 68.46%, Test: 68.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7745021497454394\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.084743, inference time:0:00:00.663028, \n",
            "Run: 1, Epoch: 385, Loss: 0.7007, Loss Cls: 0.7007, Train: 76.08%, Valid: 66.66%, Test: 63.02%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7767673546585149\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.766940, inference time:0:00:00.437901, \n",
            "Run: 1, Epoch: 386, Loss: 0.7002, Loss Cls: 0.7002, Train: 76.10%, Valid: 68.38%, Test: 68.57%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7755027985177203\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.735803, inference time:0:00:00.436258, \n",
            "Run: 1, Epoch: 387, Loss: 0.6988, Loss Cls: 0.6988, Train: 76.36%, Valid: 66.77%, Test: 62.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7781858567642758\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.771658, inference time:0:00:00.449296, \n",
            "Run: 1, Epoch: 388, Loss: 0.6936, Loss Cls: 0.6936, Train: 76.17%, Valid: 69.04%, Test: 69.43%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7781968529046305\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.724241, inference time:0:00:00.437341, \n",
            "Run: 1, Epoch: 389, Loss: 0.6897, Loss Cls: 0.6897, Train: 76.35%, Valid: 66.41%, Test: 62.19%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7802531311509661\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.725950, inference time:0:00:00.440489, \n",
            "Run: 1, Epoch: 390, Loss: 0.6880, Loss Cls: 0.6880, Train: 76.08%, Valid: 69.08%, Test: 69.73%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7807039729055102\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.724617, inference time:0:00:00.446984, \n",
            "Run: 1, Epoch: 391, Loss: 0.6860, Loss Cls: 0.6860, Train: 76.18%, Valid: 65.96%, Test: 61.42%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.779087540273364\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.738427, inference time:0:00:00.462512, \n",
            "Run: 1, Epoch: 392, Loss: 0.6884, Loss Cls: 0.6884, Train: 75.82%, Valid: 68.82%, Test: 69.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7798132855367766\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.693234, inference time:0:00:00.440766, \n",
            "Run: 1, Epoch: 393, Loss: 0.6876, Loss Cls: 0.6876, Train: 76.16%, Valid: 66.07%, Test: 61.22%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7769872774656096\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.795375, inference time:0:00:00.672301, \n",
            "Run: 1, Epoch: 394, Loss: 0.6914, Loss Cls: 0.6914, Train: 75.94%, Valid: 69.00%, Test: 69.99%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7787906444837862\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.168096, inference time:0:00:00.636372, \n",
            "Run: 1, Epoch: 395, Loss: 0.6902, Loss Cls: 0.6902, Train: 76.37%, Valid: 66.75%, Test: 62.14%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7737544122013174\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.114965, inference time:0:00:00.646271, \n",
            "Run: 1, Epoch: 396, Loss: 0.6953, Loss Cls: 0.6953, Train: 76.25%, Valid: 69.62%, Test: 70.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7765474318514202\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.078810, inference time:0:00:00.659365, \n",
            "Run: 1, Epoch: 397, Loss: 0.6948, Loss Cls: 0.6948, Train: 76.36%, Valid: 67.75%, Test: 63.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7700926974631904\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.100759, inference time:0:00:00.645457, \n",
            "Run: 1, Epoch: 398, Loss: 0.7039, Loss Cls: 0.7039, Train: 76.57%, Valid: 70.08%, Test: 70.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7748870146578551\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.033985, inference time:0:00:00.649255, \n",
            "Run: 1, Epoch: 399, Loss: 0.6983, Loss Cls: 0.6983, Train: 76.62%, Valid: 68.73%, Test: 65.56%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.771984033604205\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.076262, inference time:0:00:00.547230, \n",
            "Run: 1, Epoch: 400, Loss: 0.7023, Loss Cls: 0.7023, Train: 77.46%, Valid: 70.67%, Test: 70.92%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7803081118527397\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.714377, inference time:0:00:00.453296, \n",
            "Run: 1, Epoch: 401, Loss: 0.6864, Loss Cls: 0.6864, Train: 77.62%, Valid: 69.94%, Test: 67.67%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7796923279928745\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.774315, inference time:0:00:00.430562, \n",
            "Run: 1, Epoch: 402, Loss: 0.6835, Loss Cls: 0.6835, Train: 78.24%, Valid: 71.11%, Test: 70.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7852123904509517\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.741886, inference time:0:00:00.437809, \n",
            "Run: 1, Epoch: 403, Loss: 0.6741, Loss Cls: 0.6741, Train: 78.28%, Valid: 70.60%, Test: 68.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.784618598871796\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.771054, inference time:0:00:00.450202, \n",
            "Run: 1, Epoch: 404, Loss: 0.6723, Loss Cls: 0.6723, Train: 78.56%, Valid: 70.93%, Test: 70.29%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.786905796065581\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.733318, inference time:0:00:00.438246, \n",
            "Run: 1, Epoch: 405, Loss: 0.6688, Loss Cls: 0.6688, Train: 78.43%, Valid: 70.87%, Test: 69.45%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7864329620303273\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.739322, inference time:0:00:00.436865, \n",
            "Run: 1, Epoch: 406, Loss: 0.6691, Loss Cls: 0.6691, Train: 78.47%, Valid: 70.80%, Test: 69.62%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.786696869398841\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.769255, inference time:0:00:00.447374, \n",
            "Run: 1, Epoch: 407, Loss: 0.6692, Loss Cls: 0.6692, Train: 78.32%, Valid: 70.89%, Test: 69.82%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7860810855389758\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.729099, inference time:0:00:00.446929, \n",
            "Run: 1, Epoch: 408, Loss: 0.6728, Loss Cls: 0.6728, Train: 77.87%, Valid: 70.31%, Test: 68.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7823973785201395\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.956828, inference time:0:00:00.644763, \n",
            "Run: 1, Epoch: 409, Loss: 0.6776, Loss Cls: 0.6776, Train: 77.93%, Valid: 70.55%, Test: 69.70%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7817046216777911\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.073165, inference time:0:00:00.612714, \n",
            "Run: 1, Epoch: 410, Loss: 0.6868, Loss Cls: 0.6868, Train: 76.91%, Valid: 69.85%, Test: 68.25%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7746011150086319\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.968524, inference time:0:00:00.599688, \n",
            "Run: 1, Epoch: 411, Loss: 0.6956, Loss Cls: 0.6956, Train: 77.42%, Valid: 69.99%, Test: 69.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.775601763780913\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.981614, inference time:0:00:00.602642, \n",
            "Run: 1, Epoch: 412, Loss: 0.7013, Loss Cls: 0.7013, Train: 76.72%, Valid: 69.81%, Test: 68.27%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7724898560605228\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.085027, inference time:0:00:00.636568, \n",
            "Run: 1, Epoch: 413, Loss: 0.6993, Loss Cls: 0.6993, Train: 77.78%, Valid: 70.19%, Test: 69.14%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7801431697474187\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.116297, inference time:0:00:00.671669, \n",
            "Run: 1, Epoch: 414, Loss: 0.6892, Loss Cls: 0.6892, Train: 77.37%, Valid: 70.42%, Test: 68.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7792854707997493\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.130854, inference time:0:00:00.637336, \n",
            "Run: 1, Epoch: 415, Loss: 0.6840, Loss Cls: 0.6840, Train: 78.27%, Valid: 70.20%, Test: 69.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.783288065888873\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.063975, inference time:0:00:00.629058, \n",
            "Run: 1, Epoch: 416, Loss: 0.6789, Loss Cls: 0.6789, Train: 77.63%, Valid: 70.63%, Test: 69.06%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7810118648354427\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.088768, inference time:0:00:00.643775, \n",
            "Run: 1, Epoch: 417, Loss: 0.6786, Loss Cls: 0.6786, Train: 78.37%, Valid: 70.33%, Test: 69.12%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7847175641349886\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.100992, inference time:0:00:00.676305, \n",
            "Run: 1, Epoch: 418, Loss: 0.6776, Loss Cls: 0.6776, Train: 77.93%, Valid: 70.65%, Test: 69.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7835849616784508\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.046330, inference time:0:00:00.663406, \n",
            "Run: 1, Epoch: 419, Loss: 0.6752, Loss Cls: 0.6752, Train: 78.61%, Valid: 70.64%, Test: 69.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7857621974686885\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.100904, inference time:0:00:00.531444, \n",
            "Run: 1, Epoch: 420, Loss: 0.6719, Loss Cls: 0.6719, Train: 78.39%, Valid: 70.68%, Test: 69.21%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7868508153638073\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.732219, inference time:0:00:00.433283, \n",
            "Run: 1, Epoch: 421, Loss: 0.6670, Loss Cls: 0.6670, Train: 78.95%, Valid: 70.98%, Test: 70.03%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7888960974697881\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.729315, inference time:0:00:00.433417, \n",
            "Run: 1, Epoch: 422, Loss: 0.6625, Loss Cls: 0.6625, Train: 78.70%, Valid: 70.56%, Test: 68.91%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7899517269438427\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.084731, inference time:0:00:00.660294, \n",
            "Run: 1, Epoch: 423, Loss: 0.6596, Loss Cls: 0.6596, Train: 78.94%, Valid: 71.07%, Test: 70.43%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7898197732595859\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.147280, inference time:0:00:00.633020, \n",
            "Run: 1, Epoch: 424, Loss: 0.6575, Loss Cls: 0.6575, Train: 78.80%, Valid: 70.16%, Test: 67.97%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7902706150141301\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.185320, inference time:0:00:00.637056, \n",
            "Run: 1, Epoch: 425, Loss: 0.6587, Loss Cls: 0.6587, Train: 78.38%, Valid: 70.72%, Test: 70.65%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7885222286977271\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.053941, inference time:0:00:00.638639, \n",
            "Run: 1, Epoch: 426, Loss: 0.6610, Loss Cls: 0.6610, Train: 78.03%, Valid: 68.89%, Test: 65.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7858391704511717\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.017036, inference time:0:00:00.626093, \n",
            "Run: 1, Epoch: 427, Loss: 0.6681, Loss Cls: 0.6681, Train: 76.83%, Valid: 69.49%, Test: 70.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7818255792216932\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.071753, inference time:0:00:00.680713, \n",
            "Run: 1, Epoch: 428, Loss: 0.6751, Loss Cls: 0.6751, Train: 76.79%, Valid: 66.94%, Test: 62.81%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.778548729395982\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.924721, inference time:0:00:00.444935, \n",
            "Run: 1, Epoch: 429, Loss: 0.6846, Loss Cls: 0.6846, Train: 75.74%, Valid: 68.18%, Test: 69.28%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7771962041323496\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.726367, inference time:0:00:00.443804, \n",
            "Run: 1, Epoch: 430, Loss: 0.6861, Loss Cls: 0.6861, Train: 76.76%, Valid: 66.85%, Test: 62.50%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7788126367644956\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.736591, inference time:0:00:00.447404, \n",
            "Run: 1, Epoch: 431, Loss: 0.6844, Loss Cls: 0.6844, Train: 76.55%, Valid: 68.99%, Test: 69.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7809678802740239\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.752868, inference time:0:00:00.438029, \n",
            "Run: 1, Epoch: 432, Loss: 0.6760, Loss Cls: 0.6760, Train: 77.72%, Valid: 68.14%, Test: 64.37%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7838268767662551\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.788184, inference time:0:00:00.435076, \n",
            "Run: 1, Epoch: 433, Loss: 0.6706, Loss Cls: 0.6706, Train: 77.71%, Valid: 69.87%, Test: 70.53%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.785949131854719\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.728507, inference time:0:00:00.450742, \n",
            "Run: 1, Epoch: 434, Loss: 0.6656, Loss Cls: 0.6656, Train: 78.04%, Valid: 68.91%, Test: 65.84%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.78653192729352\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.742065, inference time:0:00:00.441157, \n",
            "Run: 1, Epoch: 435, Loss: 0.6653, Loss Cls: 0.6653, Train: 77.97%, Valid: 69.89%, Test: 69.95%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7867628462409694\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.774282, inference time:0:00:00.460403, \n",
            "Run: 1, Epoch: 436, Loss: 0.6655, Loss Cls: 0.6655, Train: 77.88%, Valid: 69.24%, Test: 66.47%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7845086374682486\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.740286, inference time:0:00:00.599033, \n",
            "Run: 1, Epoch: 437, Loss: 0.6702, Loss Cls: 0.6702, Train: 77.73%, Valid: 69.61%, Test: 69.43%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7841347686961876\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.110484, inference time:0:00:00.665138, \n",
            "Run: 1, Epoch: 438, Loss: 0.6724, Loss Cls: 0.6724, Train: 77.60%, Valid: 69.43%, Test: 66.87%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7820125136077237\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.091689, inference time:0:00:00.637771, \n",
            "Run: 1, Epoch: 439, Loss: 0.6771, Loss Cls: 0.6771, Train: 77.76%, Valid: 69.98%, Test: 69.57%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7816826293970817\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.085378, inference time:0:00:00.638669, \n",
            "Run: 1, Epoch: 440, Loss: 0.6781, Loss Cls: 0.6781, Train: 77.85%, Valid: 69.79%, Test: 67.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7826832781693626\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.054779, inference time:0:00:00.683362, \n",
            "Run: 1, Epoch: 441, Loss: 0.6750, Loss Cls: 0.6750, Train: 78.16%, Valid: 70.69%, Test: 70.08%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7840577957137045\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.073323, inference time:0:00:00.648278, \n",
            "Run: 1, Epoch: 442, Loss: 0.6732, Loss Cls: 0.6732, Train: 78.36%, Valid: 70.17%, Test: 68.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7868068308023883\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.025023, inference time:0:00:00.631184, \n",
            "Run: 1, Epoch: 443, Loss: 0.6644, Loss Cls: 0.6644, Train: 78.55%, Valid: 71.02%, Test: 70.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7873676339604798\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.786642, inference time:0:00:00.433672, \n",
            "Run: 1, Epoch: 444, Loss: 0.6629, Loss Cls: 0.6629, Train: 78.55%, Valid: 70.03%, Test: 68.34%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7885992016802102\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.759794, inference time:0:00:00.428778, \n",
            "Run: 1, Epoch: 445, Loss: 0.6576, Loss Cls: 0.6576, Train: 78.31%, Valid: 70.69%, Test: 69.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.788940082031207\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.733088, inference time:0:00:00.429718, \n",
            "Run: 1, Epoch: 446, Loss: 0.6590, Loss Cls: 0.6590, Train: 78.26%, Valid: 69.69%, Test: 67.94%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7883462904520513\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.787429, inference time:0:00:00.464291, \n",
            "Run: 1, Epoch: 447, Loss: 0.6585, Loss Cls: 0.6585, Train: 77.71%, Valid: 70.05%, Test: 68.74%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7870047613287736\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.730124, inference time:0:00:00.470511, \n",
            "Run: 1, Epoch: 448, Loss: 0.6632, Loss Cls: 0.6632, Train: 77.85%, Valid: 69.58%, Test: 67.75%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7845856104507318\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.731800, inference time:0:00:00.427035, \n",
            "Run: 1, Epoch: 449, Loss: 0.6659, Loss Cls: 0.6659, Train: 77.27%, Valid: 69.67%, Test: 68.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7838598651873192\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.716936, inference time:0:00:00.427409, \n",
            "Run: 1, Epoch: 450, Loss: 0.6732, Loss Cls: 0.6732, Train: 77.48%, Valid: 69.71%, Test: 68.20%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7796813318525198\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.749776, inference time:0:00:00.446970, \n",
            "Run: 1, Epoch: 451, Loss: 0.6752, Loss Cls: 0.6752, Train: 77.34%, Valid: 69.83%, Test: 68.34%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7814737027303417\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.771052, inference time:0:00:00.676408, \n",
            "Run: 1, Epoch: 452, Loss: 0.6785, Loss Cls: 0.6785, Train: 77.91%, Valid: 70.25%, Test: 68.79%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7820015174673689\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.106189, inference time:0:00:00.635976, \n",
            "Run: 1, Epoch: 453, Loss: 0.6701, Loss Cls: 0.6701, Train: 78.28%, Valid: 70.05%, Test: 68.55%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7860590932582664\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.154771, inference time:0:00:00.660010, \n",
            "Run: 1, Epoch: 454, Loss: 0.6636, Loss Cls: 0.6636, Train: 78.62%, Valid: 70.54%, Test: 69.36%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7882693174695682\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.028559, inference time:0:00:00.653349, \n",
            "Run: 1, Epoch: 455, Loss: 0.6545, Loss Cls: 0.6545, Train: 78.86%, Valid: 69.83%, Test: 68.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7913372406285394\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.095629, inference time:0:00:00.633742, \n",
            "Run: 1, Epoch: 456, Loss: 0.6505, Loss Cls: 0.6505, Train: 78.92%, Valid: 70.72%, Test: 69.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7923158971201109\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.117981, inference time:0:00:00.644186, \n",
            "Run: 1, Epoch: 457, Loss: 0.6474, Loss Cls: 0.6474, Train: 79.02%, Valid: 69.48%, Test: 67.26%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7931186153660066\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.010228, inference time:0:00:00.632443, \n",
            "Run: 1, Epoch: 458, Loss: 0.6457, Loss Cls: 0.6457, Train: 78.91%, Valid: 70.82%, Test: 69.98%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7928767002782023\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.735157, inference time:0:00:00.436555, \n",
            "Run: 1, Epoch: 459, Loss: 0.6456, Loss Cls: 0.6456, Train: 78.95%, Valid: 69.00%, Test: 66.35%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7930856269449423\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.708972, inference time:0:00:00.438128, \n",
            "Run: 1, Epoch: 460, Loss: 0.6451, Loss Cls: 0.6451, Train: 78.66%, Valid: 70.65%, Test: 70.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7920959743130161\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.735127, inference time:0:00:00.438699, \n",
            "Run: 1, Epoch: 461, Loss: 0.6468, Loss Cls: 0.6468, Train: 78.51%, Valid: 68.42%, Test: 65.16%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7904465532598058\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.737572, inference time:0:00:00.439930, \n",
            "Run: 1, Epoch: 462, Loss: 0.6482, Loss Cls: 0.6482, Train: 78.19%, Valid: 70.08%, Test: 70.01%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7890500434347544\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.740396, inference time:0:00:00.426977, \n",
            "Run: 1, Epoch: 463, Loss: 0.6519, Loss Cls: 0.6519, Train: 77.84%, Valid: 67.53%, Test: 63.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7868947999252263\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.713506, inference time:0:00:00.442945, \n",
            "Run: 1, Epoch: 464, Loss: 0.6548, Loss Cls: 0.6548, Train: 77.64%, Valid: 69.33%, Test: 69.64%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.786905796065581\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.752124, inference time:0:00:00.447305, \n",
            "Run: 1, Epoch: 465, Loss: 0.6573, Loss Cls: 0.6573, Train: 77.39%, Valid: 66.77%, Test: 62.82%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7855422746615938\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.729255, inference time:0:00:00.438351, \n",
            "Run: 1, Epoch: 466, Loss: 0.6580, Loss Cls: 0.6580, Train: 77.51%, Valid: 68.94%, Test: 69.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7877305065921861\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.785511, inference time:0:00:00.690037, \n",
            "Run: 1, Epoch: 467, Loss: 0.6561, Loss Cls: 0.6561, Train: 77.45%, Valid: 66.81%, Test: 62.78%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7864109697496179\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.121060, inference time:0:00:00.650926, \n",
            "Run: 1, Epoch: 468, Loss: 0.6563, Loss Cls: 0.6563, Train: 77.69%, Valid: 69.07%, Test: 69.42%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7900946767684542\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.052516, inference time:0:00:00.659531, \n",
            "Run: 1, Epoch: 469, Loss: 0.6517, Loss Cls: 0.6517, Train: 77.88%, Valid: 67.28%, Test: 63.47%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.789192993259366\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.103844, inference time:0:00:00.664899, \n",
            "Run: 1, Epoch: 470, Loss: 0.6520, Loss Cls: 0.6520, Train: 78.01%, Valid: 69.49%, Test: 69.76%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7907764374704479\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.072627, inference time:0:00:00.653986, \n",
            "Run: 1, Epoch: 471, Loss: 0.6474, Loss Cls: 0.6474, Train: 78.27%, Valid: 67.73%, Test: 64.15%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7914911865935057\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.065664, inference time:0:00:00.671376, \n",
            "Run: 1, Epoch: 472, Loss: 0.6482, Loss Cls: 0.6482, Train: 78.19%, Valid: 69.70%, Test: 69.96%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7912602676460563\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.097421, inference time:0:00:00.508491, \n",
            "Run: 1, Epoch: 473, Loss: 0.6455, Loss Cls: 0.6455, Train: 78.42%, Valid: 68.06%, Test: 64.57%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7920080051901782\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.724553, inference time:0:00:00.459753, \n",
            "Run: 1, Epoch: 474, Loss: 0.6473, Loss Cls: 0.6473, Train: 78.17%, Valid: 69.71%, Test: 70.06%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7907984297511573\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.728019, inference time:0:00:00.459917, \n",
            "Run: 1, Epoch: 475, Loss: 0.6466, Loss Cls: 0.6466, Train: 78.38%, Valid: 68.16%, Test: 64.66%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7911503062425089\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.725920, inference time:0:00:00.449866, \n",
            "Run: 1, Epoch: 476, Loss: 0.6489, Loss Cls: 0.6489, Train: 77.92%, Valid: 69.66%, Test: 70.14%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7898417655402954\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.747339, inference time:0:00:00.439646, \n",
            "Run: 1, Epoch: 477, Loss: 0.6496, Loss Cls: 0.6496, Train: 78.11%, Valid: 67.93%, Test: 64.42%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7896878195753291\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.767051, inference time:0:00:00.436372, \n",
            "Run: 1, Epoch: 478, Loss: 0.6498, Loss Cls: 0.6498, Train: 77.64%, Valid: 69.55%, Test: 70.09%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7901276651895185\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.732492, inference time:0:00:00.428305, \n",
            "Run: 1, Epoch: 479, Loss: 0.6502, Loss Cls: 0.6502, Train: 78.06%, Valid: 67.97%, Test: 64.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7898637578210048\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.768911, inference time:0:00:00.439274, \n",
            "Run: 1, Epoch: 480, Loss: 0.6467, Loss Cls: 0.6467, Train: 77.67%, Valid: 69.42%, Test: 70.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7920629858919519\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.768190, inference time:0:00:00.452609, \n",
            "Run: 1, Epoch: 481, Loss: 0.6475, Loss Cls: 0.6475, Train: 78.22%, Valid: 68.33%, Test: 64.90%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7907214567686742\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.934438, inference time:0:00:00.683048, \n",
            "Run: 1, Epoch: 482, Loss: 0.6433, Loss Cls: 0.6433, Train: 77.97%, Valid: 69.72%, Test: 70.17%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7924808392254319\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.100214, inference time:0:00:00.656372, \n",
            "Run: 1, Epoch: 483, Loss: 0.6458, Loss Cls: 0.6458, Train: 78.34%, Valid: 68.57%, Test: 65.53%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7907434490493837\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.065796, inference time:0:00:00.652428, \n",
            "Run: 1, Epoch: 484, Loss: 0.6433, Loss Cls: 0.6433, Train: 78.37%, Valid: 70.03%, Test: 70.22%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7934924841380675\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.023788, inference time:0:00:00.665560, \n",
            "Run: 1, Epoch: 485, Loss: 0.6455, Loss Cls: 0.6455, Train: 78.61%, Valid: 69.08%, Test: 66.24%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.79110632168109\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.016898, inference time:0:00:00.643407, \n",
            "Run: 1, Epoch: 486, Loss: 0.6437, Loss Cls: 0.6437, Train: 78.76%, Valid: 70.24%, Test: 70.16%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7941082679979328\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.045318, inference time:0:00:00.626541, \n",
            "Run: 1, Epoch: 487, Loss: 0.6442, Loss Cls: 0.6442, Train: 78.76%, Valid: 69.55%, Test: 67.11%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7920190013305329\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.038624, inference time:0:00:00.445482, \n",
            "Run: 1, Epoch: 488, Loss: 0.6428, Loss Cls: 0.6428, Train: 79.08%, Valid: 70.41%, Test: 70.06%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7940312950154496\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.723540, inference time:0:00:00.445392, \n",
            "Run: 1, Epoch: 489, Loss: 0.6426, Loss Cls: 0.6426, Train: 78.84%, Valid: 69.73%, Test: 67.86%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7925908006289792\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.724509, inference time:0:00:00.431540, \n",
            "Run: 1, Epoch: 490, Loss: 0.6422, Loss Cls: 0.6422, Train: 79.11%, Valid: 70.41%, Test: 69.80%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7940752795768685\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.734674, inference time:0:00:00.442324, \n",
            "Run: 1, Epoch: 491, Loss: 0.6418, Loss Cls: 0.6418, Train: 78.87%, Valid: 69.88%, Test: 68.39%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7929206848396213\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.726326, inference time:0:00:00.435578, \n",
            "Run: 1, Epoch: 492, Loss: 0.6419, Loss Cls: 0.6419, Train: 79.11%, Valid: 70.44%, Test: 69.49%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7939873104540306\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.730652, inference time:0:00:00.441613, \n",
            "Run: 1, Epoch: 493, Loss: 0.6415, Loss Cls: 0.6415, Train: 79.06%, Valid: 70.04%, Test: 68.88%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7926677736114623\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:00.758479, inference time:0:00:00.451226, \n",
            "Run: 1, Epoch: 494, Loss: 0.6409, Loss Cls: 0.6409, Train: 79.12%, Valid: 70.52%, Test: 69.31%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7934924841380675\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.725084, inference time:0:00:00.439416, \n",
            "Run: 1, Epoch: 495, Loss: 0.6410, Loss Cls: 0.6410, Train: 79.24%, Valid: 70.15%, Test: 69.23%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7930746308045876\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:00.734344, inference time:0:00:00.438831, \n",
            "Run: 1, Epoch: 496, Loss: 0.6388, Loss Cls: 0.6388, Train: 79.05%, Valid: 70.53%, Test: 69.19%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7943171946646727\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.88, avg inference:0.53, Epoch train time:0:00:01.015118, inference time:0:00:00.682253, \n",
            "Run: 1, Epoch: 497, Loss: 0.6397, Loss Cls: 0.6397, Train: 79.27%, Valid: 70.16%, Test: 69.14%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7923708778218845\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.118496, inference time:0:00:00.666321, \n",
            "Run: 1, Epoch: 498, Loss: 0.6386, Loss Cls: 0.6386, Train: 79.05%, Valid: 70.59%, Test: 69.04%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7937453953662265\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.038243, inference time:0:00:00.660156, \n",
            "Run: 1, Epoch: 499, Loss: 0.6417, Loss Cls: 0.6417, Train: 79.13%, Valid: 69.91%, Test: 68.68%\n",
            "num_B_prime:0, new edges:169343\n",
            "Batch 0.0, train acc:0.7910403448389616\n",
            "num_B_prime:0, new edges:169343\n",
            "avg train:0.89, avg inference:0.53, Epoch train time:0:00:01.070091, inference time:0:00:00.837640, \n",
            "Run: 1, Epoch: 500, Loss: 0.6423, Loss Cls: 0.6423, Train: 78.94%, Valid: 70.57%, Test: 69.12%\n",
            "Run 01:\n",
            "Highest Train: 79.27\n",
            "Highest Valid: 71.20\n",
            "  Final Train: 75.30\n",
            "   Final Test: 70.63\n",
            "All runs:\n",
            "Highest Train: 79.27 ± nan\n",
            "Highest Valid: 71.20 ± nan\n",
            "  Final Train: 75.30 ± nan\n",
            "   Final Test: 70.63 ± nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd VQ-GNN/vq_gnn_v2 && python main_node.py --num-D 4 --conv-type GAT --dataset arxiv \\\n",
        " --num-parts 20 --batch-size 60000 --test-batch-size 60000 --lr 1e-3 --sampler-type cluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abFDDrxFpKPV",
        "outputId": "0bba4252-4fd5-493d-fc11-1506ebd755a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.6.\n",
            "Namespace(EMA=True, act='leaky_gelu', alpha_dropout_flag=False, batch_size=60000, bn_flag=True, ce_only=False, clip=None, cluster='vq', commitment_cost=0.0, cont_sliding_window=1, conv_type='GAT', data_root='/cmlscratch/kong/datasets', dataset='arxiv', device=0, dropbranch=0.0, dropout=0, epochs=500, exp=False, exp_name='test', exp_tag='exp', grad_scale=[1, 1], hidden_channels=128, kmeans_init=False, kmeans_iter=100, ln_para=False, log_steps=1, lr=0.001, momentum=0.1, no_second_fc=True, num_D=4, num_M=256, num_branch=0, num_layers=3, num_parts=20, num_workers=0, recovery_flag=True, run_idx=None, runs=1, sampler_type='cluster', sche=False, skip=False, split=True, test_batch_size=60000, transformer_flag=False, use_gcn=False, walk_length=5, warm_up=True, warm_up_epochs=0, weight_ahead=False)\n",
            "Computing METIS partitioning with 20 parts... Done! [0.94s]\n",
            "Permuting data... Done! [1.00s]\n",
            "inter over intra:  0.31315153811479807\n",
            "1\n",
            "/content/VQ-GNN/vq_gnn_v2/dataloader.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  idx = torch.tensor(idx)\n",
            "num_B_prime:0, new edges:0\n",
            "2943.843328\n",
            "2\n",
            "num_B_prime:0, new edges:0\n",
            "3031.880704\n",
            "3\n",
            "num_B_prime:0, new edges:0\n",
            "3117.927936\n",
            "init done\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.013140387723908908\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.36, avg inference:0.75, Epoch train time:0:00:01.360201, inference time:0:00:00.752313, \n",
            "Run: 1, Epoch: 1, Loss: 3.8422, Loss Cls: 3.8422, Train: 20.13%, Valid: 26.25%, Test: 23.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.4768366303427497\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.16, avg inference:0.63, Epoch train time:0:00:00.958273, inference time:0:00:00.502181, \n",
            "Run: 1, Epoch: 2, Loss: 2.6109, Loss Cls: 2.6109, Train: 26.94%, Valid: 28.88%, Test: 25.90%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.5476517742272462\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.59, Epoch train time:0:00:00.986798, inference time:0:00:00.503888, \n",
            "Run: 1, Epoch: 3, Loss: 2.1797, Loss Cls: 2.1797, Train: 26.89%, Valid: 29.22%, Test: 26.19%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.5684344794976963\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.08, avg inference:0.56, Epoch train time:0:00:00.995167, inference time:0:00:00.500577, \n",
            "Run: 1, Epoch: 4, Loss: 1.9600, Loss Cls: 1.9600, Train: 29.94%, Valid: 30.54%, Test: 27.36%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.5959908072266634\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.06, avg inference:0.55, Epoch train time:0:00:00.978204, inference time:0:00:00.498689, \n",
            "Run: 1, Epoch: 5, Loss: 1.8269, Loss Cls: 1.8269, Train: 31.85%, Valid: 32.26%, Test: 28.75%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6014998735443859\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.04, avg inference:0.54, Epoch train time:0:00:00.955848, inference time:0:00:00.493359, \n",
            "Run: 1, Epoch: 6, Loss: 1.7083, Loss Cls: 1.7083, Train: 33.66%, Valid: 33.23%, Test: 30.18%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6109895426705226\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.03, avg inference:0.53, Epoch train time:0:00:01.000834, inference time:0:00:00.491582, \n",
            "Run: 1, Epoch: 7, Loss: 1.6356, Loss Cls: 1.6356, Train: 36.35%, Valid: 35.15%, Test: 31.69%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6170594121463366\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.03, avg inference:0.54, Epoch train time:0:00:00.992853, inference time:0:00:00.616366, \n",
            "Run: 1, Epoch: 8, Loss: 1.5886, Loss Cls: 1.5886, Train: 38.89%, Valid: 36.86%, Test: 33.71%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6325639700465137\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.06, avg inference:0.57, Epoch train time:0:00:01.356449, inference time:0:00:00.746197, \n",
            "Run: 1, Epoch: 9, Loss: 1.5115, Loss Cls: 1.5115, Train: 40.63%, Valid: 38.46%, Test: 35.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6365225805742184\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.09, avg inference:0.58, Epoch train time:0:00:01.274956, inference time:0:00:00.725118, \n",
            "Run: 1, Epoch: 10, Loss: 1.4645, Loss Cls: 1.4645, Train: 41.77%, Valid: 39.73%, Test: 37.07%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6434061644362828\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.60, Epoch train time:0:00:01.248724, inference time:0:00:00.734327, \n",
            "Run: 1, Epoch: 11, Loss: 1.4258, Loss Cls: 1.4258, Train: 43.66%, Valid: 42.18%, Test: 40.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6454294542615542\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.326897, inference time:0:00:00.744925, \n",
            "Run: 1, Epoch: 12, Loss: 1.3952, Loss Cls: 1.3952, Train: 43.40%, Valid: 42.35%, Test: 40.42%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6502787521579926\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.62, Epoch train time:0:00:01.262179, inference time:0:00:00.743535, \n",
            "Run: 1, Epoch: 13, Loss: 1.3698, Loss Cls: 1.3698, Train: 45.08%, Valid: 45.70%, Test: 45.73%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6495090223331611\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.085163, inference time:0:00:00.515418, \n",
            "Run: 1, Epoch: 14, Loss: 1.3497, Loss Cls: 1.3497, Train: 44.98%, Valid: 46.21%, Test: 46.44%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6520601268954597\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.005069, inference time:0:00:00.507657, \n",
            "Run: 1, Epoch: 15, Loss: 1.3350, Loss Cls: 1.3350, Train: 45.32%, Valid: 47.69%, Test: 49.49%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.652543957071068\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.953129, inference time:0:00:00.508127, \n",
            "Run: 1, Epoch: 16, Loss: 1.3160, Loss Cls: 1.3160, Train: 45.78%, Valid: 48.09%, Test: 50.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6560737181249382\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.59, Epoch train time:0:00:00.944793, inference time:0:00:00.519658, \n",
            "Run: 1, Epoch: 17, Loss: 1.3007, Loss Cls: 1.3007, Train: 45.18%, Valid: 47.89%, Test: 50.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6598563904069672\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.09, avg inference:0.59, Epoch train time:0:00:00.936036, inference time:0:00:00.518473, \n",
            "Run: 1, Epoch: 18, Loss: 1.2804, Loss Cls: 1.2804, Train: 45.63%, Valid: 46.91%, Test: 49.33%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6603072321615113\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.08, avg inference:0.59, Epoch train time:0:00:00.977362, inference time:0:00:00.517964, \n",
            "Run: 1, Epoch: 19, Loss: 1.2656, Loss Cls: 1.2656, Train: 45.11%, Valid: 47.30%, Test: 49.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.665684344794977\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.08, avg inference:0.58, Epoch train time:0:00:00.978791, inference time:0:00:00.510714, \n",
            "Run: 1, Epoch: 20, Loss: 1.2526, Loss Cls: 1.2526, Train: 45.35%, Valid: 45.38%, Test: 48.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.664518753917375\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.09, avg inference:0.59, Epoch train time:0:00:01.255473, inference time:0:00:00.761217, \n",
            "Run: 1, Epoch: 21, Loss: 1.2385, Loss Cls: 1.2385, Train: 45.06%, Valid: 46.36%, Test: 49.03%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6693350633927492\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.60, Epoch train time:0:00:01.377642, inference time:0:00:00.717082, \n",
            "Run: 1, Epoch: 22, Loss: 1.2286, Loss Cls: 1.2286, Train: 45.05%, Valid: 44.35%, Test: 47.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6687192795328839\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:01.261849, inference time:0:00:00.733854, \n",
            "Run: 1, Epoch: 23, Loss: 1.2133, Loss Cls: 1.2133, Train: 45.61%, Valid: 45.60%, Test: 48.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.674371295675218\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.281678, inference time:0:00:00.713856, \n",
            "Run: 1, Epoch: 24, Loss: 1.2030, Loss Cls: 1.2030, Train: 45.02%, Valid: 43.51%, Test: 46.61%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6735245928679033\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.320943, inference time:0:00:00.738065, \n",
            "Run: 1, Epoch: 25, Loss: 1.1901, Loss Cls: 1.1901, Train: 46.63%, Valid: 45.53%, Test: 48.01%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6793305549752037\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.219249, inference time:0:00:00.510754, \n",
            "Run: 1, Epoch: 26, Loss: 1.1811, Loss Cls: 1.1811, Train: 44.93%, Valid: 42.65%, Test: 45.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6784178753257607\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.949398, inference time:0:00:00.514730, \n",
            "Run: 1, Epoch: 27, Loss: 1.1709, Loss Cls: 1.1709, Train: 47.97%, Valid: 46.31%, Test: 48.67%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6823874819938202\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.931793, inference time:0:00:00.507024, \n",
            "Run: 1, Epoch: 28, Loss: 1.1627, Loss Cls: 1.1627, Train: 45.33%, Valid: 42.05%, Test: 45.04%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6818376749760834\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.974359, inference time:0:00:00.515588, \n",
            "Run: 1, Epoch: 29, Loss: 1.1536, Loss Cls: 1.1536, Train: 49.50%, Valid: 47.32%, Test: 49.53%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6854993897142103\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.60, Epoch train time:0:00:00.984400, inference time:0:00:00.490244, \n",
            "Run: 1, Epoch: 30, Loss: 1.1462, Loss Cls: 1.1462, Train: 46.85%, Valid: 43.23%, Test: 46.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6844987409419294\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.59, Epoch train time:0:00:00.994711, inference time:0:00:00.506883, \n",
            "Run: 1, Epoch: 31, Loss: 1.1386, Loss Cls: 1.1386, Train: 51.70%, Valid: 49.75%, Test: 51.75%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6872917605920322\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.59, Epoch train time:0:00:00.979137, inference time:0:00:00.486050, \n",
            "Run: 1, Epoch: 32, Loss: 1.1323, Loss Cls: 1.1323, Train: 48.46%, Valid: 44.02%, Test: 46.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6868299226971333\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.10, avg inference:0.59, Epoch train time:0:00:01.346216, inference time:0:00:00.715813, \n",
            "Run: 1, Epoch: 33, Loss: 1.1267, Loss Cls: 1.1267, Train: 53.97%, Valid: 52.39%, Test: 53.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6865880076093291\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:01.276861, inference time:0:00:00.729895, \n",
            "Run: 1, Epoch: 34, Loss: 1.1236, Loss Cls: 1.1236, Train: 49.72%, Valid: 44.28%, Test: 47.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6871048262060017\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.371051, inference time:0:00:00.700428, \n",
            "Run: 1, Epoch: 35, Loss: 1.1235, Loss Cls: 1.1235, Train: 56.18%, Valid: 55.01%, Test: 56.32%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6818926556778571\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.60, Epoch train time:0:00:01.424352, inference time:0:00:00.717961, \n",
            "Run: 1, Epoch: 36, Loss: 1.1230, Loss Cls: 1.1230, Train: 51.81%, Valid: 46.57%, Test: 49.72%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6856423395388219\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.387535, inference time:0:00:00.709946, \n",
            "Run: 1, Epoch: 37, Loss: 1.1230, Loss Cls: 1.1230, Train: 57.59%, Valid: 56.29%, Test: 57.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6841688567312874\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.60, Epoch train time:0:00:01.171386, inference time:0:00:00.509801, \n",
            "Run: 1, Epoch: 38, Loss: 1.1110, Loss Cls: 1.1110, Train: 55.67%, Valid: 51.77%, Test: 54.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6904366567334865\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.60, Epoch train time:0:00:00.962741, inference time:0:00:00.514497, \n",
            "Run: 1, Epoch: 39, Loss: 1.1024, Loss Cls: 1.1024, Train: 59.14%, Valid: 57.88%, Test: 59.05%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6903156991895845\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.943746, inference time:0:00:00.520771, \n",
            "Run: 1, Epoch: 40, Loss: 1.0928, Loss Cls: 1.0928, Train: 59.48%, Valid: 57.47%, Test: 59.57%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6941313598926777\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.966404, inference time:0:00:00.514646, \n",
            "Run: 1, Epoch: 41, Loss: 1.0853, Loss Cls: 1.0853, Train: 61.13%, Valid: 60.06%, Test: 61.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6933396377871367\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.949935, inference time:0:00:00.513865, \n",
            "Run: 1, Epoch: 42, Loss: 1.0797, Loss Cls: 1.0797, Train: 62.19%, Valid: 61.16%, Test: 62.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.697023344805973\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.59, Epoch train time:0:00:00.966818, inference time:0:00:00.510847, \n",
            "Run: 1, Epoch: 43, Loss: 1.0742, Loss Cls: 1.0742, Train: 62.91%, Valid: 62.09%, Test: 63.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.695197985507087\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.59, Epoch train time:0:00:00.968617, inference time:0:00:00.514558, \n",
            "Run: 1, Epoch: 44, Loss: 1.0704, Loss Cls: 1.0704, Train: 64.09%, Valid: 63.70%, Test: 64.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6981999318239298\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:01.281332, inference time:0:00:00.759656, \n",
            "Run: 1, Epoch: 45, Loss: 1.0660, Loss Cls: 1.0660, Train: 64.36%, Valid: 63.62%, Test: 64.58%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.69673744515675\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.304721, inference time:0:00:00.733559, \n",
            "Run: 1, Epoch: 46, Loss: 1.0632, Loss Cls: 1.0632, Train: 65.75%, Valid: 65.44%, Test: 66.30%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6984418469117339\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.287536, inference time:0:00:00.712462, \n",
            "Run: 1, Epoch: 47, Loss: 1.0594, Loss Cls: 1.0594, Train: 65.52%, Valid: 64.61%, Test: 65.42%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6967044567356858\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.267459, inference time:0:00:00.732746, \n",
            "Run: 1, Epoch: 48, Loss: 1.0574, Loss Cls: 1.0574, Train: 66.92%, Valid: 66.99%, Test: 67.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6990136462101803\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.303964, inference time:0:00:00.730921, \n",
            "Run: 1, Epoch: 49, Loss: 1.0545, Loss Cls: 1.0545, Train: 66.46%, Valid: 65.41%, Test: 66.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6962096304197227\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.60, Epoch train time:0:00:01.216564, inference time:0:00:00.518091, \n",
            "Run: 1, Epoch: 50, Loss: 1.0535, Loss Cls: 1.0535, Train: 67.53%, Valid: 67.70%, Test: 67.46%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6992445651576297\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.60, Epoch train time:0:00:00.973088, inference time:0:00:00.529772, \n",
            "Run: 1, Epoch: 51, Loss: 1.0510, Loss Cls: 1.0510, Train: 67.18%, Valid: 65.98%, Test: 66.77%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6954399005948912\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.958914, inference time:0:00:00.520588, \n",
            "Run: 1, Epoch: 52, Loss: 1.0512, Loss Cls: 1.0512, Train: 67.84%, Valid: 67.69%, Test: 66.98%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6991675921751466\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.967403, inference time:0:00:00.534811, \n",
            "Run: 1, Epoch: 53, Loss: 1.0491, Loss Cls: 1.0491, Train: 67.75%, Valid: 66.11%, Test: 67.00%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6959567191915638\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.948414, inference time:0:00:00.526515, \n",
            "Run: 1, Epoch: 54, Loss: 1.0473, Loss Cls: 1.0473, Train: 68.12%, Valid: 67.53%, Test: 66.58%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6989916539294707\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.963267, inference time:0:00:00.520483, \n",
            "Run: 1, Epoch: 55, Loss: 1.0439, Loss Cls: 1.0439, Train: 68.51%, Valid: 67.16%, Test: 67.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6983648739292508\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.977080, inference time:0:00:00.535739, \n",
            "Run: 1, Epoch: 56, Loss: 1.0392, Loss Cls: 1.0392, Train: 68.33%, Valid: 67.80%, Test: 67.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.6994205034033054\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.313164, inference time:0:00:00.763489, \n",
            "Run: 1, Epoch: 57, Loss: 1.0370, Loss Cls: 1.0370, Train: 69.36%, Valid: 68.28%, Test: 68.18%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7011359012986442\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.290508, inference time:0:00:00.727055, \n",
            "Run: 1, Epoch: 58, Loss: 1.0337, Loss Cls: 1.0337, Train: 68.40%, Valid: 68.40%, Test: 67.85%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7003221869123938\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.231554, inference time:0:00:00.737405, \n",
            "Run: 1, Epoch: 59, Loss: 1.0323, Loss Cls: 1.0323, Train: 69.82%, Valid: 68.93%, Test: 68.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7028293069132734\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.270417, inference time:0:00:00.731026, \n",
            "Run: 1, Epoch: 60, Loss: 1.0301, Loss Cls: 1.0301, Train: 68.49%, Valid: 68.68%, Test: 68.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.701058928316161\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.234074, inference time:0:00:00.721135, \n",
            "Run: 1, Epoch: 61, Loss: 1.0268, Loss Cls: 1.0268, Train: 70.21%, Valid: 69.07%, Test: 67.98%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7057542802476331\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.285640, inference time:0:00:00.515156, \n",
            "Run: 1, Epoch: 62, Loss: 1.0222, Loss Cls: 1.0222, Train: 69.05%, Valid: 68.99%, Test: 68.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7042588051593891\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.60, Epoch train time:0:00:00.958365, inference time:0:00:00.515671, \n",
            "Run: 1, Epoch: 63, Loss: 1.0169, Loss Cls: 1.0169, Train: 70.38%, Valid: 68.96%, Test: 67.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.708250404108158\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.926906, inference time:0:00:00.514472, \n",
            "Run: 1, Epoch: 64, Loss: 1.0123, Loss Cls: 1.0123, Train: 69.70%, Valid: 69.53%, Test: 69.32%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7069968441077182\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.962116, inference time:0:00:00.519129, \n",
            "Run: 1, Epoch: 65, Loss: 1.0083, Loss Cls: 1.0083, Train: 70.51%, Valid: 68.87%, Test: 67.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7095919332314358\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:00.950284, inference time:0:00:00.516290, \n",
            "Run: 1, Epoch: 66, Loss: 1.0054, Loss Cls: 1.0054, Train: 70.11%, Valid: 69.84%, Test: 69.55%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7083163809502865\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.944926, inference time:0:00:00.520278, \n",
            "Run: 1, Epoch: 67, Loss: 1.0027, Loss Cls: 1.0027, Train: 70.50%, Valid: 68.75%, Test: 67.21%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7100207827052705\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.60, Epoch train time:0:00:00.956132, inference time:0:00:00.514237, \n",
            "Run: 1, Epoch: 68, Loss: 1.0012, Loss Cls: 1.0012, Train: 70.42%, Valid: 70.08%, Test: 69.68%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7093280258629221\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.324749, inference time:0:00:00.761549, \n",
            "Run: 1, Epoch: 69, Loss: 0.9991, Loss Cls: 0.9991, Train: 70.42%, Valid: 68.45%, Test: 66.78%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7095479486700168\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.60, Epoch train time:0:00:01.330676, inference time:0:00:00.806743, \n",
            "Run: 1, Epoch: 70, Loss: 0.9988, Loss Cls: 0.9988, Train: 70.54%, Valid: 70.13%, Test: 69.79%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7095369525296621\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.317108, inference time:0:00:00.788499, \n",
            "Run: 1, Epoch: 71, Loss: 0.9973, Loss Cls: 0.9973, Train: 70.32%, Valid: 68.35%, Test: 66.51%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7088991763890874\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.329747, inference time:0:00:00.785662, \n",
            "Run: 1, Epoch: 72, Loss: 0.9983, Loss Cls: 0.9983, Train: 70.54%, Valid: 70.15%, Test: 69.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7092290605997295\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.300982, inference time:0:00:00.782396, \n",
            "Run: 1, Epoch: 73, Loss: 0.9964, Loss Cls: 0.9964, Train: 70.35%, Valid: 68.57%, Test: 66.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7080964581431918\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.350502, inference time:0:00:00.742757, \n",
            "Run: 1, Epoch: 74, Loss: 0.9980, Loss Cls: 0.9980, Train: 70.56%, Valid: 70.20%, Test: 69.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7094929679682431\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.298665, inference time:0:00:00.749779, \n",
            "Run: 1, Epoch: 75, Loss: 0.9949, Loss Cls: 0.9949, Train: 70.56%, Valid: 69.05%, Test: 67.55%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7083603655117053\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:00.963519, inference time:0:00:00.514245, \n",
            "Run: 1, Epoch: 76, Loss: 0.9945, Loss Cls: 0.9945, Train: 70.73%, Valid: 70.29%, Test: 69.68%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7098778328806589\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:00.919175, inference time:0:00:00.516360, \n",
            "Run: 1, Epoch: 77, Loss: 0.9907, Loss Cls: 0.9907, Train: 70.71%, Valid: 69.35%, Test: 67.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7101087518281083\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.916399, inference time:0:00:00.509939, \n",
            "Run: 1, Epoch: 78, Loss: 0.9889, Loss Cls: 0.9889, Train: 70.82%, Valid: 70.30%, Test: 69.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7097788676174662\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.925349, inference time:0:00:00.512110, \n",
            "Run: 1, Epoch: 79, Loss: 0.9860, Loss Cls: 0.9860, Train: 70.83%, Valid: 69.51%, Test: 67.92%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7107355318283283\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.946590, inference time:0:00:00.515496, \n",
            "Run: 1, Epoch: 80, Loss: 0.9865, Loss Cls: 0.9865, Train: 70.75%, Valid: 70.21%, Test: 69.32%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7086792535819927\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.963524, inference time:0:00:00.516037, \n",
            "Run: 1, Epoch: 81, Loss: 0.9847, Loss Cls: 0.9847, Train: 70.88%, Valid: 69.42%, Test: 67.92%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7102077170913009\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.977179, inference time:0:00:00.525817, \n",
            "Run: 1, Epoch: 82, Loss: 0.9871, Loss Cls: 0.9871, Train: 70.82%, Valid: 69.99%, Test: 69.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7091740798979558\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.380547, inference time:0:00:00.760076, \n",
            "Run: 1, Epoch: 83, Loss: 0.9815, Loss Cls: 0.9815, Train: 71.00%, Valid: 69.59%, Test: 68.17%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7119451072673492\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.285939, inference time:0:00:00.734651, \n",
            "Run: 1, Epoch: 84, Loss: 0.9813, Loss Cls: 0.9813, Train: 70.89%, Valid: 69.74%, Test: 68.67%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7107795163897472\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.318730, inference time:0:00:00.731655, \n",
            "Run: 1, Epoch: 85, Loss: 0.9774, Loss Cls: 0.9774, Train: 71.05%, Valid: 69.81%, Test: 68.67%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7128467907764374\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.293812, inference time:0:00:00.737719, \n",
            "Run: 1, Epoch: 86, Loss: 0.9766, Loss Cls: 0.9766, Train: 70.72%, Valid: 69.31%, Test: 67.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.712242003056927\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.300027, inference time:0:00:00.727854, \n",
            "Run: 1, Epoch: 87, Loss: 0.9756, Loss Cls: 0.9756, Train: 71.04%, Valid: 69.78%, Test: 69.11%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7136824974433974\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:01.215898, inference time:0:00:00.512206, \n",
            "Run: 1, Epoch: 88, Loss: 0.9736, Loss Cls: 0.9736, Train: 70.60%, Valid: 68.82%, Test: 66.73%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7129787444606943\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.13, avg inference:0.61, Epoch train time:0:00:00.948719, inference time:0:00:00.527950, \n",
            "Run: 1, Epoch: 89, Loss: 0.9730, Loss Cls: 0.9730, Train: 70.94%, Valid: 69.70%, Test: 69.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7137704665662352\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.929132, inference time:0:00:00.515938, \n",
            "Run: 1, Epoch: 90, Loss: 0.9701, Loss Cls: 0.9701, Train: 70.64%, Valid: 68.52%, Test: 66.04%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7141993160400699\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.980116, inference time:0:00:00.532781, \n",
            "Run: 1, Epoch: 91, Loss: 0.9697, Loss Cls: 0.9697, Train: 70.75%, Valid: 69.41%, Test: 69.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7140783584961679\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.957116, inference time:0:00:00.511636, \n",
            "Run: 1, Epoch: 92, Loss: 0.9670, Loss Cls: 0.9670, Train: 70.80%, Valid: 68.66%, Test: 66.21%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7149800420052561\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.926091, inference time:0:00:00.542080, \n",
            "Run: 1, Epoch: 93, Loss: 0.9670, Loss Cls: 0.9670, Train: 70.79%, Valid: 69.71%, Test: 69.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7141113469172321\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.940232, inference time:0:00:00.508022, \n",
            "Run: 1, Epoch: 94, Loss: 0.9655, Loss Cls: 0.9655, Train: 70.99%, Valid: 68.93%, Test: 66.63%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7155628374440571\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.259529, inference time:0:00:00.735123, \n",
            "Run: 1, Epoch: 95, Loss: 0.9659, Loss Cls: 0.9659, Train: 70.83%, Valid: 69.89%, Test: 69.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.71336360937311\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.246166, inference time:0:00:00.732730, \n",
            "Run: 1, Epoch: 96, Loss: 0.9654, Loss Cls: 0.9654, Train: 71.03%, Valid: 69.27%, Test: 67.25%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7161016483214392\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.257980, inference time:0:00:00.719256, \n",
            "Run: 1, Epoch: 97, Loss: 0.9652, Loss Cls: 0.9652, Train: 70.94%, Valid: 70.23%, Test: 70.08%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7126268679693427\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.245080, inference time:0:00:00.738158, \n",
            "Run: 1, Epoch: 98, Loss: 0.9634, Loss Cls: 0.9634, Train: 71.34%, Valid: 69.73%, Test: 68.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7169593472691086\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.238776, inference time:0:00:00.729396, \n",
            "Run: 1, Epoch: 99, Loss: 0.9619, Loss Cls: 0.9619, Train: 71.16%, Valid: 70.54%, Test: 70.18%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7131216942853058\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.273835, inference time:0:00:00.517101, \n",
            "Run: 1, Epoch: 100, Loss: 0.9584, Loss Cls: 0.9584, Train: 71.61%, Valid: 70.25%, Test: 68.89%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7177620655150042\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.008036, inference time:0:00:00.516024, \n",
            "Run: 1, Epoch: 101, Loss: 0.9564, Loss Cls: 0.9564, Train: 71.45%, Valid: 70.67%, Test: 70.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7147711153385162\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.974847, inference time:0:00:00.536563, \n",
            "Run: 1, Epoch: 102, Loss: 0.9533, Loss Cls: 0.9533, Train: 71.66%, Valid: 70.56%, Test: 69.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7188066988487041\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.965956, inference time:0:00:00.524016, \n",
            "Run: 1, Epoch: 103, Loss: 0.9519, Loss Cls: 0.9519, Train: 71.63%, Valid: 70.88%, Test: 70.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7163765518303076\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.943725, inference time:0:00:00.516320, \n",
            "Run: 1, Epoch: 104, Loss: 0.9505, Loss Cls: 0.9505, Train: 71.69%, Valid: 70.55%, Test: 69.58%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7197413707788566\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.975945, inference time:0:00:00.515735, \n",
            "Run: 1, Epoch: 105, Loss: 0.9506, Loss Cls: 0.9506, Train: 71.56%, Valid: 70.91%, Test: 69.81%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7158597332336349\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.951303, inference time:0:00:00.515059, \n",
            "Run: 1, Epoch: 106, Loss: 0.9507, Loss Cls: 0.9507, Train: 71.68%, Valid: 70.33%, Test: 69.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7189056641118967\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.085820, inference time:0:00:00.729538, \n",
            "Run: 1, Epoch: 107, Loss: 0.9520, Loss Cls: 0.9520, Train: 71.40%, Valid: 70.89%, Test: 69.74%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7160136791986013\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.399075, inference time:0:00:00.720364, \n",
            "Run: 1, Epoch: 108, Loss: 0.9516, Loss Cls: 0.9516, Train: 71.66%, Valid: 70.27%, Test: 69.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7190046293750894\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.262322, inference time:0:00:00.733426, \n",
            "Run: 1, Epoch: 109, Loss: 0.9515, Loss Cls: 0.9515, Train: 71.38%, Valid: 70.95%, Test: 70.00%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7169593472691086\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.305795, inference time:0:00:00.733430, \n",
            "Run: 1, Epoch: 110, Loss: 0.9486, Loss Cls: 0.9486, Train: 71.80%, Valid: 70.41%, Test: 69.45%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7200052781473703\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.320732, inference time:0:00:00.734247, \n",
            "Run: 1, Epoch: 111, Loss: 0.9460, Loss Cls: 0.9460, Train: 71.60%, Valid: 71.07%, Test: 70.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.718432830076643\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.270645, inference time:0:00:00.518814, \n",
            "Run: 1, Epoch: 112, Loss: 0.9430, Loss Cls: 0.9430, Train: 71.95%, Valid: 70.61%, Test: 69.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7210279192003607\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.968744, inference time:0:00:00.509524, \n",
            "Run: 1, Epoch: 113, Loss: 0.9403, Loss Cls: 0.9403, Train: 71.71%, Valid: 71.06%, Test: 70.51%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7198733244631135\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.942094, inference time:0:00:00.521258, \n",
            "Run: 1, Epoch: 114, Loss: 0.9383, Loss Cls: 0.9383, Train: 72.02%, Valid: 70.61%, Test: 69.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7217206760427091\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.960899, inference time:0:00:00.514798, \n",
            "Run: 1, Epoch: 115, Loss: 0.9365, Loss Cls: 0.9365, Train: 71.74%, Valid: 71.03%, Test: 70.65%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7207090311300733\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.974360, inference time:0:00:00.523646, \n",
            "Run: 1, Epoch: 116, Loss: 0.9356, Loss Cls: 0.9356, Train: 71.98%, Valid: 70.33%, Test: 69.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7217866528848375\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.919108, inference time:0:00:00.513454, \n",
            "Run: 1, Epoch: 117, Loss: 0.9350, Loss Cls: 0.9350, Train: 71.77%, Valid: 70.91%, Test: 70.65%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7208299886739754\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.967374, inference time:0:00:00.502729, \n",
            "Run: 1, Epoch: 118, Loss: 0.9354, Loss Cls: 0.9354, Train: 71.79%, Valid: 70.25%, Test: 69.02%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7200822511298535\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.985615, inference time:0:00:00.757077, \n",
            "Run: 1, Epoch: 119, Loss: 0.9358, Loss Cls: 0.9358, Train: 71.67%, Valid: 70.84%, Test: 70.57%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7196973862174377\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.319802, inference time:0:00:00.767969, \n",
            "Run: 1, Epoch: 120, Loss: 0.9380, Loss Cls: 0.9380, Train: 71.75%, Valid: 70.16%, Test: 69.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.719103594638282\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.234495, inference time:0:00:00.721851, \n",
            "Run: 1, Epoch: 121, Loss: 0.9384, Loss Cls: 0.9384, Train: 71.57%, Valid: 70.66%, Test: 70.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7184658184977073\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.335273, inference time:0:00:00.738089, \n",
            "Run: 1, Epoch: 122, Loss: 0.9411, Loss Cls: 0.9411, Train: 71.75%, Valid: 70.11%, Test: 69.07%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.718938652532961\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.282264, inference time:0:00:00.725112, \n",
            "Run: 1, Epoch: 123, Loss: 0.9391, Loss Cls: 0.9391, Train: 71.58%, Valid: 70.73%, Test: 70.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7186747451644473\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.245689, inference time:0:00:00.601505, \n",
            "Run: 1, Epoch: 124, Loss: 0.9385, Loss Cls: 0.9385, Train: 71.92%, Valid: 70.21%, Test: 69.45%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7203021739369482\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.949915, inference time:0:00:00.485312, \n",
            "Run: 1, Epoch: 125, Loss: 0.9355, Loss Cls: 0.9355, Train: 71.80%, Valid: 70.97%, Test: 70.37%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.720720027270428\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.944622, inference time:0:00:00.485869, \n",
            "Run: 1, Epoch: 126, Loss: 0.9332, Loss Cls: 0.9332, Train: 72.01%, Valid: 70.28%, Test: 69.50%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7219515949901585\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.963674, inference time:0:00:00.515064, \n",
            "Run: 1, Epoch: 127, Loss: 0.9312, Loss Cls: 0.9312, Train: 72.03%, Valid: 71.05%, Test: 70.15%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7220285679726416\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.943786, inference time:0:00:00.509718, \n",
            "Run: 1, Epoch: 128, Loss: 0.9288, Loss Cls: 0.9288, Train: 72.05%, Valid: 70.54%, Test: 69.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7229522437624394\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.992647, inference time:0:00:00.512681, \n",
            "Run: 1, Epoch: 129, Loss: 0.9275, Loss Cls: 0.9275, Train: 72.16%, Valid: 71.04%, Test: 69.90%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7225563827096689\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.943940, inference time:0:00:00.508465, \n",
            "Run: 1, Epoch: 130, Loss: 0.9255, Loss Cls: 0.9255, Train: 72.07%, Valid: 70.57%, Test: 69.96%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7231171858677604\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.949093, inference time:0:00:00.728470, \n",
            "Run: 1, Epoch: 131, Loss: 0.9247, Loss Cls: 0.9247, Train: 72.25%, Valid: 71.03%, Test: 69.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7236120121837235\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.259086, inference time:0:00:00.722381, \n",
            "Run: 1, Epoch: 132, Loss: 0.9226, Loss Cls: 0.9226, Train: 72.16%, Valid: 70.72%, Test: 70.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7236669928854972\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.309080, inference time:0:00:00.728640, \n",
            "Run: 1, Epoch: 133, Loss: 0.9222, Loss Cls: 0.9222, Train: 72.25%, Valid: 71.12%, Test: 69.78%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7240958423593319\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.283121, inference time:0:00:00.713690, \n",
            "Run: 1, Epoch: 134, Loss: 0.9202, Loss Cls: 0.9202, Train: 72.11%, Valid: 70.70%, Test: 70.26%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7237549620083351\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.270216, inference time:0:00:00.685168, \n",
            "Run: 1, Epoch: 135, Loss: 0.9204, Loss Cls: 0.9204, Train: 72.20%, Valid: 71.06%, Test: 70.07%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7246456493770687\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.215279, inference time:0:00:00.733956, \n",
            "Run: 1, Epoch: 136, Loss: 0.9187, Loss Cls: 0.9187, Train: 72.11%, Valid: 70.70%, Test: 70.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7236230083240782\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.984198, inference time:0:00:00.514377, \n",
            "Run: 1, Epoch: 137, Loss: 0.9197, Loss Cls: 0.9197, Train: 72.08%, Valid: 70.88%, Test: 69.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.724172815341815\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.984942, inference time:0:00:00.516812, \n",
            "Run: 1, Epoch: 138, Loss: 0.9183, Loss Cls: 0.9183, Train: 72.13%, Valid: 70.64%, Test: 69.98%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7233371086748551\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.942545, inference time:0:00:00.517597, \n",
            "Run: 1, Epoch: 139, Loss: 0.9199, Loss Cls: 0.9199, Train: 71.92%, Valid: 70.52%, Test: 69.73%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7238759195522372\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.928558, inference time:0:00:00.509413, \n",
            "Run: 1, Epoch: 140, Loss: 0.9187, Loss Cls: 0.9187, Train: 72.09%, Valid: 70.18%, Test: 69.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7228312862185373\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.927004, inference time:0:00:00.513924, \n",
            "Run: 1, Epoch: 141, Loss: 0.9213, Loss Cls: 0.9213, Train: 71.65%, Valid: 69.81%, Test: 69.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7233700970959194\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.967121, inference time:0:00:00.504201, \n",
            "Run: 1, Epoch: 142, Loss: 0.9192, Loss Cls: 0.9192, Train: 72.00%, Valid: 69.97%, Test: 68.65%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7223914406043479\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.964726, inference time:0:00:00.584166, \n",
            "Run: 1, Epoch: 143, Loss: 0.9212, Loss Cls: 0.9212, Train: 71.52%, Valid: 69.32%, Test: 69.03%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7245576802542307\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.297681, inference time:0:00:00.755790, \n",
            "Run: 1, Epoch: 144, Loss: 0.9168, Loss Cls: 0.9168, Train: 72.11%, Valid: 70.05%, Test: 68.53%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7240298655172035\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.268812, inference time:0:00:00.735051, \n",
            "Run: 1, Epoch: 145, Loss: 0.9161, Loss Cls: 0.9161, Train: 71.79%, Valid: 69.76%, Test: 69.50%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7259212016582179\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.259411, inference time:0:00:00.737494, \n",
            "Run: 1, Epoch: 146, Loss: 0.9116, Loss Cls: 0.9116, Train: 72.21%, Valid: 70.16%, Test: 68.36%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7256572942897043\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.286924, inference time:0:00:00.733899, \n",
            "Run: 1, Epoch: 147, Loss: 0.9107, Loss Cls: 0.9107, Train: 71.92%, Valid: 70.04%, Test: 70.02%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7270977886761747\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.285283, inference time:0:00:00.723016, \n",
            "Run: 1, Epoch: 148, Loss: 0.9080, Loss Cls: 0.9080, Train: 72.31%, Valid: 70.17%, Test: 68.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7261301283249579\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.108673, inference time:0:00:00.511398, \n",
            "Run: 1, Epoch: 149, Loss: 0.9084, Loss Cls: 0.9084, Train: 71.77%, Valid: 69.80%, Test: 69.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7268228851673063\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.940393, inference time:0:00:00.500893, \n",
            "Run: 1, Epoch: 150, Loss: 0.9069, Loss Cls: 0.9069, Train: 72.22%, Valid: 69.87%, Test: 67.71%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7260201669214106\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.945913, inference time:0:00:00.529053, \n",
            "Run: 1, Epoch: 151, Loss: 0.9087, Loss Cls: 0.9087, Train: 71.49%, Valid: 69.31%, Test: 69.67%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7258552248160896\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.961406, inference time:0:00:00.505123, \n",
            "Run: 1, Epoch: 152, Loss: 0.9073, Loss Cls: 0.9073, Train: 71.99%, Valid: 69.52%, Test: 66.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7253494023597717\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.974660, inference time:0:00:00.524817, \n",
            "Run: 1, Epoch: 153, Loss: 0.9102, Loss Cls: 0.9102, Train: 71.27%, Valid: 69.01%, Test: 69.45%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.724799595342035\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.959100, inference time:0:00:00.508047, \n",
            "Run: 1, Epoch: 154, Loss: 0.9083, Loss Cls: 0.9083, Train: 71.95%, Valid: 69.43%, Test: 66.82%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7248545760438087\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.935124, inference time:0:00:00.524761, \n",
            "Run: 1, Epoch: 155, Loss: 0.9112, Loss Cls: 0.9112, Train: 71.28%, Valid: 69.28%, Test: 69.64%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7237439658679803\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.218732, inference time:0:00:00.761856, \n",
            "Run: 1, Epoch: 156, Loss: 0.9093, Loss Cls: 0.9093, Train: 72.02%, Valid: 69.73%, Test: 67.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7250525065701938\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.225126, inference time:0:00:00.707289, \n",
            "Run: 1, Epoch: 157, Loss: 0.9113, Loss Cls: 0.9113, Train: 71.68%, Valid: 70.02%, Test: 70.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7243157651664266\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.272746, inference time:0:00:00.723162, \n",
            "Run: 1, Epoch: 158, Loss: 0.9084, Loss Cls: 0.9084, Train: 72.35%, Valid: 70.52%, Test: 68.88%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7258332325353801\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.300113, inference time:0:00:00.728609, \n",
            "Run: 1, Epoch: 159, Loss: 0.9084, Loss Cls: 0.9084, Train: 72.10%, Valid: 70.65%, Test: 70.50%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7253164139387075\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.312038, inference time:0:00:00.715851, \n",
            "Run: 1, Epoch: 160, Loss: 0.9050, Loss Cls: 0.9050, Train: 72.64%, Valid: 71.03%, Test: 69.78%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7273177114832694\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.272464, inference time:0:00:00.505181, \n",
            "Run: 1, Epoch: 161, Loss: 0.9032, Loss Cls: 0.9032, Train: 72.43%, Valid: 71.02%, Test: 70.60%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7268228851673063\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.962529, inference time:0:00:00.512849, \n",
            "Run: 1, Epoch: 162, Loss: 0.9009, Loss Cls: 0.9009, Train: 72.75%, Valid: 71.27%, Test: 70.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7289231479750607\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.949519, inference time:0:00:00.516896, \n",
            "Run: 1, Epoch: 163, Loss: 0.8992, Loss Cls: 0.8992, Train: 72.56%, Valid: 71.07%, Test: 70.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7280654490273913\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.954831, inference time:0:00:00.458042, \n",
            "Run: 1, Epoch: 164, Loss: 0.8987, Loss Cls: 0.8987, Train: 72.75%, Valid: 71.18%, Test: 70.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7294729549927975\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.951065, inference time:0:00:00.500033, \n",
            "Run: 1, Epoch: 165, Loss: 0.8982, Loss Cls: 0.8982, Train: 72.55%, Valid: 70.85%, Test: 70.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7283843370976787\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.037305, inference time:0:00:00.499896, \n",
            "Run: 1, Epoch: 166, Loss: 0.8991, Loss Cls: 0.8991, Train: 72.64%, Valid: 71.10%, Test: 70.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7282743756941313\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.962982, inference time:0:00:00.502812, \n",
            "Run: 1, Epoch: 167, Loss: 0.8997, Loss Cls: 0.8997, Train: 72.47%, Valid: 70.62%, Test: 70.08%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7283843370976787\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.115871, inference time:0:00:00.765827, \n",
            "Run: 1, Epoch: 168, Loss: 0.9004, Loss Cls: 0.9004, Train: 72.49%, Valid: 70.91%, Test: 70.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7277025763956851\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.361833, inference time:0:00:00.784971, \n",
            "Run: 1, Epoch: 169, Loss: 0.9013, Loss Cls: 0.9013, Train: 72.57%, Valid: 70.50%, Test: 69.77%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7287252174486755\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.336719, inference time:0:00:00.762017, \n",
            "Run: 1, Epoch: 170, Loss: 0.9000, Loss Cls: 0.9000, Train: 72.47%, Valid: 70.81%, Test: 70.21%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7279115030624251\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.288124, inference time:0:00:00.748727, \n",
            "Run: 1, Epoch: 171, Loss: 0.8998, Loss Cls: 0.8998, Train: 72.67%, Valid: 70.54%, Test: 69.64%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7294509627120881\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.333525, inference time:0:00:00.760143, \n",
            "Run: 1, Epoch: 172, Loss: 0.8969, Loss Cls: 0.8969, Train: 72.38%, Valid: 70.63%, Test: 70.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7280104683256177\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.366600, inference time:0:00:00.773927, \n",
            "Run: 1, Epoch: 173, Loss: 0.8963, Loss Cls: 0.8963, Train: 72.84%, Valid: 70.63%, Test: 69.47%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7302756732386932\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.348530, inference time:0:00:00.750560, \n",
            "Run: 1, Epoch: 174, Loss: 0.8939, Loss Cls: 0.8939, Train: 72.26%, Valid: 70.36%, Test: 69.95%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7284393177994524\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.201352, inference time:0:00:00.508167, \n",
            "Run: 1, Epoch: 175, Loss: 0.8936, Loss Cls: 0.8936, Train: 72.84%, Valid: 70.63%, Test: 69.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7302756732386932\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.969677, inference time:0:00:00.516035, \n",
            "Run: 1, Epoch: 176, Loss: 0.8930, Loss Cls: 0.8930, Train: 71.89%, Valid: 69.67%, Test: 69.35%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7283403525362597\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.966163, inference time:0:00:00.500880, \n",
            "Run: 1, Epoch: 177, Loss: 0.8938, Loss Cls: 0.8938, Train: 72.75%, Valid: 70.44%, Test: 69.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7292640283260575\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.956106, inference time:0:00:00.493928, \n",
            "Run: 1, Epoch: 178, Loss: 0.8946, Loss Cls: 0.8946, Train: 71.67%, Valid: 69.35%, Test: 69.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7280214644659725\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.943243, inference time:0:00:00.486214, \n",
            "Run: 1, Epoch: 179, Loss: 0.8959, Loss Cls: 0.8959, Train: 72.69%, Valid: 70.51%, Test: 69.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7275596265710735\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.000562, inference time:0:00:00.511373, \n",
            "Run: 1, Epoch: 180, Loss: 0.8975, Loss Cls: 0.8975, Train: 71.71%, Valid: 69.36%, Test: 69.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7279005069220703\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.986067, inference time:0:00:00.752875, \n",
            "Run: 1, Epoch: 181, Loss: 0.8977, Loss Cls: 0.8977, Train: 72.74%, Valid: 70.70%, Test: 69.68%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7266359507812757\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.294566, inference time:0:00:00.697346, \n",
            "Run: 1, Epoch: 182, Loss: 0.8974, Loss Cls: 0.8974, Train: 72.12%, Valid: 70.04%, Test: 69.75%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7286042599047734\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.329580, inference time:0:00:00.694573, \n",
            "Run: 1, Epoch: 183, Loss: 0.8958, Loss Cls: 0.8958, Train: 72.78%, Valid: 70.91%, Test: 70.07%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7273836883253978\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.316827, inference time:0:00:00.703659, \n",
            "Run: 1, Epoch: 184, Loss: 0.8934, Loss Cls: 0.8934, Train: 72.47%, Valid: 70.69%, Test: 70.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7293629935892502\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.426350, inference time:0:00:00.728085, \n",
            "Run: 1, Epoch: 185, Loss: 0.8920, Loss Cls: 0.8920, Train: 72.81%, Valid: 70.86%, Test: 70.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7283953332380334\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.293607, inference time:0:00:00.528046, \n",
            "Run: 1, Epoch: 186, Loss: 0.8906, Loss Cls: 0.8906, Train: 72.73%, Valid: 71.00%, Test: 70.27%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7302976655194027\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.946417, inference time:0:00:00.511628, \n",
            "Run: 1, Epoch: 187, Loss: 0.8891, Loss Cls: 0.8891, Train: 72.84%, Valid: 70.76%, Test: 70.01%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7286042599047734\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.963534, inference time:0:00:00.514981, \n",
            "Run: 1, Epoch: 188, Loss: 0.8893, Loss Cls: 0.8893, Train: 72.88%, Valid: 71.16%, Test: 70.27%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7314632563970046\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.926368, inference time:0:00:00.507015, \n",
            "Run: 1, Epoch: 189, Loss: 0.8870, Loss Cls: 0.8870, Train: 72.92%, Valid: 70.70%, Test: 69.96%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7295499279752806\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.957018, inference time:0:00:00.511097, \n",
            "Run: 1, Epoch: 190, Loss: 0.8880, Loss Cls: 0.8880, Train: 73.09%, Valid: 71.26%, Test: 70.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7324199206078666\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.980227, inference time:0:00:00.518853, \n",
            "Run: 1, Epoch: 191, Loss: 0.8843, Loss Cls: 0.8843, Train: 72.96%, Valid: 70.85%, Test: 70.11%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7311443683267174\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.950382, inference time:0:00:00.513418, \n",
            "Run: 1, Epoch: 192, Loss: 0.8848, Loss Cls: 0.8848, Train: 73.25%, Valid: 71.27%, Test: 70.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7330467006080865\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.957552, inference time:0:00:00.740420, \n",
            "Run: 1, Epoch: 193, Loss: 0.8815, Loss Cls: 0.8815, Train: 72.99%, Valid: 70.89%, Test: 70.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7320350556954509\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.249852, inference time:0:00:00.729829, \n",
            "Run: 1, Epoch: 194, Loss: 0.8814, Loss Cls: 0.8814, Train: 73.30%, Valid: 71.14%, Test: 69.90%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7337614497311443\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.297805, inference time:0:00:00.724421, \n",
            "Run: 1, Epoch: 195, Loss: 0.8792, Loss Cls: 0.8792, Train: 73.03%, Valid: 71.02%, Test: 70.68%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.732485897449995\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.229580, inference time:0:00:00.722364, \n",
            "Run: 1, Epoch: 196, Loss: 0.8789, Loss Cls: 0.8789, Train: 73.31%, Valid: 71.07%, Test: 69.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7341683069242696\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.278542, inference time:0:00:00.733323, \n",
            "Run: 1, Epoch: 197, Loss: 0.8773, Loss Cls: 0.8773, Train: 72.94%, Valid: 71.02%, Test: 70.85%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7333765848187286\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.324279, inference time:0:00:00.710988, \n",
            "Run: 1, Epoch: 198, Loss: 0.8769, Loss Cls: 0.8769, Train: 73.27%, Valid: 70.93%, Test: 69.25%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7341023300821412\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.947353, inference time:0:00:00.506926, \n",
            "Run: 1, Epoch: 199, Loss: 0.8764, Loss Cls: 0.8764, Train: 72.83%, Valid: 71.06%, Test: 71.03%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7331456658712792\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.927369, inference time:0:00:00.513134, \n",
            "Run: 1, Epoch: 200, Loss: 0.8760, Loss Cls: 0.8760, Train: 73.23%, Valid: 70.74%, Test: 69.05%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7340913339417864\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.920979, inference time:0:00:00.506550, \n",
            "Run: 1, Epoch: 201, Loss: 0.8760, Loss Cls: 0.8760, Train: 72.81%, Valid: 71.07%, Test: 71.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7336624844679518\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.962780, inference time:0:00:00.511109, \n",
            "Run: 1, Epoch: 202, Loss: 0.8755, Loss Cls: 0.8755, Train: 73.15%, Valid: 70.59%, Test: 69.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7333875809590834\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.933953, inference time:0:00:00.512960, \n",
            "Run: 1, Epoch: 203, Loss: 0.8758, Loss Cls: 0.8758, Train: 72.85%, Valid: 71.17%, Test: 71.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7331456658712792\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.943965, inference time:0:00:00.523415, \n",
            "Run: 1, Epoch: 204, Loss: 0.8765, Loss Cls: 0.8765, Train: 73.13%, Valid: 70.58%, Test: 69.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.732485897449995\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.950270, inference time:0:00:00.676883, \n",
            "Run: 1, Epoch: 205, Loss: 0.8774, Loss Cls: 0.8774, Train: 72.86%, Valid: 71.13%, Test: 70.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7320130634147414\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.267197, inference time:0:00:00.754726, \n",
            "Run: 1, Epoch: 206, Loss: 0.8796, Loss Cls: 0.8796, Train: 73.10%, Valid: 70.50%, Test: 69.53%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7314522602566499\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.300304, inference time:0:00:00.744737, \n",
            "Run: 1, Epoch: 207, Loss: 0.8805, Loss Cls: 0.8805, Train: 72.94%, Valid: 71.02%, Test: 70.81%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7316172023619709\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.275507, inference time:0:00:00.740273, \n",
            "Run: 1, Epoch: 208, Loss: 0.8812, Loss Cls: 0.8812, Train: 73.16%, Valid: 70.48%, Test: 69.46%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7321230248182887\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.332958, inference time:0:00:00.701642, \n",
            "Run: 1, Epoch: 209, Loss: 0.8803, Loss Cls: 0.8803, Train: 73.01%, Valid: 71.17%, Test: 70.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7328377739413466\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.341839, inference time:0:00:00.731920, \n",
            "Run: 1, Epoch: 210, Loss: 0.8768, Loss Cls: 0.8768, Train: 73.38%, Valid: 70.84%, Test: 69.94%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7341793030646243\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.026064, inference time:0:00:00.498905, \n",
            "Run: 1, Epoch: 211, Loss: 0.8748, Loss Cls: 0.8748, Train: 73.19%, Valid: 71.34%, Test: 70.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7343112567488811\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.953523, inference time:0:00:00.524352, \n",
            "Run: 1, Epoch: 212, Loss: 0.8712, Loss Cls: 0.8712, Train: 73.48%, Valid: 71.08%, Test: 70.21%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7357627472757062\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.936033, inference time:0:00:00.517372, \n",
            "Run: 1, Epoch: 213, Loss: 0.8699, Loss Cls: 0.8699, Train: 73.33%, Valid: 71.54%, Test: 70.78%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.735026005871939\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.971501, inference time:0:00:00.529170, \n",
            "Run: 1, Epoch: 214, Loss: 0.8677, Loss Cls: 0.8677, Train: 73.56%, Valid: 71.23%, Test: 70.40%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7364115195566356\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.975522, inference time:0:00:00.525976, \n",
            "Run: 1, Epoch: 215, Loss: 0.8665, Loss Cls: 0.8665, Train: 73.45%, Valid: 71.53%, Test: 70.60%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7352789171000979\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.002760, inference time:0:00:00.523100, \n",
            "Run: 1, Epoch: 216, Loss: 0.8652, Loss Cls: 0.8652, Train: 73.59%, Valid: 71.33%, Test: 70.44%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7370822841182745\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.958961, inference time:0:00:00.607237, \n",
            "Run: 1, Epoch: 217, Loss: 0.8641, Loss Cls: 0.8641, Train: 73.49%, Valid: 71.51%, Test: 70.63%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7360706392056389\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.336302, inference time:0:00:00.724347, \n",
            "Run: 1, Epoch: 218, Loss: 0.8634, Loss Cls: 0.8634, Train: 73.62%, Valid: 71.38%, Test: 70.40%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7373022069253692\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.283222, inference time:0:00:00.728542, \n",
            "Run: 1, Epoch: 219, Loss: 0.8624, Loss Cls: 0.8624, Train: 73.34%, Valid: 71.20%, Test: 70.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.736477496398764\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.250363, inference time:0:00:00.748613, \n",
            "Run: 1, Epoch: 220, Loss: 0.8622, Loss Cls: 0.8622, Train: 73.64%, Valid: 71.15%, Test: 69.78%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7375771104342376\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.264521, inference time:0:00:00.738889, \n",
            "Run: 1, Epoch: 221, Loss: 0.8622, Loss Cls: 0.8622, Train: 72.85%, Valid: 70.33%, Test: 70.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7353119055211621\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.338695, inference time:0:00:00.733496, \n",
            "Run: 1, Epoch: 222, Loss: 0.8636, Loss Cls: 0.8636, Train: 73.18%, Valid: 69.98%, Test: 67.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7363345465741524\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.093382, inference time:0:00:00.515135, \n",
            "Run: 1, Epoch: 223, Loss: 0.8662, Loss Cls: 0.8662, Train: 71.82%, Valid: 68.51%, Test: 68.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7328927546431203\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.976820, inference time:0:00:00.509821, \n",
            "Run: 1, Epoch: 224, Loss: 0.8686, Loss Cls: 0.8686, Train: 72.40%, Valid: 67.93%, Test: 64.63%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7334865462222759\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.932400, inference time:0:00:00.509867, \n",
            "Run: 1, Epoch: 225, Loss: 0.8754, Loss Cls: 0.8754, Train: 71.00%, Valid: 67.07%, Test: 67.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7311553644670721\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.949926, inference time:0:00:00.503473, \n",
            "Run: 1, Epoch: 226, Loss: 0.8732, Loss Cls: 0.8732, Train: 72.37%, Valid: 67.96%, Test: 64.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7329257430641845\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.993271, inference time:0:00:00.493179, \n",
            "Run: 1, Epoch: 227, Loss: 0.8771, Loss Cls: 0.8771, Train: 71.50%, Valid: 68.25%, Test: 68.71%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7322549785025456\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.931705, inference time:0:00:00.502003, \n",
            "Run: 1, Epoch: 228, Loss: 0.8703, Loss Cls: 0.8703, Train: 72.97%, Valid: 69.68%, Test: 67.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7347950869244895\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.958211, inference time:0:00:00.496273, \n",
            "Run: 1, Epoch: 229, Loss: 0.8701, Loss Cls: 0.8701, Train: 72.30%, Valid: 70.07%, Test: 70.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.733651488327597\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.296570, inference time:0:00:00.775329, \n",
            "Run: 1, Epoch: 230, Loss: 0.8676, Loss Cls: 0.8676, Train: 73.27%, Valid: 70.70%, Test: 69.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7332006465730528\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.366801, inference time:0:00:00.754281, \n",
            "Run: 1, Epoch: 231, Loss: 0.8700, Loss Cls: 0.8700, Train: 72.59%, Valid: 71.07%, Test: 70.94%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7322109939411267\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.281464, inference time:0:00:00.752212, \n",
            "Run: 1, Epoch: 232, Loss: 0.8730, Loss Cls: 0.8730, Train: 73.20%, Valid: 70.59%, Test: 69.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7312873181513289\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.293438, inference time:0:00:00.764138, \n",
            "Run: 1, Epoch: 233, Loss: 0.8729, Loss Cls: 0.8729, Train: 72.97%, Valid: 71.29%, Test: 70.77%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7321890016604172\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.292971, inference time:0:00:00.748207, \n",
            "Run: 1, Epoch: 234, Loss: 0.8730, Loss Cls: 0.8730, Train: 73.29%, Valid: 70.45%, Test: 69.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7350370020122937\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.208512, inference time:0:00:00.529259, \n",
            "Run: 1, Epoch: 235, Loss: 0.8647, Loss Cls: 0.8647, Train: 73.52%, Valid: 71.44%, Test: 70.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7360926314863483\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.999839, inference time:0:00:00.500535, \n",
            "Run: 1, Epoch: 236, Loss: 0.8609, Loss Cls: 0.8609, Train: 73.46%, Valid: 70.65%, Test: 69.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7372692185043049\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.987186, inference time:0:00:00.536069, \n",
            "Run: 1, Epoch: 237, Loss: 0.8586, Loss Cls: 0.8586, Train: 73.67%, Valid: 71.42%, Test: 70.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7371482609604029\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.964091, inference time:0:00:00.522457, \n",
            "Run: 1, Epoch: 238, Loss: 0.8564, Loss Cls: 0.8564, Train: 73.44%, Valid: 70.56%, Test: 69.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7376540834167208\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.949843, inference time:0:00:00.515722, \n",
            "Run: 1, Epoch: 239, Loss: 0.8566, Loss Cls: 0.8566, Train: 73.72%, Valid: 71.31%, Test: 70.11%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7375881065745923\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.930741, inference time:0:00:00.532946, \n",
            "Run: 1, Epoch: 240, Loss: 0.8557, Loss Cls: 0.8557, Train: 73.48%, Valid: 70.68%, Test: 70.11%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.737808029381687\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.946915, inference time:0:00:00.515449, \n",
            "Run: 1, Epoch: 241, Loss: 0.8565, Loss Cls: 0.8565, Train: 73.65%, Valid: 71.36%, Test: 70.21%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7370712879779198\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.271824, inference time:0:00:00.732844, \n",
            "Run: 1, Epoch: 242, Loss: 0.8573, Loss Cls: 0.8573, Train: 73.39%, Valid: 70.82%, Test: 70.00%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7369943149954366\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.303344, inference time:0:00:00.715270, \n",
            "Run: 1, Epoch: 243, Loss: 0.8591, Loss Cls: 0.8591, Train: 73.48%, Valid: 71.08%, Test: 70.32%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7355868090300305\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.296809, inference time:0:00:00.725956, \n",
            "Run: 1, Epoch: 244, Loss: 0.8613, Loss Cls: 0.8613, Train: 73.29%, Valid: 70.79%, Test: 69.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7348830560473274\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.298672, inference time:0:00:00.728756, \n",
            "Run: 1, Epoch: 245, Loss: 0.8641, Loss Cls: 0.8641, Train: 73.34%, Valid: 70.88%, Test: 70.33%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.735026005871939\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.342072, inference time:0:00:00.722019, \n",
            "Run: 1, Epoch: 246, Loss: 0.8638, Loss Cls: 0.8638, Train: 73.37%, Valid: 70.77%, Test: 69.86%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7347840907841348\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.240557, inference time:0:00:00.516267, \n",
            "Run: 1, Epoch: 247, Loss: 0.8641, Loss Cls: 0.8641, Train: 73.48%, Valid: 70.87%, Test: 70.40%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7366094500830208\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.947608, inference time:0:00:00.516883, \n",
            "Run: 1, Epoch: 248, Loss: 0.8595, Loss Cls: 0.8595, Train: 73.56%, Valid: 71.21%, Test: 70.38%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.737060291837565\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.983933, inference time:0:00:00.510061, \n",
            "Run: 1, Epoch: 249, Loss: 0.8572, Loss Cls: 0.8572, Train: 73.65%, Valid: 70.93%, Test: 70.57%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7382148865748123\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.949135, inference time:0:00:00.517637, \n",
            "Run: 1, Epoch: 250, Loss: 0.8533, Loss Cls: 0.8533, Train: 73.78%, Valid: 71.49%, Test: 70.46%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7379839676273628\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.939307, inference time:0:00:00.526405, \n",
            "Run: 1, Epoch: 251, Loss: 0.8521, Loss Cls: 0.8521, Train: 73.71%, Valid: 71.06%, Test: 70.33%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7392045392067385\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.941627, inference time:0:00:00.517262, \n",
            "Run: 1, Epoch: 252, Loss: 0.8507, Loss Cls: 0.8507, Train: 73.67%, Valid: 71.41%, Test: 70.52%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7379399830659439\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.959489, inference time:0:00:00.526771, \n",
            "Run: 1, Epoch: 253, Loss: 0.8510, Loss Cls: 0.8510, Train: 73.75%, Valid: 71.00%, Test: 70.03%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7390835816628364\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.284860, inference time:0:00:00.718758, \n",
            "Run: 1, Epoch: 254, Loss: 0.8512, Loss Cls: 0.8512, Train: 73.59%, Valid: 71.23%, Test: 70.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.738060940609846\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.259450, inference time:0:00:00.725506, \n",
            "Run: 1, Epoch: 255, Loss: 0.8524, Loss Cls: 0.8524, Train: 73.85%, Valid: 70.81%, Test: 69.60%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7385667630661638\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.278999, inference time:0:00:00.715681, \n",
            "Run: 1, Epoch: 256, Loss: 0.8523, Loss Cls: 0.8523, Train: 73.41%, Valid: 70.79%, Test: 70.51%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7379289869255892\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.400643, inference time:0:00:00.727017, \n",
            "Run: 1, Epoch: 257, Loss: 0.8538, Loss Cls: 0.8538, Train: 73.76%, Valid: 70.45%, Test: 68.73%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7385777592065185\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.239474, inference time:0:00:00.744522, \n",
            "Run: 1, Epoch: 258, Loss: 0.8523, Loss Cls: 0.8523, Train: 73.10%, Valid: 70.41%, Test: 70.38%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.738060940609846\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.304701, inference time:0:00:00.521944, \n",
            "Run: 1, Epoch: 259, Loss: 0.8529, Loss Cls: 0.8529, Train: 73.70%, Valid: 70.24%, Test: 68.30%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7385777592065185\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.963277, inference time:0:00:00.520575, \n",
            "Run: 1, Epoch: 260, Loss: 0.8507, Loss Cls: 0.8507, Train: 73.02%, Valid: 70.27%, Test: 70.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7388966472768058\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.949344, inference time:0:00:00.533205, \n",
            "Run: 1, Epoch: 261, Loss: 0.8505, Loss Cls: 0.8505, Train: 73.67%, Valid: 70.03%, Test: 67.96%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7390176048207079\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.016317, inference time:0:00:00.515203, \n",
            "Run: 1, Epoch: 262, Loss: 0.8492, Loss Cls: 0.8492, Train: 72.95%, Valid: 70.21%, Test: 70.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7389406318382248\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.955265, inference time:0:00:00.514069, \n",
            "Run: 1, Epoch: 263, Loss: 0.8481, Loss Cls: 0.8481, Train: 73.75%, Valid: 70.29%, Test: 68.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7396993655227015\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.080213, inference time:0:00:00.756434, \n",
            "Run: 1, Epoch: 264, Loss: 0.8473, Loss Cls: 0.8473, Train: 73.10%, Valid: 70.34%, Test: 70.51%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7397103616630563\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.335993, inference time:0:00:00.855905, \n",
            "Run: 1, Epoch: 265, Loss: 0.8464, Loss Cls: 0.8464, Train: 73.81%, Valid: 70.55%, Test: 68.57%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7394684465752521\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.542214, inference time:0:00:00.822009, \n",
            "Run: 1, Epoch: 266, Loss: 0.8467, Loss Cls: 0.8467, Train: 73.26%, Valid: 70.75%, Test: 70.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7399962613122794\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.393611, inference time:0:00:00.766878, \n",
            "Run: 1, Epoch: 267, Loss: 0.8468, Loss Cls: 0.8468, Train: 73.81%, Valid: 70.95%, Test: 69.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7384677978029711\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.374412, inference time:0:00:00.746299, \n",
            "Run: 1, Epoch: 268, Loss: 0.8487, Loss Cls: 0.8487, Train: 73.36%, Valid: 71.11%, Test: 70.65%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7388526627153869\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.302572, inference time:0:00:00.768827, \n",
            "Run: 1, Epoch: 269, Loss: 0.8490, Loss Cls: 0.8490, Train: 73.86%, Valid: 71.36%, Test: 70.05%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7386767244697111\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.294572, inference time:0:00:00.716574, \n",
            "Run: 1, Epoch: 270, Loss: 0.8492, Loss Cls: 0.8492, Train: 73.57%, Valid: 71.11%, Test: 70.25%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7396883693823468\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.264618, inference time:0:00:00.723137, \n",
            "Run: 1, Epoch: 271, Loss: 0.8480, Loss Cls: 0.8480, Train: 73.98%, Valid: 71.57%, Test: 70.56%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7408649564003035\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.161385, inference time:0:00:00.515352, \n",
            "Run: 1, Epoch: 272, Loss: 0.8449, Loss Cls: 0.8449, Train: 73.75%, Valid: 70.78%, Test: 69.53%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7408099756985298\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.966851, inference time:0:00:00.513385, \n",
            "Run: 1, Epoch: 273, Loss: 0.8440, Loss Cls: 0.8440, Train: 74.01%, Valid: 71.28%, Test: 70.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7419425781550676\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.968470, inference time:0:00:00.510364, \n",
            "Run: 1, Epoch: 274, Loss: 0.8416, Loss Cls: 0.8416, Train: 73.70%, Valid: 70.12%, Test: 68.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7407439988564014\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.955384, inference time:0:00:00.517795, \n",
            "Run: 1, Epoch: 275, Loss: 0.8435, Loss Cls: 0.8435, Train: 73.60%, Valid: 70.51%, Test: 70.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7413817749969761\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.943637, inference time:0:00:00.523702, \n",
            "Run: 1, Epoch: 276, Loss: 0.8432, Loss Cls: 0.8432, Train: 73.31%, Valid: 68.81%, Test: 66.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7392925083295763\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.965310, inference time:0:00:00.524051, \n",
            "Run: 1, Epoch: 277, Loss: 0.8483, Loss Cls: 0.8483, Train: 73.07%, Valid: 69.65%, Test: 69.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7397763385051846\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.943186, inference time:0:00:00.542019, \n",
            "Run: 1, Epoch: 278, Loss: 0.8486, Loss Cls: 0.8486, Train: 73.12%, Valid: 68.37%, Test: 65.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7367963844690514\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.282274, inference time:0:00:00.745882, \n",
            "Run: 1, Epoch: 279, Loss: 0.8535, Loss Cls: 0.8535, Train: 73.07%, Valid: 69.75%, Test: 69.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7392375276278026\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.295461, inference time:0:00:00.686465, \n",
            "Run: 1, Epoch: 280, Loss: 0.8498, Loss Cls: 0.8498, Train: 73.27%, Valid: 69.38%, Test: 67.19%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7375331258728186\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.274805, inference time:0:00:00.695015, \n",
            "Run: 1, Epoch: 281, Loss: 0.8497, Loss Cls: 0.8497, Train: 73.66%, Valid: 70.88%, Test: 70.64%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7405350721896614\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.241100, inference time:0:00:00.720336, \n",
            "Run: 1, Epoch: 282, Loss: 0.8434, Loss Cls: 0.8434, Train: 73.68%, Valid: 70.54%, Test: 69.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7397763385051846\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.283668, inference time:0:00:00.726047, \n",
            "Run: 1, Epoch: 283, Loss: 0.8418, Loss Cls: 0.8418, Train: 73.99%, Valid: 71.44%, Test: 71.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7419315820147129\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.149949, inference time:0:00:00.519225, \n",
            "Run: 1, Epoch: 284, Loss: 0.8383, Loss Cls: 0.8383, Train: 73.82%, Valid: 70.91%, Test: 69.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7400292497333436\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.962932, inference time:0:00:00.510777, \n",
            "Run: 1, Epoch: 285, Loss: 0.8387, Loss Cls: 0.8387, Train: 74.09%, Valid: 71.58%, Test: 70.83%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7422504700850001\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.962729, inference time:0:00:00.514571, \n",
            "Run: 1, Epoch: 286, Loss: 0.8367, Loss Cls: 0.8367, Train: 73.84%, Valid: 71.08%, Test: 70.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7407989795581751\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.900146, inference time:0:00:00.502920, \n",
            "Run: 1, Epoch: 287, Loss: 0.8384, Loss Cls: 0.8384, Train: 74.09%, Valid: 71.34%, Test: 70.32%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7425143774535138\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.930753, inference time:0:00:00.509517, \n",
            "Run: 1, Epoch: 288, Loss: 0.8367, Loss Cls: 0.8367, Train: 73.88%, Valid: 70.94%, Test: 70.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7408209718388845\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.975144, inference time:0:00:00.513978, \n",
            "Run: 1, Epoch: 289, Loss: 0.8380, Loss Cls: 0.8380, Train: 74.16%, Valid: 71.30%, Test: 69.93%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7420855279796791\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.945497, inference time:0:00:00.508181, \n",
            "Run: 1, Epoch: 290, Loss: 0.8361, Loss Cls: 0.8361, Train: 73.94%, Valid: 71.05%, Test: 70.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7414147634180402\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.213138, inference time:0:00:00.753041, \n",
            "Run: 1, Epoch: 291, Loss: 0.8363, Loss Cls: 0.8363, Train: 74.25%, Valid: 71.05%, Test: 69.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7423934199096117\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.313050, inference time:0:00:00.717346, \n",
            "Run: 1, Epoch: 292, Loss: 0.8347, Loss Cls: 0.8347, Train: 73.94%, Valid: 71.06%, Test: 70.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7424044160499664\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.294407, inference time:0:00:00.731720, \n",
            "Run: 1, Epoch: 293, Loss: 0.8343, Loss Cls: 0.8343, Train: 74.30%, Valid: 71.11%, Test: 69.63%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7428332655238011\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.336137, inference time:0:00:00.724072, \n",
            "Run: 1, Epoch: 294, Loss: 0.8336, Loss Cls: 0.8336, Train: 73.91%, Valid: 71.11%, Test: 70.36%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7426573272781254\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.266976, inference time:0:00:00.745230, \n",
            "Run: 1, Epoch: 295, Loss: 0.8330, Loss Cls: 0.8330, Train: 74.26%, Valid: 71.05%, Test: 69.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7429322307869938\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.175699, inference time:0:00:00.521011, \n",
            "Run: 1, Epoch: 296, Loss: 0.8336, Loss Cls: 0.8336, Train: 73.85%, Valid: 71.05%, Test: 70.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7421625009621623\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.933436, inference time:0:00:00.507992, \n",
            "Run: 1, Epoch: 297, Loss: 0.8339, Loss Cls: 0.8339, Train: 74.16%, Valid: 71.04%, Test: 69.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7423604314885475\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.999308, inference time:0:00:00.516298, \n",
            "Run: 1, Epoch: 298, Loss: 0.8363, Loss Cls: 0.8363, Train: 73.45%, Valid: 70.71%, Test: 70.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7395454195577352\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.935105, inference time:0:00:00.507292, \n",
            "Run: 1, Epoch: 299, Loss: 0.8376, Loss Cls: 0.8376, Train: 73.80%, Valid: 70.55%, Test: 68.60%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7406120451721446\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.921470, inference time:0:00:00.505052, \n",
            "Run: 1, Epoch: 300, Loss: 0.8427, Loss Cls: 0.8427, Train: 73.07%, Valid: 70.30%, Test: 70.37%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7368843535918892\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.943462, inference time:0:00:00.515219, \n",
            "Run: 1, Epoch: 301, Loss: 0.8415, Loss Cls: 0.8415, Train: 73.57%, Valid: 69.85%, Test: 67.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7401831956983099\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.926189, inference time:0:00:00.507838, \n",
            "Run: 1, Epoch: 302, Loss: 0.8448, Loss Cls: 0.8448, Train: 73.16%, Valid: 69.96%, Test: 70.27%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7378300216623965\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.218708, inference time:0:00:00.749352, \n",
            "Run: 1, Epoch: 303, Loss: 0.8401, Loss Cls: 0.8401, Train: 73.71%, Valid: 69.81%, Test: 67.38%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7420745318393244\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.406447, inference time:0:00:00.747171, \n",
            "Run: 1, Epoch: 304, Loss: 0.8393, Loss Cls: 0.8393, Train: 73.27%, Valid: 69.83%, Test: 70.19%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7402051879790194\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.286798, inference time:0:00:00.738502, \n",
            "Run: 1, Epoch: 305, Loss: 0.8365, Loss Cls: 0.8365, Train: 74.06%, Valid: 70.18%, Test: 67.83%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.74371295675218\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.264277, inference time:0:00:00.751781, \n",
            "Run: 1, Epoch: 306, Loss: 0.8335, Loss Cls: 0.8335, Train: 73.45%, Valid: 69.91%, Test: 70.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7428112732430917\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.314243, inference time:0:00:00.732182, \n",
            "Run: 1, Epoch: 307, Loss: 0.8304, Loss Cls: 0.8304, Train: 74.30%, Valid: 70.66%, Test: 68.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7446806171033967\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.200314, inference time:0:00:00.529612, \n",
            "Run: 1, Epoch: 308, Loss: 0.8281, Loss Cls: 0.8281, Train: 73.75%, Valid: 70.26%, Test: 70.29%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7445706556998494\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.967549, inference time:0:00:00.524503, \n",
            "Run: 1, Epoch: 309, Loss: 0.8260, Loss Cls: 0.8260, Train: 74.41%, Valid: 71.01%, Test: 68.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7450764781561672\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.946774, inference time:0:00:00.531028, \n",
            "Run: 1, Epoch: 310, Loss: 0.8253, Loss Cls: 0.8253, Train: 73.89%, Valid: 70.35%, Test: 70.40%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7444936827173662\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.948832, inference time:0:00:00.530632, \n",
            "Run: 1, Epoch: 311, Loss: 0.8246, Loss Cls: 0.8246, Train: 74.38%, Valid: 70.97%, Test: 68.64%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7448785476297819\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.960830, inference time:0:00:00.517080, \n",
            "Run: 1, Epoch: 312, Loss: 0.8255, Loss Cls: 0.8255, Train: 73.93%, Valid: 70.45%, Test: 70.36%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7443287406120451\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.942037, inference time:0:00:00.513031, \n",
            "Run: 1, Epoch: 313, Loss: 0.8266, Loss Cls: 0.8266, Train: 74.33%, Valid: 70.75%, Test: 68.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7439548718399842\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.932226, inference time:0:00:00.529674, \n",
            "Run: 1, Epoch: 314, Loss: 0.8283, Loss Cls: 0.8283, Train: 73.95%, Valid: 70.48%, Test: 70.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7429212346466391\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.315845, inference time:0:00:00.739252, \n",
            "Run: 1, Epoch: 315, Loss: 0.8310, Loss Cls: 0.8310, Train: 74.24%, Valid: 70.95%, Test: 69.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7427452964009633\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.349966, inference time:0:00:00.753921, \n",
            "Run: 1, Epoch: 316, Loss: 0.8317, Loss Cls: 0.8317, Train: 74.01%, Valid: 70.74%, Test: 70.37%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7427013118395444\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.278985, inference time:0:00:00.737242, \n",
            "Run: 1, Epoch: 317, Loss: 0.8339, Loss Cls: 0.8339, Train: 74.16%, Valid: 71.10%, Test: 69.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7431411574537338\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.282839, inference time:0:00:00.729001, \n",
            "Run: 1, Epoch: 318, Loss: 0.8318, Loss Cls: 0.8318, Train: 74.07%, Valid: 70.93%, Test: 70.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7435919992082779\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.209510, inference time:0:00:00.749805, \n",
            "Run: 1, Epoch: 319, Loss: 0.8321, Loss Cls: 0.8321, Train: 74.11%, Valid: 71.02%, Test: 70.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7436469799100516\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.068481, inference time:0:00:00.552442, \n",
            "Run: 1, Epoch: 320, Loss: 0.8292, Loss Cls: 0.8292, Train: 74.11%, Valid: 70.82%, Test: 69.35%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7451974357000692\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.968223, inference time:0:00:00.516278, \n",
            "Run: 1, Epoch: 321, Loss: 0.8278, Loss Cls: 0.8278, Train: 73.96%, Valid: 70.61%, Test: 70.11%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7447246016648157\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.953896, inference time:0:00:00.531413, \n",
            "Run: 1, Epoch: 322, Loss: 0.8254, Loss Cls: 0.8254, Train: 74.06%, Valid: 70.31%, Test: 68.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7459671655249007\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.928081, inference time:0:00:00.521833, \n",
            "Run: 1, Epoch: 323, Loss: 0.8246, Loss Cls: 0.8246, Train: 73.69%, Valid: 70.11%, Test: 69.96%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7450105013140388\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.976707, inference time:0:00:00.535554, \n",
            "Run: 1, Epoch: 324, Loss: 0.8244, Loss Cls: 0.8244, Train: 73.77%, Valid: 69.31%, Test: 66.50%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7443947174541736\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.925639, inference time:0:00:00.524015, \n",
            "Run: 1, Epoch: 325, Loss: 0.8266, Loss Cls: 0.8266, Train: 73.18%, Valid: 69.38%, Test: 69.46%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7427013118395444\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.986085, inference time:0:00:00.576086, \n",
            "Run: 1, Epoch: 326, Loss: 0.8289, Loss Cls: 0.8289, Train: 73.17%, Valid: 68.30%, Test: 65.00%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7401062227158267\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.302567, inference time:0:00:00.748468, \n",
            "Run: 1, Epoch: 327, Loss: 0.8357, Loss Cls: 0.8357, Train: 72.90%, Valid: 69.10%, Test: 69.46%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7403151493825667\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.358469, inference time:0:00:00.754434, \n",
            "Run: 1, Epoch: 328, Loss: 0.8348, Loss Cls: 0.8348, Train: 73.06%, Valid: 68.31%, Test: 65.32%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7385777592065185\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.286263, inference time:0:00:00.756132, \n",
            "Run: 1, Epoch: 329, Loss: 0.8384, Loss Cls: 0.8384, Train: 73.22%, Valid: 69.86%, Test: 70.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7404141146457593\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.342670, inference time:0:00:00.754183, \n",
            "Run: 1, Epoch: 330, Loss: 0.8334, Loss Cls: 0.8334, Train: 73.64%, Valid: 69.65%, Test: 67.17%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7409089409617224\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.292864, inference time:0:00:00.537560, \n",
            "Run: 1, Epoch: 331, Loss: 0.8306, Loss Cls: 0.8306, Train: 73.65%, Valid: 70.45%, Test: 70.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7426793195588348\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.946235, inference time:0:00:00.539115, \n",
            "Run: 1, Epoch: 332, Loss: 0.8283, Loss Cls: 0.8283, Train: 74.14%, Valid: 70.57%, Test: 68.37%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7434270571029569\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.955040, inference time:0:00:00.525246, \n",
            "Run: 1, Epoch: 333, Loss: 0.8254, Loss Cls: 0.8254, Train: 73.94%, Valid: 70.87%, Test: 70.47%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.74371295675218\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.934207, inference time:0:00:00.525837, \n",
            "Run: 1, Epoch: 334, Loss: 0.8252, Loss Cls: 0.8252, Train: 74.30%, Valid: 71.01%, Test: 69.40%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7440318448224673\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.939692, inference time:0:00:00.531146, \n",
            "Run: 1, Epoch: 335, Loss: 0.8234, Loss Cls: 0.8234, Train: 74.01%, Valid: 70.79%, Test: 70.08%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7446586248226872\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.947875, inference time:0:00:00.522877, \n",
            "Run: 1, Epoch: 336, Loss: 0.8247, Loss Cls: 0.8247, Train: 74.26%, Valid: 71.27%, Test: 70.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7439108872785652\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.933582, inference time:0:00:00.522581, \n",
            "Run: 1, Epoch: 337, Loss: 0.8242, Loss Cls: 0.8242, Train: 74.06%, Valid: 70.67%, Test: 69.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.74371295675218\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.942111, inference time:0:00:00.754756, \n",
            "Run: 1, Epoch: 338, Loss: 0.8260, Loss Cls: 0.8260, Train: 74.23%, Valid: 71.56%, Test: 70.60%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7437679374539536\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.319464, inference time:0:00:00.740489, \n",
            "Run: 1, Epoch: 339, Loss: 0.8244, Loss Cls: 0.8244, Train: 74.23%, Valid: 70.54%, Test: 69.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7442297753488526\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.366722, inference time:0:00:00.734163, \n",
            "Run: 1, Epoch: 340, Loss: 0.8237, Loss Cls: 0.8237, Train: 74.39%, Valid: 71.67%, Test: 70.94%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7445156749980757\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.338299, inference time:0:00:00.742595, \n",
            "Run: 1, Epoch: 341, Loss: 0.8212, Loss Cls: 0.8212, Train: 74.43%, Valid: 70.52%, Test: 68.75%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7456592735949682\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.320453, inference time:0:00:00.764332, \n",
            "Run: 1, Epoch: 342, Loss: 0.8189, Loss Cls: 0.8189, Train: 74.49%, Valid: 71.61%, Test: 71.07%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7460221462266744\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.252191, inference time:0:00:00.535786, \n",
            "Run: 1, Epoch: 343, Loss: 0.8171, Loss Cls: 0.8171, Train: 74.58%, Valid: 70.51%, Test: 68.57%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7468798451743438\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.935415, inference time:0:00:00.536155, \n",
            "Run: 1, Epoch: 344, Loss: 0.8156, Loss Cls: 0.8156, Train: 74.43%, Valid: 71.56%, Test: 71.00%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7475506097359826\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.974035, inference time:0:00:00.526877, \n",
            "Run: 1, Epoch: 345, Loss: 0.8143, Loss Cls: 0.8143, Train: 74.65%, Valid: 70.41%, Test: 68.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7473746714903069\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.963892, inference time:0:00:00.526929, \n",
            "Run: 1, Epoch: 346, Loss: 0.8139, Loss Cls: 0.8139, Train: 74.49%, Valid: 71.42%, Test: 71.01%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7480014514905268\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.980481, inference time:0:00:00.535833, \n",
            "Run: 1, Epoch: 347, Loss: 0.8128, Loss Cls: 0.8128, Train: 74.65%, Valid: 70.47%, Test: 68.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7481773897362026\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.958585, inference time:0:00:00.530457, \n",
            "Run: 1, Epoch: 348, Loss: 0.8135, Loss Cls: 0.8135, Train: 74.41%, Valid: 71.23%, Test: 70.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7477375441220132\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.953599, inference time:0:00:00.552378, \n",
            "Run: 1, Epoch: 349, Loss: 0.8121, Loss Cls: 0.8121, Train: 74.64%, Valid: 70.40%, Test: 68.42%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7488041697364225\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.331955, inference time:0:00:00.740546, \n",
            "Run: 1, Epoch: 350, Loss: 0.8140, Loss Cls: 0.8140, Train: 74.19%, Valid: 70.97%, Test: 70.70%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7475506097359826\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.330796, inference time:0:00:00.739970, \n",
            "Run: 1, Epoch: 351, Loss: 0.8133, Loss Cls: 0.8133, Train: 74.54%, Valid: 70.36%, Test: 68.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7477375441220132\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.279576, inference time:0:00:00.746718, \n",
            "Run: 1, Epoch: 352, Loss: 0.8175, Loss Cls: 0.8175, Train: 73.97%, Valid: 70.55%, Test: 70.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7460661307880934\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.253342, inference time:0:00:00.730689, \n",
            "Run: 1, Epoch: 353, Loss: 0.8188, Loss Cls: 0.8188, Train: 74.32%, Valid: 70.57%, Test: 68.96%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7441637985067241\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.284426, inference time:0:00:00.704132, \n",
            "Run: 1, Epoch: 354, Loss: 0.8243, Loss Cls: 0.8243, Train: 73.67%, Valid: 70.57%, Test: 69.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7431081690326695\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.969805, inference time:0:00:00.534377, \n",
            "Run: 1, Epoch: 355, Loss: 0.8274, Loss Cls: 0.8274, Train: 74.31%, Valid: 71.03%, Test: 69.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7418766013129392\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.944779, inference time:0:00:00.518938, \n",
            "Run: 1, Epoch: 356, Loss: 0.8275, Loss Cls: 0.8275, Train: 73.84%, Valid: 70.86%, Test: 70.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7430311960501864\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.959332, inference time:0:00:00.534504, \n",
            "Run: 1, Epoch: 357, Loss: 0.8280, Loss Cls: 0.8280, Train: 74.62%, Valid: 71.52%, Test: 70.93%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7447795823665894\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.935825, inference time:0:00:00.528098, \n",
            "Run: 1, Epoch: 358, Loss: 0.8194, Loss Cls: 0.8194, Train: 74.34%, Valid: 71.22%, Test: 70.19%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.746000153945965\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.957118, inference time:0:00:00.527203, \n",
            "Run: 1, Epoch: 359, Loss: 0.8163, Loss Cls: 0.8163, Train: 74.84%, Valid: 71.79%, Test: 71.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7485512585082637\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.938071, inference time:0:00:00.529910, \n",
            "Run: 1, Epoch: 360, Loss: 0.8101, Loss Cls: 0.8101, Train: 74.68%, Valid: 71.48%, Test: 70.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7479244785080437\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.958449, inference time:0:00:00.842155, \n",
            "Run: 1, Epoch: 361, Loss: 0.8083, Loss Cls: 0.8083, Train: 74.98%, Valid: 71.80%, Test: 71.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7498707953508319\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.358984, inference time:0:00:00.811976, \n",
            "Run: 1, Epoch: 362, Loss: 0.8067, Loss Cls: 0.8067, Train: 74.84%, Valid: 71.37%, Test: 69.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7488481542978415\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.326537, inference time:0:00:00.771906, \n",
            "Run: 1, Epoch: 363, Loss: 0.8071, Loss Cls: 0.8071, Train: 74.93%, Valid: 71.61%, Test: 71.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7492440153506119\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:01.287969, inference time:0:00:00.778158, \n",
            "Run: 1, Epoch: 364, Loss: 0.8089, Loss Cls: 0.8089, Train: 74.78%, Valid: 71.25%, Test: 69.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7479464707887531\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.291346, inference time:0:00:00.770294, \n",
            "Run: 1, Epoch: 365, Loss: 0.8101, Loss Cls: 0.8101, Train: 74.70%, Valid: 71.14%, Test: 70.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7476385788588206\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.316442, inference time:0:00:00.772617, \n",
            "Run: 1, Epoch: 366, Loss: 0.8140, Loss Cls: 0.8140, Train: 74.60%, Valid: 71.33%, Test: 69.60%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7471217602621479\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.303215, inference time:0:00:00.669631, \n",
            "Run: 1, Epoch: 367, Loss: 0.8131, Loss Cls: 0.8131, Train: 74.67%, Valid: 71.16%, Test: 70.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7471547486832122\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.948739, inference time:0:00:00.519640, \n",
            "Run: 1, Epoch: 368, Loss: 0.8154, Loss Cls: 0.8154, Train: 74.55%, Valid: 71.51%, Test: 70.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7471107641217932\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.943752, inference time:0:00:00.535719, \n",
            "Run: 1, Epoch: 369, Loss: 0.8124, Loss Cls: 0.8124, Train: 74.71%, Valid: 71.02%, Test: 70.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7485292662275541\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.943906, inference time:0:00:00.548163, \n",
            "Run: 1, Epoch: 370, Loss: 0.8116, Loss Cls: 0.8116, Train: 74.59%, Valid: 71.75%, Test: 71.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7476385788588206\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.969100, inference time:0:00:00.530167, \n",
            "Run: 1, Epoch: 371, Loss: 0.8099, Loss Cls: 0.8099, Train: 74.73%, Valid: 71.01%, Test: 69.59%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7492550114909666\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.946441, inference time:0:00:00.524522, \n",
            "Run: 1, Epoch: 372, Loss: 0.8091, Loss Cls: 0.8091, Train: 74.37%, Valid: 71.68%, Test: 71.46%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7474626406131448\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.940973, inference time:0:00:00.540824, \n",
            "Run: 1, Epoch: 373, Loss: 0.8098, Loss Cls: 0.8098, Train: 74.64%, Valid: 70.45%, Test: 68.74%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7486502237714562\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.997681, inference time:0:00:00.774446, \n",
            "Run: 1, Epoch: 374, Loss: 0.8102, Loss Cls: 0.8102, Train: 74.03%, Valid: 71.34%, Test: 71.38%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7459011886827723\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.246447, inference time:0:00:00.726294, \n",
            "Run: 1, Epoch: 375, Loss: 0.8133, Loss Cls: 0.8133, Train: 74.47%, Valid: 70.09%, Test: 67.93%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7471107641217932\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.228899, inference time:0:00:00.721918, \n",
            "Run: 1, Epoch: 376, Loss: 0.8137, Loss Cls: 0.8137, Train: 73.69%, Valid: 70.97%, Test: 71.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7445706556998494\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.305469, inference time:0:00:00.741940, \n",
            "Run: 1, Epoch: 377, Loss: 0.8176, Loss Cls: 0.8176, Train: 74.46%, Valid: 70.23%, Test: 68.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7462530651741239\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.322833, inference time:0:00:00.762449, \n",
            "Run: 1, Epoch: 378, Loss: 0.8159, Loss Cls: 0.8159, Train: 73.74%, Valid: 70.93%, Test: 70.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7448455592087178\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.305523, inference time:0:00:00.530088, \n",
            "Run: 1, Epoch: 379, Loss: 0.8174, Loss Cls: 0.8174, Train: 74.65%, Valid: 71.00%, Test: 69.41%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7462970497355428\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.963897, inference time:0:00:00.535254, \n",
            "Run: 1, Epoch: 380, Loss: 0.8125, Loss Cls: 0.8125, Train: 74.39%, Valid: 71.25%, Test: 70.71%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7473086946481785\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.965420, inference time:0:00:00.531512, \n",
            "Run: 1, Epoch: 381, Loss: 0.8100, Loss Cls: 0.8100, Train: 74.88%, Valid: 71.49%, Test: 70.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7490350886838719\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.956181, inference time:0:00:00.531019, \n",
            "Run: 1, Epoch: 382, Loss: 0.8055, Loss Cls: 0.8055, Train: 74.82%, Valid: 71.51%, Test: 70.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7494529420173519\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.986236, inference time:0:00:00.526616, \n",
            "Run: 1, Epoch: 383, Loss: 0.8031, Loss Cls: 0.8031, Train: 74.98%, Valid: 71.67%, Test: 70.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7506735135967275\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.920542, inference time:0:00:00.526844, \n",
            "Run: 1, Epoch: 384, Loss: 0.8007, Loss Cls: 0.8007, Train: 74.90%, Valid: 71.07%, Test: 69.63%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7502336679825381\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.968666, inference time:0:00:00.536846, \n",
            "Run: 1, Epoch: 385, Loss: 0.8009, Loss Cls: 0.8009, Train: 74.93%, Valid: 71.65%, Test: 71.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7507284942985012\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.197820, inference time:0:00:00.713458, \n",
            "Run: 1, Epoch: 386, Loss: 0.8005, Loss Cls: 0.8005, Train: 74.81%, Valid: 70.51%, Test: 68.49%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7495189188594803\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.314624, inference time:0:00:00.706492, \n",
            "Run: 1, Epoch: 387, Loss: 0.8031, Loss Cls: 0.8031, Train: 74.56%, Valid: 71.28%, Test: 71.18%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7489801079820982\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.338176, inference time:0:00:00.737433, \n",
            "Run: 1, Epoch: 388, Loss: 0.8037, Loss Cls: 0.8037, Train: 74.31%, Valid: 69.48%, Test: 66.80%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7483313357011689\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.366925, inference time:0:00:00.714932, \n",
            "Run: 1, Epoch: 389, Loss: 0.8079, Loss Cls: 0.8079, Train: 74.13%, Valid: 70.76%, Test: 71.03%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7477155518413037\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.308564, inference time:0:00:00.754312, \n",
            "Run: 1, Epoch: 390, Loss: 0.8075, Loss Cls: 0.8075, Train: 74.06%, Valid: 68.81%, Test: 65.44%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7480014514905268\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.964676, inference time:0:00:00.539339, \n",
            "Run: 1, Epoch: 391, Loss: 0.8105, Loss Cls: 0.8105, Train: 73.87%, Valid: 70.32%, Test: 70.83%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7472317216656953\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.922412, inference time:0:00:00.528597, \n",
            "Run: 1, Epoch: 392, Loss: 0.8077, Loss Cls: 0.8077, Train: 74.13%, Valid: 68.87%, Test: 65.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7489141311399699\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.955291, inference time:0:00:00.546823, \n",
            "Run: 1, Epoch: 393, Loss: 0.8076, Loss Cls: 0.8076, Train: 73.94%, Valid: 70.37%, Test: 70.83%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7488481542978415\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.963746, inference time:0:00:00.525218, \n",
            "Run: 1, Epoch: 394, Loss: 0.8039, Loss Cls: 0.8039, Train: 74.35%, Valid: 69.39%, Test: 66.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7504096062282138\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.956369, inference time:0:00:00.531727, \n",
            "Run: 1, Epoch: 395, Loss: 0.8030, Loss Cls: 0.8030, Train: 74.12%, Valid: 70.50%, Test: 70.88%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.749947768333315\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.945561, inference time:0:00:00.518438, \n",
            "Run: 1, Epoch: 396, Loss: 0.8008, Loss Cls: 0.8008, Train: 74.58%, Valid: 69.88%, Test: 67.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7510693746494981\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.945163, inference time:0:00:00.560393, \n",
            "Run: 1, Epoch: 397, Loss: 0.8004, Loss Cls: 0.8004, Train: 74.25%, Valid: 70.79%, Test: 70.94%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7498927876315413\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.284140, inference time:0:00:00.701492, \n",
            "Run: 1, Epoch: 398, Loss: 0.7995, Loss Cls: 0.7995, Train: 74.76%, Valid: 70.33%, Test: 67.88%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.750365621666795\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.331440, inference time:0:00:00.700192, \n",
            "Run: 1, Epoch: 399, Loss: 0.8000, Loss Cls: 0.8000, Train: 74.41%, Valid: 71.06%, Test: 71.00%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7502556602632476\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.313944, inference time:0:00:00.713468, \n",
            "Run: 1, Epoch: 400, Loss: 0.7998, Loss Cls: 0.7998, Train: 74.80%, Valid: 70.52%, Test: 68.30%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7502336679825381\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.280533, inference time:0:00:00.699433, \n",
            "Run: 1, Epoch: 401, Loss: 0.8002, Loss Cls: 0.8002, Train: 74.42%, Valid: 71.22%, Test: 70.86%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7496838609648013\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.318639, inference time:0:00:00.665155, \n",
            "Run: 1, Epoch: 402, Loss: 0.7998, Loss Cls: 0.7998, Train: 74.79%, Valid: 70.60%, Test: 68.65%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7499367721929603\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.029888, inference time:0:00:00.507275, \n",
            "Run: 1, Epoch: 403, Loss: 0.8001, Loss Cls: 0.8001, Train: 74.42%, Valid: 71.16%, Test: 70.67%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.750321637105376\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.975920, inference time:0:00:00.529956, \n",
            "Run: 1, Epoch: 404, Loss: 0.7998, Loss Cls: 0.7998, Train: 74.73%, Valid: 70.47%, Test: 68.57%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7501347027193455\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.973135, inference time:0:00:00.536164, \n",
            "Run: 1, Epoch: 405, Loss: 0.8007, Loss Cls: 0.8007, Train: 74.16%, Valid: 70.61%, Test: 70.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.748826162017132\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.959267, inference time:0:00:00.536729, \n",
            "Run: 1, Epoch: 406, Loss: 0.8015, Loss Cls: 0.8015, Train: 74.47%, Valid: 70.02%, Test: 68.07%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7497938223683487\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.61, Epoch train time:0:00:00.987480, inference time:0:00:00.546327, \n",
            "Run: 1, Epoch: 407, Loss: 0.8038, Loss Cls: 0.8038, Train: 73.90%, Valid: 70.05%, Test: 69.69%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.748452293245071\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.983552, inference time:0:00:00.534503, \n",
            "Run: 1, Epoch: 408, Loss: 0.8026, Loss Cls: 0.8026, Train: 74.23%, Valid: 69.36%, Test: 67.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7495848957016087\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.974547, inference time:0:00:00.744647, \n",
            "Run: 1, Epoch: 409, Loss: 0.8049, Loss Cls: 0.8049, Train: 73.97%, Valid: 70.22%, Test: 69.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7490790732452909\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.305764, inference time:0:00:00.732050, \n",
            "Run: 1, Epoch: 410, Loss: 0.8014, Loss Cls: 0.8014, Train: 74.47%, Valid: 69.64%, Test: 67.24%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7510033978073696\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.253778, inference time:0:00:00.747764, \n",
            "Run: 1, Epoch: 411, Loss: 0.8019, Loss Cls: 0.8019, Train: 74.35%, Valid: 70.72%, Test: 70.42%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7500467335965076\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.277348, inference time:0:00:00.737597, \n",
            "Run: 1, Epoch: 412, Loss: 0.7981, Loss Cls: 0.7981, Train: 74.79%, Valid: 70.33%, Test: 68.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7516631662286537\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.273868, inference time:0:00:00.742654, \n",
            "Run: 1, Epoch: 413, Loss: 0.7981, Loss Cls: 0.7981, Train: 74.62%, Valid: 71.09%, Test: 70.73%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7511573437723359\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.261908, inference time:0:00:00.522238, \n",
            "Run: 1, Epoch: 414, Loss: 0.7958, Loss Cls: 0.7958, Train: 75.01%, Valid: 70.68%, Test: 68.68%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7521469964042621\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.949071, inference time:0:00:00.538109, \n",
            "Run: 1, Epoch: 415, Loss: 0.7960, Loss Cls: 0.7960, Train: 74.78%, Valid: 71.46%, Test: 71.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7507944711406297\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.959687, inference time:0:00:00.521862, \n",
            "Run: 1, Epoch: 416, Loss: 0.7941, Loss Cls: 0.7941, Train: 75.17%, Valid: 71.16%, Test: 69.19%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.75244389219384\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.005515, inference time:0:00:00.544642, \n",
            "Run: 1, Epoch: 417, Loss: 0.7946, Loss Cls: 0.7946, Train: 74.93%, Valid: 71.46%, Test: 71.15%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7507504865792107\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.941723, inference time:0:00:00.522547, \n",
            "Run: 1, Epoch: 418, Loss: 0.7929, Loss Cls: 0.7929, Train: 75.16%, Valid: 71.42%, Test: 69.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7521360002639074\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.971834, inference time:0:00:00.535939, \n",
            "Run: 1, Epoch: 419, Loss: 0.7942, Loss Cls: 0.7942, Train: 74.80%, Valid: 71.31%, Test: 70.93%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.750200679561474\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.934350, inference time:0:00:00.529997, \n",
            "Run: 1, Epoch: 420, Loss: 0.7950, Loss Cls: 0.7950, Train: 75.02%, Valid: 71.27%, Test: 69.72%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7509154286845318\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:01.268278, inference time:0:00:00.738875, \n",
            "Run: 1, Epoch: 421, Loss: 0.7991, Loss Cls: 0.7991, Train: 74.43%, Valid: 70.82%, Test: 70.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7471217602621479\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.311204, inference time:0:00:00.731450, \n",
            "Run: 1, Epoch: 422, Loss: 0.8036, Loss Cls: 0.8036, Train: 74.67%, Valid: 71.29%, Test: 70.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7486502237714562\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.274356, inference time:0:00:00.749095, \n",
            "Run: 1, Epoch: 423, Loss: 0.8061, Loss Cls: 0.8061, Train: 74.26%, Valid: 70.46%, Test: 69.92%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7471107641217932\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.244702, inference time:0:00:00.734555, \n",
            "Run: 1, Epoch: 424, Loss: 0.8078, Loss Cls: 0.8078, Train: 74.72%, Valid: 71.56%, Test: 70.55%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7502776525439571\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.219401, inference time:0:00:00.739883, \n",
            "Run: 1, Epoch: 425, Loss: 0.8019, Loss Cls: 0.8019, Train: 74.73%, Valid: 70.86%, Test: 69.98%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7501017142982813\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.075383, inference time:0:00:00.527333, \n",
            "Run: 1, Epoch: 426, Loss: 0.7973, Loss Cls: 0.7973, Train: 75.08%, Valid: 71.83%, Test: 71.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7529277223694483\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.955615, inference time:0:00:00.529824, \n",
            "Run: 1, Epoch: 427, Loss: 0.7920, Loss Cls: 0.7920, Train: 75.20%, Valid: 71.15%, Test: 70.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7531146567554788\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.942768, inference time:0:00:00.528413, \n",
            "Run: 1, Epoch: 428, Loss: 0.7891, Loss Cls: 0.7891, Train: 75.24%, Valid: 71.90%, Test: 71.34%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7540273364049219\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.044508, inference time:0:00:00.533633, \n",
            "Run: 1, Epoch: 429, Loss: 0.7873, Loss Cls: 0.7873, Train: 75.23%, Valid: 71.21%, Test: 69.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7540493286856313\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.934894, inference time:0:00:00.501463, \n",
            "Run: 1, Epoch: 430, Loss: 0.7870, Loss Cls: 0.7870, Train: 75.10%, Valid: 71.75%, Test: 71.28%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7534995216678946\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.965002, inference time:0:00:00.528951, \n",
            "Run: 1, Epoch: 431, Loss: 0.7886, Loss Cls: 0.7886, Train: 75.06%, Valid: 70.87%, Test: 69.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7516851585093632\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.985178, inference time:0:00:00.588168, \n",
            "Run: 1, Epoch: 432, Loss: 0.7932, Loss Cls: 0.7932, Train: 74.39%, Valid: 70.76%, Test: 70.45%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.749573899561254\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.272863, inference time:0:00:00.739687, \n",
            "Run: 1, Epoch: 433, Loss: 0.8025, Loss Cls: 0.8025, Train: 73.79%, Valid: 69.45%, Test: 67.26%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7440978216645957\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.282391, inference time:0:00:00.763439, \n",
            "Run: 1, Epoch: 434, Loss: 0.8135, Loss Cls: 0.8135, Train: 72.94%, Valid: 68.79%, Test: 68.84%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7423604314885475\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.310694, inference time:0:00:00.742497, \n",
            "Run: 1, Epoch: 435, Loss: 0.8235, Loss Cls: 0.8235, Train: 73.42%, Valid: 68.46%, Test: 65.91%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7440758293838863\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.298565, inference time:0:00:00.742885, \n",
            "Run: 1, Epoch: 436, Loss: 0.8146, Loss Cls: 0.8146, Train: 73.71%, Valid: 69.41%, Test: 69.13%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7489251272803246\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.272932, inference time:0:00:00.576597, \n",
            "Run: 1, Epoch: 437, Loss: 0.8012, Loss Cls: 0.8012, Train: 74.66%, Valid: 70.15%, Test: 68.01%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7521689886849716\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.963492, inference time:0:00:00.523890, \n",
            "Run: 1, Epoch: 438, Loss: 0.7934, Loss Cls: 0.7934, Train: 74.61%, Valid: 70.50%, Test: 70.02%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7529057300887388\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.956580, inference time:0:00:00.531831, \n",
            "Run: 1, Epoch: 439, Loss: 0.7868, Loss Cls: 0.7868, Train: 75.14%, Valid: 70.76%, Test: 68.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7548850353525912\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.933984, inference time:0:00:00.515269, \n",
            "Run: 1, Epoch: 440, Loss: 0.7852, Loss Cls: 0.7852, Train: 74.93%, Valid: 70.90%, Test: 70.39%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7545001704401755\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.962947, inference time:0:00:00.536290, \n",
            "Run: 1, Epoch: 441, Loss: 0.7827, Loss Cls: 0.7827, Train: 75.26%, Valid: 70.97%, Test: 68.80%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7551819311421691\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.947534, inference time:0:00:00.528649, \n",
            "Run: 1, Epoch: 442, Loss: 0.7829, Loss Cls: 0.7829, Train: 75.01%, Valid: 71.13%, Test: 70.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7549510121947196\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.938986, inference time:0:00:00.531638, \n",
            "Run: 1, Epoch: 443, Loss: 0.7818, Loss Cls: 0.7818, Train: 75.21%, Valid: 70.78%, Test: 68.45%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7553468732474902\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.958410, inference time:0:00:00.741367, \n",
            "Run: 1, Epoch: 444, Loss: 0.7828, Loss Cls: 0.7828, Train: 75.10%, Valid: 71.08%, Test: 70.55%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7544451897384018\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.283976, inference time:0:00:00.737216, \n",
            "Run: 1, Epoch: 445, Loss: 0.7829, Loss Cls: 0.7829, Train: 75.07%, Valid: 70.74%, Test: 68.36%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7546431202647871\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.222456, inference time:0:00:00.735127, \n",
            "Run: 1, Epoch: 446, Loss: 0.7847, Loss Cls: 0.7847, Train: 75.07%, Valid: 70.97%, Test: 70.64%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7538294058785366\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.291165, inference time:0:00:00.730270, \n",
            "Run: 1, Epoch: 447, Loss: 0.7852, Loss Cls: 0.7852, Train: 75.02%, Valid: 70.77%, Test: 68.48%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7537414367556987\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.283969, inference time:0:00:00.734409, \n",
            "Run: 1, Epoch: 448, Loss: 0.7879, Loss Cls: 0.7879, Train: 75.08%, Valid: 71.00%, Test: 70.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7530816683344146\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.244565, inference time:0:00:00.538455, \n",
            "Run: 1, Epoch: 449, Loss: 0.7880, Loss Cls: 0.7880, Train: 74.99%, Valid: 71.05%, Test: 68.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7526858072816441\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.949096, inference time:0:00:00.540287, \n",
            "Run: 1, Epoch: 450, Loss: 0.7905, Loss Cls: 0.7905, Train: 75.10%, Valid: 71.08%, Test: 70.66%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7535764946503777\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.947484, inference time:0:00:00.533233, \n",
            "Run: 1, Epoch: 451, Loss: 0.7881, Loss Cls: 0.7881, Train: 75.13%, Valid: 71.41%, Test: 69.45%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7533785641239925\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.939842, inference time:0:00:00.522917, \n",
            "Run: 1, Epoch: 452, Loss: 0.7886, Loss Cls: 0.7886, Train: 75.08%, Valid: 70.98%, Test: 70.51%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7537414367556987\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.963398, inference time:0:00:00.527673, \n",
            "Run: 1, Epoch: 453, Loss: 0.7866, Loss Cls: 0.7866, Train: 75.18%, Valid: 71.56%, Test: 69.82%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7530486799133504\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.957917, inference time:0:00:00.534358, \n",
            "Run: 1, Epoch: 454, Loss: 0.7878, Loss Cls: 0.7878, Train: 74.86%, Valid: 70.66%, Test: 70.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7532466104397356\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.61, Epoch train time:0:00:00.963666, inference time:0:00:00.525554, \n",
            "Run: 1, Epoch: 455, Loss: 0.7898, Loss Cls: 0.7898, Train: 75.04%, Valid: 71.03%, Test: 69.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7521360002639074\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.099851, inference time:0:00:00.768431, \n",
            "Run: 1, Epoch: 456, Loss: 0.7919, Loss Cls: 0.7919, Train: 74.43%, Valid: 70.33%, Test: 70.02%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7510473823687885\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.264528, inference time:0:00:00.734097, \n",
            "Run: 1, Epoch: 457, Loss: 0.7960, Loss Cls: 0.7960, Train: 74.85%, Valid: 70.57%, Test: 68.38%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.751278301316238\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.243424, inference time:0:00:00.742035, \n",
            "Run: 1, Epoch: 458, Loss: 0.7943, Loss Cls: 0.7943, Train: 74.36%, Valid: 70.47%, Test: 70.42%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7515971893865253\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.278416, inference time:0:00:00.807123, \n",
            "Run: 1, Epoch: 459, Loss: 0.7928, Loss Cls: 0.7928, Train: 74.93%, Valid: 70.63%, Test: 68.09%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7526858072816441\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.305138, inference time:0:00:00.743652, \n",
            "Run: 1, Epoch: 460, Loss: 0.7895, Loss Cls: 0.7895, Train: 74.48%, Valid: 70.84%, Test: 71.06%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7534225486854115\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.285707, inference time:0:00:00.781163, \n",
            "Run: 1, Epoch: 461, Loss: 0.7859, Loss Cls: 0.7859, Train: 75.16%, Valid: 70.83%, Test: 68.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7539613595627934\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.280870, inference time:0:00:00.718542, \n",
            "Run: 1, Epoch: 462, Loss: 0.7841, Loss Cls: 0.7841, Train: 74.74%, Valid: 71.23%, Test: 71.22%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.754522162720885\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.294481, inference time:0:00:00.753134, \n",
            "Run: 1, Epoch: 463, Loss: 0.7818, Loss Cls: 0.7818, Train: 75.39%, Valid: 71.27%, Test: 68.90%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7548740392122365\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.343519, inference time:0:00:00.728383, \n",
            "Run: 1, Epoch: 464, Loss: 0.7805, Loss Cls: 0.7805, Train: 74.92%, Valid: 71.29%, Test: 71.12%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7553138848264259\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.245033, inference time:0:00:00.531806, \n",
            "Run: 1, Epoch: 465, Loss: 0.7792, Loss Cls: 0.7792, Train: 75.51%, Valid: 71.22%, Test: 68.94%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7558966802652269\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.918287, inference time:0:00:00.519333, \n",
            "Run: 1, Epoch: 466, Loss: 0.7779, Loss Cls: 0.7779, Train: 75.07%, Valid: 71.34%, Test: 71.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7561495914933858\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.969753, inference time:0:00:00.761561, \n",
            "Run: 1, Epoch: 467, Loss: 0.7770, Loss Cls: 0.7770, Train: 75.49%, Valid: 70.97%, Test: 68.76%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7570072904410552\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.313197, inference time:0:00:00.725723, \n",
            "Run: 1, Epoch: 468, Loss: 0.7761, Loss Cls: 0.7761, Train: 75.07%, Valid: 71.18%, Test: 70.93%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.75618257991445\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.276338, inference time:0:00:00.735202, \n",
            "Run: 1, Epoch: 469, Loss: 0.7765, Loss Cls: 0.7765, Train: 75.34%, Valid: 70.53%, Test: 68.16%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7571282479849573\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.271674, inference time:0:00:00.735928, \n",
            "Run: 1, Epoch: 470, Loss: 0.7773, Loss Cls: 0.7773, Train: 74.70%, Valid: 70.66%, Test: 70.64%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7539283711417293\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.312714, inference time:0:00:00.739736, \n",
            "Run: 1, Epoch: 471, Loss: 0.7800, Loss Cls: 0.7800, Train: 74.86%, Valid: 69.66%, Test: 66.99%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7536204792117966\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.223279, inference time:0:00:00.526327, \n",
            "Run: 1, Epoch: 472, Loss: 0.7862, Loss Cls: 0.7862, Train: 74.07%, Valid: 70.03%, Test: 70.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7487601851750035\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.981283, inference time:0:00:00.539040, \n",
            "Run: 1, Epoch: 473, Loss: 0.7893, Loss Cls: 0.7893, Train: 74.51%, Valid: 69.33%, Test: 66.72%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7498488030701224\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.959483, inference time:0:00:00.526659, \n",
            "Run: 1, Epoch: 474, Loss: 0.7983, Loss Cls: 0.7983, Train: 74.55%, Valid: 70.80%, Test: 70.81%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7504425946492781\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.983638, inference time:0:00:00.528480, \n",
            "Run: 1, Epoch: 475, Loss: 0.7872, Loss Cls: 0.7872, Train: 75.09%, Valid: 70.41%, Test: 68.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7533895602643472\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.956146, inference time:0:00:00.530121, \n",
            "Run: 1, Epoch: 476, Loss: 0.7863, Loss Cls: 0.7863, Train: 75.37%, Valid: 71.60%, Test: 71.33%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7551599388614596\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.952186, inference time:0:00:00.538538, \n",
            "Run: 1, Epoch: 477, Loss: 0.7796, Loss Cls: 0.7796, Train: 75.36%, Valid: 71.32%, Test: 69.97%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7546431202647871\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.964911, inference time:0:00:00.528855, \n",
            "Run: 1, Epoch: 478, Loss: 0.7791, Loss Cls: 0.7791, Train: 75.66%, Valid: 71.90%, Test: 71.18%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.755808711142389\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.260875, inference time:0:00:00.749651, \n",
            "Run: 1, Epoch: 479, Loss: 0.7772, Loss Cls: 0.7772, Train: 75.27%, Valid: 71.53%, Test: 70.62%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.754104309387405\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.277370, inference time:0:00:00.757074, \n",
            "Run: 1, Epoch: 480, Loss: 0.7779, Loss Cls: 0.7779, Train: 75.74%, Valid: 71.63%, Test: 70.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7563475220197711\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.287909, inference time:0:00:00.742088, \n",
            "Run: 1, Epoch: 481, Loss: 0.7774, Loss Cls: 0.7774, Train: 75.10%, Valid: 71.29%, Test: 70.83%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.753521513948604\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.269833, inference time:0:00:00.746696, \n",
            "Run: 1, Epoch: 482, Loss: 0.7789, Loss Cls: 0.7789, Train: 75.63%, Valid: 71.10%, Test: 69.23%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7559076764055817\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.265714, inference time:0:00:00.731726, \n",
            "Run: 1, Epoch: 483, Loss: 0.7792, Loss Cls: 0.7792, Train: 74.73%, Valid: 70.69%, Test: 70.43%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7521030118428431\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.960407, inference time:0:00:00.533760, \n",
            "Run: 1, Epoch: 484, Loss: 0.7825, Loss Cls: 0.7825, Train: 75.22%, Valid: 70.53%, Test: 68.31%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7545881395630134\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.942773, inference time:0:00:00.550183, \n",
            "Run: 1, Epoch: 485, Loss: 0.7843, Loss Cls: 0.7843, Train: 74.41%, Valid: 70.30%, Test: 70.20%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7497278455262203\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.947044, inference time:0:00:00.537100, \n",
            "Run: 1, Epoch: 486, Loss: 0.7895, Loss Cls: 0.7895, Train: 74.87%, Valid: 70.06%, Test: 67.87%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7519600620182316\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.958200, inference time:0:00:00.543438, \n",
            "Run: 1, Epoch: 487, Loss: 0.7907, Loss Cls: 0.7907, Train: 74.33%, Valid: 70.56%, Test: 70.19%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7488371581574867\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.985842, inference time:0:00:00.529987, \n",
            "Run: 1, Epoch: 488, Loss: 0.7941, Loss Cls: 0.7941, Train: 75.12%, Valid: 70.78%, Test: 69.01%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7521140079831979\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.956159, inference time:0:00:00.526965, \n",
            "Run: 1, Epoch: 489, Loss: 0.7894, Loss Cls: 0.7894, Train: 74.99%, Valid: 71.38%, Test: 70.78%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7525428574570325\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.977111, inference time:0:00:00.764856, \n",
            "Run: 1, Epoch: 490, Loss: 0.7861, Loss Cls: 0.7861, Train: 75.59%, Valid: 71.43%, Test: 70.10%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7547970662297534\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:01.299290, inference time:0:00:00.744798, \n",
            "Run: 1, Epoch: 491, Loss: 0.7792, Loss Cls: 0.7792, Train: 75.58%, Valid: 71.82%, Test: 70.96%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7564134988618995\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.247757, inference time:0:00:00.753731, \n",
            "Run: 1, Epoch: 492, Loss: 0.7753, Loss Cls: 0.7753, Train: 75.69%, Valid: 71.73%, Test: 70.71%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7562815451776427\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.245081, inference time:0:00:00.759650, \n",
            "Run: 1, Epoch: 493, Loss: 0.7723, Loss Cls: 0.7723, Train: 75.75%, Valid: 71.83%, Test: 70.63%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.757886981669434\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.247115, inference time:0:00:00.743948, \n",
            "Run: 1, Epoch: 494, Loss: 0.7713, Loss Cls: 0.7713, Train: 75.63%, Valid: 71.49%, Test: 70.51%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7564244950022542\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:01.290590, inference time:0:00:00.539819, \n",
            "Run: 1, Epoch: 495, Loss: 0.7715, Loss Cls: 0.7715, Train: 75.50%, Valid: 71.42%, Test: 69.86%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7568643406164436\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.957034, inference time:0:00:00.533352, \n",
            "Run: 1, Epoch: 496, Loss: 0.7728, Loss Cls: 0.7728, Train: 75.37%, Valid: 70.91%, Test: 69.82%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7553798616685543\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.948795, inference time:0:00:00.533133, \n",
            "Run: 1, Epoch: 497, Loss: 0.7758, Loss Cls: 0.7758, Train: 74.94%, Valid: 70.67%, Test: 69.14%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7548190585104628\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.12, avg inference:0.62, Epoch train time:0:00:00.964176, inference time:0:00:00.528784, \n",
            "Run: 1, Epoch: 498, Loss: 0.7788, Loss Cls: 0.7788, Train: 74.88%, Valid: 70.11%, Test: 68.65%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7534225486854115\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.970779, inference time:0:00:00.539291, \n",
            "Run: 1, Epoch: 499, Loss: 0.7809, Loss Cls: 0.7809, Train: 74.61%, Valid: 70.34%, Test: 68.92%\n",
            "num_B_prime:0, new edges:0\n",
            "Batch 0.0, train acc:0.7538404020188914\n",
            "num_B_prime:0, new edges:0\n",
            "avg train:1.11, avg inference:0.62, Epoch train time:0:00:00.956542, inference time:0:00:00.533652, \n",
            "Run: 1, Epoch: 500, Loss: 0.7822, Loss Cls: 0.7822, Train: 74.97%, Valid: 70.14%, Test: 68.33%\n",
            "Run 01:\n",
            "Highest Train: 75.75\n",
            "Highest Valid: 71.90\n",
            "  Final Train: 75.24\n",
            "   Final Test: 71.34\n",
            "All runs:\n",
            "Highest Train: 75.75 ± nan\n",
            "Highest Valid: 71.90 ± nan\n",
            "  Final Train: 75.24 ± nan\n",
            "   Final Test: 71.34 ± nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd VQ-GNN/vq_gnn_v2 && python main_node.py --hidden-channels 256  --lr 3e-3 --epochs 500 \\\n",
        "--batch-size 60000 --test-batch-size 60000 --num-M 4096 --num-D 4  --conv-type SAGE \\\n",
        "--sampler-type node --dataset ppi --skip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U3ahhMFtVs9",
        "outputId": "0583cccb-fdff-495b-8c3d-f03d36cc2f23"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.6.\n",
            "Namespace(EMA=True, act='leaky_gelu', alpha_dropout_flag=False, batch_size=60000, bn_flag=True, ce_only=False, clip=None, cluster='vq', commitment_cost=0.0, cont_sliding_window=1, conv_type='SAGE', data_root='/cmlscratch/kong/datasets', dataset='ppi', device=0, dropbranch=0.0, dropout=0, epochs=500, exp=False, exp_name='test', exp_tag='exp', grad_scale=[1, 1], hidden_channels=256, kmeans_init=False, kmeans_iter=100, ln_para=False, log_steps=1, lr=0.003, momentum=0.1, no_second_fc=True, num_D=4, num_M=4096, num_branch=0, num_layers=3, num_parts=1, num_workers=0, recovery_flag=True, run_idx=None, runs=1, sampler_type='node', sche=False, skip=True, split=True, test_batch_size=60000, transformer_flag=False, use_gcn=False, walk_length=5, warm_up=True, warm_up_epochs=0, weight_ahead=False)\n",
            "PPI loaded\n",
            "1\n",
            "num_B_prime:0, new edges:44906\n",
            "2315.715584\n",
            "2\n",
            "num_B_prime:0, new edges:44906\n",
            "2362.058752\n",
            "3\n",
            "num_B_prime:0, new edges:44906\n",
            "2408.512512\n",
            "init done\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.38465293924015476\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 1, Loss: 0.7375, Loss Cls: 0.7375, Train: 41.32%, Valid: 41.39%, Test: 41.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.41742386598282827\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 2, Loss: 1.3167, Loss Cls: 1.3167, Train: 44.52%, Valid: 44.22%, Test: 44.46%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4361725946091636\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 3, Loss: 0.6545, Loss Cls: 0.6545, Train: 44.15%, Valid: 43.25%, Test: 43.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4265814619762201\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 4, Loss: 0.6190, Loss Cls: 0.6190, Train: 44.13%, Valid: 44.08%, Test: 44.26%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.43894261602363926\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 5, Loss: 0.5831, Loss Cls: 0.5831, Train: 48.99%, Valid: 47.89%, Test: 48.29%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4438664715415508\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 6, Loss: 0.5702, Loss Cls: 0.5702, Train: 46.70%, Valid: 46.42%, Test: 46.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.45164351077985376\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 7, Loss: 0.5511, Loss Cls: 0.5511, Train: 49.57%, Valid: 48.85%, Test: 49.22%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.43757621889499804\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 8, Loss: 0.5301, Loss Cls: 0.5301, Train: 49.50%, Valid: 48.92%, Test: 49.28%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4540798648534289\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 9, Loss: 0.5236, Loss Cls: 0.5236, Train: 51.01%, Valid: 50.15%, Test: 50.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4534633338957585\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 10, Loss: 0.5188, Loss Cls: 0.5188, Train: 50.33%, Valid: 49.54%, Test: 49.95%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4634383462700941\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 11, Loss: 0.5148, Loss Cls: 0.5148, Train: 52.69%, Valid: 51.65%, Test: 52.14%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4736419873857437\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 12, Loss: 0.5116, Loss Cls: 0.5116, Train: 48.63%, Valid: 47.89%, Test: 48.30%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.46901256550393955\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 13, Loss: 0.5107, Loss Cls: 0.5107, Train: 54.69%, Valid: 53.55%, Test: 54.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4896949488881615\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 14, Loss: 0.5178, Loss Cls: 0.5178, Train: 47.14%, Valid: 46.86%, Test: 47.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.47254446235368075\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 15, Loss: 0.5127, Loss Cls: 0.5127, Train: 55.72%, Valid: 54.52%, Test: 55.08%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.4917716966717521\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 16, Loss: 0.5063, Loss Cls: 0.5063, Train: 51.04%, Valid: 50.20%, Test: 50.68%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.49571980004186317\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 17, Loss: 0.5000, Loss Cls: 0.5000, Train: 56.19%, Valid: 54.82%, Test: 55.40%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5063042761771175\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 18, Loss: 0.4961, Loss Cls: 0.4961, Train: 50.63%, Valid: 49.65%, Test: 50.16%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5108745375692201\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 19, Loss: 0.4946, Loss Cls: 0.4946, Train: 56.96%, Valid: 55.53%, Test: 56.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5162777959247075\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 20, Loss: 0.5003, Loss Cls: 0.5003, Train: 50.56%, Valid: 49.65%, Test: 50.21%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5174125103886834\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 21, Loss: 0.4971, Loss Cls: 0.4971, Train: 56.26%, Valid: 54.71%, Test: 55.41%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5139454004906214\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 22, Loss: 0.4941, Loss Cls: 0.4941, Train: 54.22%, Valid: 52.86%, Test: 53.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5323344263509884\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 23, Loss: 0.4855, Loss Cls: 0.4855, Train: 55.85%, Valid: 54.09%, Test: 54.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5256309667665064\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 24, Loss: 0.4801, Loss Cls: 0.4801, Train: 53.99%, Valid: 52.37%, Test: 53.19%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5517451462653192\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 25, Loss: 0.4776, Loss Cls: 0.4776, Train: 56.63%, Valid: 54.82%, Test: 55.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.536624345201101\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 26, Loss: 0.4808, Loss Cls: 0.4808, Train: 52.24%, Valid: 50.77%, Test: 51.52%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.55116008615881\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 27, Loss: 0.4852, Loss Cls: 0.4852, Train: 57.68%, Valid: 55.96%, Test: 56.73%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5346102715114857\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 28, Loss: 0.4873, Loss Cls: 0.4873, Train: 56.71%, Valid: 55.00%, Test: 55.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5559309853196014\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 29, Loss: 0.4742, Loss Cls: 0.4742, Train: 57.19%, Valid: 55.07%, Test: 56.01%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.54812\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 30, Loss: 0.4672, Loss Cls: 0.4672, Train: 55.54%, Valid: 53.62%, Test: 54.52%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5781722156996221\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 31, Loss: 0.4649, Loss Cls: 0.4649, Train: 58.84%, Valid: 56.72%, Test: 57.66%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5574387533306443\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 32, Loss: 0.4697, Loss Cls: 0.4697, Train: 52.82%, Valid: 50.87%, Test: 51.71%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5751913113526782\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 33, Loss: 0.4750, Loss Cls: 0.4750, Train: 59.09%, Valid: 57.38%, Test: 58.18%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5606330002184652\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 34, Loss: 0.4784, Loss Cls: 0.4784, Train: 56.02%, Valid: 53.82%, Test: 54.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5725442085289933\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 35, Loss: 0.4675, Loss Cls: 0.4675, Train: 58.53%, Valid: 56.42%, Test: 57.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5654939447034102\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 36, Loss: 0.4603, Loss Cls: 0.4603, Train: 58.17%, Valid: 56.05%, Test: 57.06%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5901938426453819\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 37, Loss: 0.4598, Loss Cls: 0.4598, Train: 57.75%, Valid: 55.28%, Test: 56.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5753680034437171\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 38, Loss: 0.4563, Loss Cls: 0.4563, Train: 58.75%, Valid: 56.34%, Test: 57.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6005540415600424\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 39, Loss: 0.4527, Loss Cls: 0.4527, Train: 59.87%, Valid: 57.67%, Test: 58.78%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5805050402851955\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 40, Loss: 0.4543, Loss Cls: 0.4543, Train: 58.58%, Valid: 56.09%, Test: 57.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6043628095235334\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 41, Loss: 0.4548, Loss Cls: 0.4548, Train: 61.22%, Valid: 59.14%, Test: 60.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5780051557185873\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 42, Loss: 0.4539, Loss Cls: 0.4539, Train: 58.92%, Valid: 56.35%, Test: 57.50%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6116610427519463\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 43, Loss: 0.4505, Loss Cls: 0.4505, Train: 59.42%, Valid: 57.22%, Test: 58.26%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.5865358496423443\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 44, Loss: 0.4486, Loss Cls: 0.4486, Train: 59.56%, Valid: 56.87%, Test: 58.04%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6160039290184617\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 45, Loss: 0.4434, Loss Cls: 0.4434, Train: 59.73%, Valid: 57.40%, Test: 58.53%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6002029042030509\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 46, Loss: 0.4459, Loss Cls: 0.4459, Train: 60.21%, Valid: 57.68%, Test: 58.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6063241093136539\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 47, Loss: 0.4477, Loss Cls: 0.4477, Train: 59.82%, Valid: 57.24%, Test: 58.49%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6091225761978828\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 48, Loss: 0.4412, Loss Cls: 0.4412, Train: 62.33%, Valid: 60.00%, Test: 61.03%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6138604682933493\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 49, Loss: 0.4351, Loss Cls: 0.4351, Train: 59.46%, Valid: 56.42%, Test: 57.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6245737357205182\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 50, Loss: 0.4281, Loss Cls: 0.4281, Train: 63.50%, Valid: 61.14%, Test: 62.27%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6266750891903166\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 51, Loss: 0.4272, Loss Cls: 0.4272, Train: 59.54%, Valid: 56.42%, Test: 57.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6273086617326231\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 52, Loss: 0.4270, Loss Cls: 0.4270, Train: 62.70%, Valid: 60.40%, Test: 61.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6207491259259971\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 53, Loss: 0.4329, Loss Cls: 0.4329, Train: 61.25%, Valid: 58.36%, Test: 59.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6250985123986174\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 54, Loss: 0.4321, Loss Cls: 0.4321, Train: 60.86%, Valid: 58.54%, Test: 59.70%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6231940157327784\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 55, Loss: 0.4328, Loss Cls: 0.4328, Train: 63.35%, Valid: 60.48%, Test: 61.92%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6303456704555009\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 56, Loss: 0.4288, Loss Cls: 0.4288, Train: 60.19%, Valid: 57.62%, Test: 58.98%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.63278402859776\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 57, Loss: 0.4213, Loss Cls: 0.4213, Train: 65.11%, Valid: 62.11%, Test: 63.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6443751333324033\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 58, Loss: 0.4172, Loss Cls: 0.4172, Train: 59.66%, Valid: 57.07%, Test: 58.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6360759982096279\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 59, Loss: 0.4201, Loss Cls: 0.4201, Train: 64.37%, Valid: 61.36%, Test: 62.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6369118306452709\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 60, Loss: 0.4235, Loss Cls: 0.4235, Train: 60.87%, Valid: 58.38%, Test: 59.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6401431247780196\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 61, Loss: 0.4209, Loss Cls: 0.4209, Train: 64.06%, Valid: 60.72%, Test: 62.16%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6437692692023893\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 62, Loss: 0.4113, Loss Cls: 0.4113, Train: 63.48%, Valid: 60.97%, Test: 62.43%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6578424233342152\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 63, Loss: 0.4099, Loss Cls: 0.4099, Train: 62.76%, Valid: 59.34%, Test: 60.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6442852373306586\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 64, Loss: 0.4094, Loss Cls: 0.4094, Train: 64.20%, Valid: 61.65%, Test: 63.18%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6577690132287424\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 65, Loss: 0.4122, Loss Cls: 0.4122, Train: 60.28%, Valid: 56.74%, Test: 58.29%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6422011705954553\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 66, Loss: 0.4086, Loss Cls: 0.4086, Train: 66.23%, Valid: 63.60%, Test: 65.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6592205102664493\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 67, Loss: 0.4093, Loss Cls: 0.4093, Train: 58.16%, Valid: 54.71%, Test: 56.41%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6529005949737064\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 68, Loss: 0.4075, Loss Cls: 0.4075, Train: 67.82%, Valid: 65.21%, Test: 66.63%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6493267000098828\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 69, Loss: 0.4132, Loss Cls: 0.4132, Train: 61.75%, Valid: 58.80%, Test: 60.38%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.664572282465167\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 70, Loss: 0.4064, Loss Cls: 0.4064, Train: 66.83%, Valid: 63.74%, Test: 65.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6551694977559189\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 71, Loss: 0.4010, Loss Cls: 0.4010, Train: 64.41%, Valid: 61.22%, Test: 62.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6794478658952318\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 72, Loss: 0.3948, Loss Cls: 0.3948, Train: 66.08%, Valid: 62.95%, Test: 64.53%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6612931216272743\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 73, Loss: 0.3951, Loss Cls: 0.3951, Train: 64.87%, Valid: 61.60%, Test: 63.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6825820174332223\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 74, Loss: 0.3949, Loss Cls: 0.3949, Train: 66.40%, Valid: 63.37%, Test: 64.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6598929797553083\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 75, Loss: 0.3967, Loss Cls: 0.3967, Train: 65.18%, Valid: 61.84%, Test: 63.65%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6855975893894682\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 76, Loss: 0.3927, Loss Cls: 0.3927, Train: 67.40%, Valid: 64.38%, Test: 65.93%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6632291458047752\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 77, Loss: 0.3917, Loss Cls: 0.3917, Train: 65.16%, Valid: 61.69%, Test: 63.60%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6879053869282898\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 78, Loss: 0.3902, Loss Cls: 0.3902, Train: 68.08%, Valid: 65.09%, Test: 66.70%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6664611394153698\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 79, Loss: 0.3870, Loss Cls: 0.3870, Train: 66.50%, Valid: 63.14%, Test: 64.97%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6978413703681985\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 80, Loss: 0.3810, Loss Cls: 0.3810, Train: 68.22%, Valid: 65.12%, Test: 66.73%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6777243319346443\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 81, Loss: 0.3779, Loss Cls: 0.3779, Train: 67.52%, Valid: 64.12%, Test: 65.94%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7034926088115184\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 82, Loss: 0.3766, Loss Cls: 0.3766, Train: 67.88%, Valid: 64.71%, Test: 66.36%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6791006301646136\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 83, Loss: 0.3787, Loss Cls: 0.3787, Train: 67.86%, Valid: 64.57%, Test: 66.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7000177551659462\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 84, Loss: 0.3795, Loss Cls: 0.3795, Train: 66.96%, Valid: 63.78%, Test: 65.43%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6762761649889985\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 85, Loss: 0.3822, Loss Cls: 0.3822, Train: 68.94%, Valid: 65.78%, Test: 67.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6984393096748408\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 86, Loss: 0.3798, Loss Cls: 0.3798, Train: 65.56%, Valid: 62.22%, Test: 63.95%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6819149195580434\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 87, Loss: 0.3789, Loss Cls: 0.3789, Train: 69.15%, Valid: 65.99%, Test: 67.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6980681477413551\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 88, Loss: 0.3756, Loss Cls: 0.3756, Train: 65.21%, Valid: 61.69%, Test: 63.42%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6872106374559006\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 89, Loss: 0.3765, Loss Cls: 0.3765, Train: 69.02%, Valid: 65.86%, Test: 67.68%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6974627989819191\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 90, Loss: 0.3734, Loss Cls: 0.3734, Train: 67.12%, Valid: 63.54%, Test: 65.35%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.693926775343002\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 91, Loss: 0.3719, Loss Cls: 0.3719, Train: 69.17%, Valid: 65.99%, Test: 67.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7015131718126082\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 92, Loss: 0.3696, Loss Cls: 0.3696, Train: 69.82%, Valid: 66.58%, Test: 68.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.6974507057773505\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 93, Loss: 0.3693, Loss Cls: 0.3693, Train: 67.65%, Valid: 64.17%, Test: 66.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7024462214102288\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 94, Loss: 0.3695, Loss Cls: 0.3695, Train: 71.30%, Valid: 68.21%, Test: 69.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7007842900957867\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 95, Loss: 0.3676, Loss Cls: 0.3676, Train: 67.56%, Valid: 64.03%, Test: 66.00%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7050095648133421\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 96, Loss: 0.3665, Loss Cls: 0.3665, Train: 70.72%, Valid: 67.54%, Test: 69.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7042462892106439\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 97, Loss: 0.3653, Loss Cls: 0.3653, Train: 68.29%, Valid: 64.91%, Test: 66.71%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7036600193426412\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 98, Loss: 0.3660, Loss Cls: 0.3660, Train: 70.53%, Valid: 67.18%, Test: 69.08%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7080474637365956\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 99, Loss: 0.3637, Loss Cls: 0.3637, Train: 69.92%, Valid: 66.63%, Test: 68.40%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.70573013123543\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 100, Loss: 0.3620, Loss Cls: 0.3620, Train: 69.51%, Valid: 65.99%, Test: 67.97%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7151774793352874\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 101, Loss: 0.3598, Loss Cls: 0.3598, Train: 71.97%, Valid: 68.91%, Test: 70.65%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7030367364742247\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 102, Loss: 0.3608, Loss Cls: 0.3608, Train: 67.87%, Valid: 64.09%, Test: 66.17%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7217206949524856\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 103, Loss: 0.3587, Loss Cls: 0.3587, Train: 72.50%, Valid: 69.45%, Test: 71.28%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7020351857665217\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 104, Loss: 0.3573, Loss Cls: 0.3573, Train: 69.04%, Valid: 65.26%, Test: 67.40%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7309255820862853\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 105, Loss: 0.3538, Loss Cls: 0.3538, Train: 72.06%, Valid: 68.77%, Test: 70.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7025748522670638\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 106, Loss: 0.3559, Loss Cls: 0.3559, Train: 71.07%, Valid: 67.63%, Test: 69.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7298722610041546\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 107, Loss: 0.3548, Loss Cls: 0.3548, Train: 70.91%, Valid: 67.26%, Test: 69.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7065404360608931\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 108, Loss: 0.3546, Loss Cls: 0.3546, Train: 72.90%, Valid: 69.77%, Test: 71.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7349006959069536\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 109, Loss: 0.3478, Loss Cls: 0.3478, Train: 70.56%, Valid: 66.74%, Test: 68.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7148094645620467\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 110, Loss: 0.3473, Loss Cls: 0.3473, Train: 73.73%, Valid: 70.80%, Test: 72.46%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7363375238165158\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 111, Loss: 0.3477, Loss Cls: 0.3477, Train: 69.38%, Valid: 65.43%, Test: 67.76%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7142143648045126\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 112, Loss: 0.3496, Loss Cls: 0.3496, Train: 73.64%, Valid: 70.80%, Test: 72.44%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7353028284427839\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 113, Loss: 0.3480, Loss Cls: 0.3480, Train: 70.37%, Valid: 66.53%, Test: 68.81%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7206810220007177\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 114, Loss: 0.3458, Loss Cls: 0.3458, Train: 73.06%, Valid: 70.23%, Test: 71.86%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7393569803976178\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 115, Loss: 0.3413, Loss Cls: 0.3413, Train: 72.41%, Valid: 68.84%, Test: 70.97%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.728080572458457\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 116, Loss: 0.3404, Loss Cls: 0.3404, Train: 72.46%, Valid: 69.38%, Test: 71.20%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7381328863627705\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 117, Loss: 0.3390, Loss Cls: 0.3390, Train: 72.39%, Valid: 68.96%, Test: 70.98%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7295331011372334\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 118, Loss: 0.3412, Loss Cls: 0.3412, Train: 71.96%, Valid: 68.76%, Test: 70.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7341642633066124\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 119, Loss: 0.3399, Loss Cls: 0.3399, Train: 72.07%, Valid: 68.71%, Test: 70.69%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7309147004493587\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 120, Loss: 0.3421, Loss Cls: 0.3421, Train: 71.79%, Valid: 68.53%, Test: 70.46%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.731305013855492\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 121, Loss: 0.3409, Loss Cls: 0.3409, Train: 72.35%, Valid: 68.98%, Test: 70.95%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7331189585168149\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 122, Loss: 0.3402, Loss Cls: 0.3402, Train: 72.40%, Valid: 69.15%, Test: 71.08%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7330121163263981\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 123, Loss: 0.3383, Loss Cls: 0.3383, Train: 73.52%, Valid: 70.15%, Test: 72.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7425332541675237\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 124, Loss: 0.3327, Loss Cls: 0.3327, Train: 73.49%, Valid: 70.17%, Test: 72.14%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7405185576745259\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 125, Loss: 0.3305, Loss Cls: 0.3305, Train: 74.19%, Valid: 70.79%, Test: 72.79%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7469516474672707\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 126, Loss: 0.3291, Loss Cls: 0.3291, Train: 73.84%, Valid: 70.48%, Test: 72.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7408011050804745\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 127, Loss: 0.3311, Loss Cls: 0.3311, Train: 74.09%, Valid: 70.67%, Test: 72.64%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7434000596623036\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 128, Loss: 0.3315, Loss Cls: 0.3315, Train: 73.83%, Valid: 70.50%, Test: 72.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7415338542206379\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 129, Loss: 0.3321, Loss Cls: 0.3321, Train: 73.89%, Valid: 70.48%, Test: 72.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7403498175854827\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 130, Loss: 0.3314, Loss Cls: 0.3314, Train: 73.81%, Valid: 70.62%, Test: 72.53%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7437952471667085\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 131, Loss: 0.3324, Loss Cls: 0.3324, Train: 73.82%, Valid: 70.34%, Test: 72.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7389974114647707\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 132, Loss: 0.3306, Loss Cls: 0.3306, Train: 74.08%, Valid: 70.76%, Test: 72.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7485049921771643\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 133, Loss: 0.3297, Loss Cls: 0.3297, Train: 74.40%, Valid: 70.94%, Test: 72.98%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.743237607009078\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 134, Loss: 0.3253, Loss Cls: 0.3253, Train: 74.39%, Valid: 70.95%, Test: 73.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7558884792063476\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 135, Loss: 0.3238, Loss Cls: 0.3238, Train: 75.02%, Valid: 71.66%, Test: 73.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.74788903407537\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 136, Loss: 0.3202, Loss Cls: 0.3202, Train: 74.60%, Valid: 71.21%, Test: 73.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7609386021206511\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 137, Loss: 0.3191, Loss Cls: 0.3191, Train: 75.36%, Valid: 72.01%, Test: 73.94%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.749939212939715\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 138, Loss: 0.3173, Loss Cls: 0.3173, Train: 75.02%, Valid: 71.63%, Test: 73.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7635283962045969\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 139, Loss: 0.3171, Loss Cls: 0.3171, Train: 75.31%, Valid: 71.93%, Test: 73.88%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7495994195462135\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 140, Loss: 0.3173, Loss Cls: 0.3173, Train: 75.53%, Valid: 72.19%, Test: 74.26%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7623479935191935\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 141, Loss: 0.3182, Loss Cls: 0.3182, Train: 74.99%, Valid: 71.62%, Test: 73.61%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7470796980662312\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 142, Loss: 0.3200, Loss Cls: 0.3200, Train: 75.75%, Valid: 72.35%, Test: 74.47%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7599502299502301\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 143, Loss: 0.3202, Loss Cls: 0.3202, Train: 74.75%, Valid: 71.44%, Test: 73.44%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7476868968237582\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 144, Loss: 0.3196, Loss Cls: 0.3196, Train: 76.08%, Valid: 72.63%, Test: 74.70%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.76130971366032\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 145, Loss: 0.3185, Loss Cls: 0.3185, Train: 74.79%, Valid: 71.51%, Test: 73.60%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7499047614025975\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 146, Loss: 0.3182, Loss Cls: 0.3182, Train: 75.75%, Valid: 72.22%, Test: 74.22%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7643104151764576\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 147, Loss: 0.3166, Loss Cls: 0.3166, Train: 75.58%, Valid: 72.30%, Test: 74.36%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7517548012056934\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 148, Loss: 0.3168, Loss Cls: 0.3168, Train: 74.42%, Valid: 70.82%, Test: 72.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7651127061349016\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 149, Loss: 0.3162, Loss Cls: 0.3162, Train: 76.40%, Valid: 73.16%, Test: 75.24%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7580161335761292\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 150, Loss: 0.3143, Loss Cls: 0.3143, Train: 74.28%, Valid: 70.77%, Test: 72.71%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7634356885587711\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 151, Loss: 0.3140, Loss Cls: 0.3140, Train: 76.77%, Valid: 73.49%, Test: 75.61%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7657553603009005\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 152, Loss: 0.3117, Loss Cls: 0.3117, Train: 74.45%, Valid: 70.91%, Test: 72.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7578659486969314\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 153, Loss: 0.3132, Loss Cls: 0.3132, Train: 76.80%, Valid: 73.50%, Test: 75.66%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7714556770336285\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 154, Loss: 0.3107, Loss Cls: 0.3107, Train: 75.27%, Valid: 71.79%, Test: 73.72%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7547967853788512\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 155, Loss: 0.3109, Loss Cls: 0.3109, Train: 76.68%, Valid: 73.26%, Test: 75.48%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7760170739005675\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 156, Loss: 0.3090, Loss Cls: 0.3090, Train: 76.73%, Valid: 73.44%, Test: 75.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7521279776136822\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 157, Loss: 0.3101, Loss Cls: 0.3101, Train: 76.12%, Valid: 72.52%, Test: 74.72%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7785769424966659\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 158, Loss: 0.3084, Loss Cls: 0.3084, Train: 76.87%, Valid: 73.59%, Test: 75.50%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7528829343002106\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 159, Loss: 0.3082, Loss Cls: 0.3082, Train: 75.98%, Valid: 72.29%, Test: 74.52%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7794339214051059\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 160, Loss: 0.3065, Loss Cls: 0.3065, Train: 77.25%, Valid: 74.00%, Test: 75.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7567801298138871\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 161, Loss: 0.3056, Loss Cls: 0.3056, Train: 75.82%, Valid: 72.06%, Test: 74.30%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7812011867196426\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 162, Loss: 0.3031, Loss Cls: 0.3031, Train: 77.68%, Valid: 74.44%, Test: 76.42%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7610211455546448\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 163, Loss: 0.3027, Loss Cls: 0.3027, Train: 75.68%, Valid: 71.95%, Test: 74.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.782736369784316\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 164, Loss: 0.3010, Loss Cls: 0.3010, Train: 77.92%, Valid: 74.67%, Test: 76.65%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7627590085534252\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 165, Loss: 0.3018, Loss Cls: 0.3018, Train: 75.56%, Valid: 71.90%, Test: 74.14%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7829687075201515\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 166, Loss: 0.3001, Loss Cls: 0.3001, Train: 78.34%, Valid: 75.15%, Test: 77.05%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7660270947001696\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 167, Loss: 0.3001, Loss Cls: 0.3001, Train: 75.57%, Valid: 71.86%, Test: 74.16%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7837978442038026\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 168, Loss: 0.2978, Loss Cls: 0.2978, Train: 78.65%, Valid: 75.46%, Test: 77.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7725147367728896\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 169, Loss: 0.2962, Loss Cls: 0.2962, Train: 76.23%, Valid: 72.50%, Test: 74.86%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7857088705352017\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 170, Loss: 0.2935, Loss Cls: 0.2935, Train: 78.70%, Valid: 75.50%, Test: 77.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7787888391783699\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 171, Loss: 0.2927, Loss Cls: 0.2927, Train: 76.65%, Valid: 73.04%, Test: 75.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7841714742173016\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 172, Loss: 0.2929, Loss Cls: 0.2929, Train: 78.21%, Valid: 74.99%, Test: 76.78%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.777819992555237\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 173, Loss: 0.2956, Loss Cls: 0.2956, Train: 76.29%, Valid: 72.63%, Test: 75.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7759470302341568\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 174, Loss: 0.2991, Loss Cls: 0.2991, Train: 77.51%, Valid: 74.21%, Test: 76.11%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.774170061243751\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 175, Loss: 0.3016, Loss Cls: 0.3016, Train: 76.04%, Valid: 72.46%, Test: 74.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7713060458312705\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 176, Loss: 0.3031, Loss Cls: 0.3031, Train: 77.56%, Valid: 74.10%, Test: 76.11%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.777706340532581\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 177, Loss: 0.2988, Loss Cls: 0.2988, Train: 76.31%, Valid: 72.61%, Test: 75.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7761131637420695\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 178, Loss: 0.2963, Loss Cls: 0.2963, Train: 78.56%, Valid: 75.14%, Test: 77.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7853252077562327\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 179, Loss: 0.2916, Loss Cls: 0.2916, Train: 76.40%, Valid: 72.57%, Test: 74.93%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7805082649585763\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 180, Loss: 0.2909, Loss Cls: 0.2909, Train: 79.19%, Valid: 75.90%, Test: 77.92%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.787719059240465\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 181, Loss: 0.2894, Loss Cls: 0.2894, Train: 75.84%, Valid: 71.93%, Test: 74.23%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7805578284946493\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 182, Loss: 0.2906, Loss Cls: 0.2906, Train: 79.17%, Valid: 75.94%, Test: 77.93%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7865682186718368\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 183, Loss: 0.2899, Loss Cls: 0.2899, Train: 75.49%, Valid: 71.52%, Test: 73.88%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7821640152556241\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 184, Loss: 0.2896, Loss Cls: 0.2896, Train: 79.26%, Valid: 76.01%, Test: 78.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7881598832334124\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 185, Loss: 0.2873, Loss Cls: 0.2873, Train: 76.10%, Valid: 72.11%, Test: 74.48%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7868692249053498\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 186, Loss: 0.2860, Loss Cls: 0.2860, Train: 79.50%, Valid: 76.36%, Test: 78.27%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7895325698693277\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 187, Loss: 0.2847, Loss Cls: 0.2847, Train: 76.70%, Valid: 72.78%, Test: 75.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7892782467452408\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 188, Loss: 0.2855, Loss Cls: 0.2855, Train: 79.28%, Valid: 76.20%, Test: 78.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7846014548711929\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 189, Loss: 0.2875, Loss Cls: 0.2875, Train: 76.55%, Valid: 72.62%, Test: 74.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7881773245281288\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 190, Loss: 0.2894, Loss Cls: 0.2894, Train: 78.94%, Valid: 75.81%, Test: 77.76%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7788942598855503\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 191, Loss: 0.2907, Loss Cls: 0.2907, Train: 77.17%, Valid: 73.24%, Test: 75.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7926087097717015\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 192, Loss: 0.2881, Loss Cls: 0.2881, Train: 78.98%, Valid: 75.71%, Test: 77.78%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7820213983044616\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 193, Loss: 0.2859, Loss Cls: 0.2859, Train: 78.37%, Valid: 74.63%, Test: 76.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7983872136661253\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 194, Loss: 0.2836, Loss Cls: 0.2836, Train: 78.66%, Valid: 75.29%, Test: 77.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7830320642591262\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 195, Loss: 0.2848, Loss Cls: 0.2848, Train: 78.73%, Valid: 75.11%, Test: 77.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7968062043982338\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 196, Loss: 0.2848, Loss Cls: 0.2848, Train: 78.49%, Valid: 75.06%, Test: 77.22%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7807467258984054\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 197, Loss: 0.2860, Loss Cls: 0.2860, Train: 78.86%, Valid: 75.36%, Test: 77.43%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.796632667124845\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 198, Loss: 0.2843, Loss Cls: 0.2843, Train: 79.06%, Valid: 75.65%, Test: 77.83%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7834672469189868\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 199, Loss: 0.2830, Loss Cls: 0.2830, Train: 79.33%, Valid: 75.81%, Test: 77.94%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8029626184681933\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 200, Loss: 0.2782, Loss Cls: 0.2782, Train: 79.98%, Valid: 76.70%, Test: 78.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7905790768993812\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 201, Loss: 0.2763, Loss Cls: 0.2763, Train: 79.68%, Valid: 76.28%, Test: 78.30%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8086373212107771\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 202, Loss: 0.2733, Loss Cls: 0.2733, Train: 80.41%, Valid: 77.18%, Test: 79.25%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7932591915740547\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 203, Loss: 0.2738, Loss Cls: 0.2738, Train: 79.47%, Valid: 76.07%, Test: 78.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8084227667255549\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 204, Loss: 0.2739, Loss Cls: 0.2739, Train: 80.00%, Valid: 76.73%, Test: 78.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7881091205546191\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 205, Loss: 0.2782, Loss Cls: 0.2782, Train: 78.87%, Valid: 75.45%, Test: 77.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8028843439909091\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 206, Loss: 0.2794, Loss Cls: 0.2794, Train: 79.17%, Valid: 75.77%, Test: 77.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7836052847410006\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 207, Loss: 0.2838, Loss Cls: 0.2838, Train: 78.95%, Valid: 75.60%, Test: 77.74%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8010223688795215\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 208, Loss: 0.2796, Loss Cls: 0.2796, Train: 79.28%, Valid: 75.69%, Test: 77.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7911047520767164\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 209, Loss: 0.2780, Loss Cls: 0.2780, Train: 79.83%, Valid: 76.49%, Test: 78.61%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8064613427477897\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 210, Loss: 0.2718, Loss Cls: 0.2718, Train: 79.94%, Valid: 76.33%, Test: 78.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8003702626050755\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 211, Loss: 0.2703, Loss Cls: 0.2703, Train: 80.09%, Valid: 76.73%, Test: 78.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8082417673973182\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 212, Loss: 0.2687, Loss Cls: 0.2687, Train: 80.26%, Valid: 76.79%, Test: 78.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8023144504243869\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 213, Loss: 0.2701, Loss Cls: 0.2701, Train: 79.41%, Valid: 76.03%, Test: 78.21%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8050913648989979\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 214, Loss: 0.2709, Loss Cls: 0.2709, Train: 80.30%, Valid: 76.90%, Test: 79.00%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8004166057455135\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 215, Loss: 0.2729, Loss Cls: 0.2729, Train: 78.59%, Valid: 75.14%, Test: 77.43%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.802489689034576\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 216, Loss: 0.2731, Loss Cls: 0.2731, Train: 80.49%, Valid: 77.05%, Test: 79.19%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8000005065338113\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 217, Loss: 0.2735, Loss Cls: 0.2735, Train: 78.40%, Valid: 75.01%, Test: 77.28%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8026368851384731\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 218, Loss: 0.2721, Loss Cls: 0.2721, Train: 80.77%, Valid: 77.26%, Test: 79.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8031201532418156\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 219, Loss: 0.2705, Loss Cls: 0.2705, Train: 79.31%, Valid: 75.96%, Test: 78.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8062514363060878\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 220, Loss: 0.2678, Loss Cls: 0.2678, Train: 80.92%, Valid: 77.35%, Test: 79.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.807973622897543\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 221, Loss: 0.2658, Loss Cls: 0.2658, Train: 80.04%, Valid: 76.77%, Test: 78.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8070159825159844\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 222, Loss: 0.2649, Loss Cls: 0.2649, Train: 80.34%, Valid: 76.60%, Test: 78.93%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8095406798354055\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 223, Loss: 0.2657, Loss Cls: 0.2657, Train: 80.07%, Valid: 76.80%, Test: 78.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8027789499778143\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 224, Loss: 0.2665, Loss Cls: 0.2665, Train: 79.14%, Valid: 75.26%, Test: 77.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8075489369439832\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 225, Loss: 0.2691, Loss Cls: 0.2691, Train: 79.72%, Valid: 76.40%, Test: 78.50%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7991970503106156\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 226, Loss: 0.2695, Loss Cls: 0.2695, Train: 78.09%, Valid: 74.20%, Test: 76.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8064541408452104\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 227, Loss: 0.2715, Loss Cls: 0.2715, Train: 79.82%, Valid: 76.43%, Test: 78.58%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8001489998528515\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 228, Loss: 0.2692, Loss Cls: 0.2692, Train: 78.21%, Valid: 74.33%, Test: 76.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8108201275902677\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 229, Loss: 0.2681, Loss Cls: 0.2681, Train: 80.98%, Valid: 77.68%, Test: 79.76%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8066571966306789\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 230, Loss: 0.2628, Loss Cls: 0.2628, Train: 79.41%, Valid: 75.60%, Test: 78.08%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8179302093174079\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 231, Loss: 0.2608, Loss Cls: 0.2608, Train: 81.82%, Valid: 78.58%, Test: 80.58%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8098232657950118\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 232, Loss: 0.2586, Loss Cls: 0.2586, Train: 79.98%, Valid: 76.19%, Test: 78.70%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.819781290685521\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 233, Loss: 0.2592, Loss Cls: 0.2592, Train: 81.98%, Valid: 78.70%, Test: 80.76%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8066691355688845\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 234, Loss: 0.2600, Loss Cls: 0.2600, Train: 79.98%, Valid: 76.21%, Test: 78.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8184778275675656\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 235, Loss: 0.2613, Loss Cls: 0.2613, Train: 81.79%, Valid: 78.56%, Test: 80.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8013187306972829\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 236, Loss: 0.2630, Loss Cls: 0.2630, Train: 80.00%, Valid: 76.23%, Test: 78.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8173000285454043\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 237, Loss: 0.2643, Loss Cls: 0.2643, Train: 81.18%, Valid: 77.97%, Test: 80.00%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7948104124576937\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 238, Loss: 0.2670, Loss Cls: 0.2670, Train: 79.90%, Valid: 76.11%, Test: 78.40%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8144570898683157\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 239, Loss: 0.2692, Loss Cls: 0.2692, Train: 80.30%, Valid: 76.89%, Test: 79.04%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7887595768161464\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 240, Loss: 0.2716, Loss Cls: 0.2716, Train: 80.35%, Valid: 76.74%, Test: 78.93%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8140266034753815\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 241, Loss: 0.2703, Loss Cls: 0.2703, Train: 80.00%, Valid: 76.40%, Test: 78.66%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.7954575291675609\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 242, Loss: 0.2656, Loss Cls: 0.2656, Train: 81.60%, Valid: 78.22%, Test: 80.27%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8227110115565495\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 243, Loss: 0.2593, Loss Cls: 0.2593, Train: 80.17%, Valid: 76.49%, Test: 78.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8083617104872736\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 244, Loss: 0.2552, Loss Cls: 0.2552, Train: 82.09%, Valid: 78.83%, Test: 80.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8271581752164647\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 245, Loss: 0.2531, Loss Cls: 0.2531, Train: 79.59%, Valid: 75.79%, Test: 78.05%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8132696306552145\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 246, Loss: 0.2524, Loss Cls: 0.2524, Train: 81.92%, Valid: 78.65%, Test: 80.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.826495815762622\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 247, Loss: 0.2530, Loss Cls: 0.2530, Train: 78.28%, Valid: 74.14%, Test: 76.63%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.811345045506816\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 248, Loss: 0.2548, Loss Cls: 0.2548, Train: 81.77%, Valid: 78.48%, Test: 80.52%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8235086131218352\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 249, Loss: 0.2567, Loss Cls: 0.2567, Train: 76.77%, Valid: 72.33%, Test: 74.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8062520212115191\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 250, Loss: 0.2598, Loss Cls: 0.2598, Train: 81.76%, Valid: 78.51%, Test: 80.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8211917072497067\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 251, Loss: 0.2595, Loss Cls: 0.2595, Train: 76.47%, Valid: 71.93%, Test: 74.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.805261475607995\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 252, Loss: 0.2609, Loss Cls: 0.2609, Train: 81.98%, Valid: 78.72%, Test: 80.84%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8224812178732793\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 253, Loss: 0.2572, Loss Cls: 0.2572, Train: 77.81%, Valid: 73.53%, Test: 76.11%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8105764042695367\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 254, Loss: 0.2561, Loss Cls: 0.2561, Train: 82.38%, Valid: 79.14%, Test: 81.26%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8268516762800713\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 255, Loss: 0.2518, Loss Cls: 0.2518, Train: 79.28%, Valid: 75.21%, Test: 77.72%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8173028700775059\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 256, Loss: 0.2498, Loss Cls: 0.2498, Train: 82.90%, Valid: 79.65%, Test: 81.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8317579726105155\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 257, Loss: 0.2465, Loss Cls: 0.2465, Train: 80.21%, Valid: 76.19%, Test: 78.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.821857065909392\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 258, Loss: 0.2456, Loss Cls: 0.2456, Train: 83.02%, Valid: 79.81%, Test: 81.89%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.83340798397854\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 259, Loss: 0.2445, Loss Cls: 0.2445, Train: 80.24%, Valid: 76.22%, Test: 78.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8219252547261233\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 260, Loss: 0.2458, Loss Cls: 0.2458, Train: 82.62%, Valid: 79.36%, Test: 81.41%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.830018752520397\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 261, Loss: 0.2474, Loss Cls: 0.2474, Train: 79.35%, Valid: 75.24%, Test: 77.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8155003791114395\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 262, Loss: 0.2520, Loss Cls: 0.2520, Train: 81.89%, Valid: 78.60%, Test: 80.66%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8214691663747832\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 263, Loss: 0.2550, Loss Cls: 0.2550, Train: 78.49%, Valid: 74.48%, Test: 77.05%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8082161905330587\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 264, Loss: 0.2602, Loss Cls: 0.2602, Train: 81.86%, Valid: 78.65%, Test: 80.65%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.818305659280377\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 265, Loss: 0.2571, Loss Cls: 0.2571, Train: 79.64%, Valid: 75.66%, Test: 78.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8141412441309708\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 266, Loss: 0.2554, Loss Cls: 0.2554, Train: 82.44%, Valid: 79.24%, Test: 81.28%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8234336130922707\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 267, Loss: 0.2499, Loss Cls: 0.2499, Train: 80.98%, Valid: 77.24%, Test: 79.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8217065003314007\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 268, Loss: 0.2489, Loss Cls: 0.2489, Train: 82.49%, Valid: 79.17%, Test: 81.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8236872625387228\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 269, Loss: 0.2473, Loss Cls: 0.2473, Train: 81.09%, Valid: 77.51%, Test: 79.81%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8231680539737303\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 270, Loss: 0.2485, Loss Cls: 0.2485, Train: 82.31%, Valid: 78.97%, Test: 81.13%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8207633678263059\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 271, Loss: 0.2485, Loss Cls: 0.2485, Train: 81.38%, Valid: 77.94%, Test: 80.14%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8239845572915617\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 272, Loss: 0.2491, Loss Cls: 0.2491, Train: 82.11%, Valid: 78.67%, Test: 80.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8202799486694249\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 273, Loss: 0.2479, Loss Cls: 0.2479, Train: 82.11%, Valid: 78.79%, Test: 80.98%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8278225073334831\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 274, Loss: 0.2461, Loss Cls: 0.2461, Train: 81.85%, Valid: 78.42%, Test: 80.64%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8222471734377215\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 275, Loss: 0.2450, Loss Cls: 0.2450, Train: 82.57%, Valid: 79.27%, Test: 81.44%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8303048423933511\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 276, Loss: 0.2439, Loss Cls: 0.2439, Train: 81.38%, Valid: 77.90%, Test: 80.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.82263205277909\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 277, Loss: 0.2442, Loss Cls: 0.2442, Train: 82.79%, Valid: 79.50%, Test: 81.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8320531729579427\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 278, Loss: 0.2428, Loss Cls: 0.2428, Train: 81.15%, Valid: 77.56%, Test: 79.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8247648133452132\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 279, Loss: 0.2417, Loss Cls: 0.2417, Train: 83.13%, Valid: 79.86%, Test: 81.99%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8354579317211616\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 280, Loss: 0.2397, Loss Cls: 0.2397, Train: 80.79%, Valid: 77.17%, Test: 79.50%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8269239943591625\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 281, Loss: 0.2393, Loss Cls: 0.2393, Train: 83.11%, Valid: 79.86%, Test: 81.97%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8362576014969101\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 282, Loss: 0.2390, Loss Cls: 0.2390, Train: 79.79%, Valid: 76.10%, Test: 78.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8262155932487634\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 283, Loss: 0.2404, Loss Cls: 0.2404, Train: 82.67%, Valid: 79.41%, Test: 81.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8342518739336903\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 284, Loss: 0.2409, Loss Cls: 0.2409, Train: 78.87%, Valid: 75.18%, Test: 77.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8243469140045836\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 285, Loss: 0.2429, Loss Cls: 0.2429, Train: 82.50%, Valid: 79.28%, Test: 81.41%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8313022275529495\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 286, Loss: 0.2430, Loss Cls: 0.2430, Train: 79.14%, Valid: 75.44%, Test: 77.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8228144320640592\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 287, Loss: 0.2451, Loss Cls: 0.2451, Train: 82.97%, Valid: 79.79%, Test: 81.89%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8298474930711002\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 288, Loss: 0.2435, Loss Cls: 0.2435, Train: 80.70%, Valid: 77.11%, Test: 79.44%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8243973904533128\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 289, Loss: 0.2439, Loss Cls: 0.2439, Train: 83.57%, Valid: 80.34%, Test: 82.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8307345069047701\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 290, Loss: 0.2415, Loss Cls: 0.2415, Train: 81.98%, Valid: 78.50%, Test: 80.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8271424958812602\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 291, Loss: 0.2423, Loss Cls: 0.2423, Train: 83.25%, Valid: 79.99%, Test: 82.13%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8282485727426337\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 292, Loss: 0.2428, Loss Cls: 0.2428, Train: 82.07%, Valid: 78.54%, Test: 80.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8259644277120669\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 293, Loss: 0.2457, Loss Cls: 0.2457, Train: 82.22%, Valid: 78.78%, Test: 81.01%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.822141179001192\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 294, Loss: 0.2478, Loss Cls: 0.2478, Train: 81.89%, Valid: 78.26%, Test: 80.40%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8258799645572497\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 295, Loss: 0.2481, Loss Cls: 0.2481, Train: 82.08%, Valid: 78.61%, Test: 80.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8211885505685766\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 296, Loss: 0.2468, Loss Cls: 0.2468, Train: 82.49%, Valid: 78.81%, Test: 81.09%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8329441836007725\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 297, Loss: 0.2415, Loss Cls: 0.2415, Train: 82.89%, Valid: 79.51%, Test: 81.71%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8282091151976653\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 298, Loss: 0.2378, Loss Cls: 0.2378, Train: 83.35%, Valid: 79.74%, Test: 82.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8405633578748186\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 299, Loss: 0.2341, Loss Cls: 0.2341, Train: 83.54%, Valid: 80.21%, Test: 82.37%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8323508591409675\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 300, Loss: 0.2331, Loss Cls: 0.2331, Train: 83.59%, Valid: 80.04%, Test: 82.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8422231317617306\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 301, Loss: 0.2328, Loss Cls: 0.2328, Train: 83.60%, Valid: 80.31%, Test: 82.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8307166917183723\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 302, Loss: 0.2339, Loss Cls: 0.2339, Train: 83.47%, Valid: 79.90%, Test: 82.22%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8411571734806744\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 303, Loss: 0.2343, Loss Cls: 0.2343, Train: 83.51%, Valid: 80.24%, Test: 82.36%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8287200851105753\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 304, Loss: 0.2350, Loss Cls: 0.2350, Train: 83.27%, Valid: 79.65%, Test: 82.04%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8406088454036992\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 305, Loss: 0.2342, Loss Cls: 0.2342, Train: 83.61%, Valid: 80.33%, Test: 82.44%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8291496660727982\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 306, Loss: 0.2344, Loss Cls: 0.2344, Train: 82.86%, Valid: 79.21%, Test: 81.61%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8400455369021377\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 307, Loss: 0.2342, Loss Cls: 0.2342, Train: 83.42%, Valid: 80.12%, Test: 82.20%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8292728794575267\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 308, Loss: 0.2355, Loss Cls: 0.2355, Train: 82.09%, Valid: 78.28%, Test: 80.78%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8375158496561743\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 309, Loss: 0.2360, Loss Cls: 0.2360, Train: 83.11%, Valid: 79.81%, Test: 81.93%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8289115177591195\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 310, Loss: 0.2370, Loss Cls: 0.2370, Train: 81.54%, Valid: 77.61%, Test: 80.20%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.836355508350892\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 311, Loss: 0.2370, Loss Cls: 0.2370, Train: 83.33%, Valid: 80.07%, Test: 82.21%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8299127313845884\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 312, Loss: 0.2367, Loss Cls: 0.2367, Train: 81.19%, Valid: 77.18%, Test: 79.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8363443259892914\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 313, Loss: 0.2371, Loss Cls: 0.2371, Train: 83.64%, Valid: 80.43%, Test: 82.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8311920105511499\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 314, Loss: 0.2359, Loss Cls: 0.2359, Train: 81.12%, Valid: 77.06%, Test: 79.72%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8371677202569268\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 315, Loss: 0.2355, Loss Cls: 0.2355, Train: 84.06%, Valid: 80.88%, Test: 82.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8345736357486625\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 316, Loss: 0.2324, Loss Cls: 0.2324, Train: 81.58%, Valid: 77.64%, Test: 80.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8410473212336906\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 317, Loss: 0.2306, Loss Cls: 0.2306, Train: 84.48%, Valid: 81.30%, Test: 83.36%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8397381769364037\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 318, Loss: 0.2276, Loss Cls: 0.2276, Train: 82.37%, Valid: 78.50%, Test: 80.97%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.845406846954272\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 319, Loss: 0.2261, Loss Cls: 0.2261, Train: 84.67%, Valid: 81.51%, Test: 83.60%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8431869471030736\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 320, Loss: 0.2245, Loss Cls: 0.2245, Train: 82.93%, Valid: 79.22%, Test: 81.53%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8476017405923948\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 321, Loss: 0.2238, Loss Cls: 0.2238, Train: 84.58%, Valid: 81.42%, Test: 83.53%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8441585451136535\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 322, Loss: 0.2235, Loss Cls: 0.2235, Train: 83.18%, Valid: 79.55%, Test: 81.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8478687467262062\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 323, Loss: 0.2235, Loss Cls: 0.2235, Train: 84.15%, Valid: 80.95%, Test: 83.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8426161525146569\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 324, Loss: 0.2246, Loss Cls: 0.2246, Train: 83.21%, Valid: 79.61%, Test: 81.83%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8467457493832757\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 325, Loss: 0.2251, Loss Cls: 0.2251, Train: 83.59%, Valid: 80.29%, Test: 82.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8390895948958516\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 326, Loss: 0.2269, Loss Cls: 0.2269, Train: 83.26%, Valid: 79.81%, Test: 81.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8454238057664459\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 327, Loss: 0.2276, Loss Cls: 0.2276, Train: 83.02%, Valid: 79.49%, Test: 81.91%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8354215135180851\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 328, Loss: 0.2288, Loss Cls: 0.2288, Train: 83.44%, Valid: 80.11%, Test: 82.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8452526824719869\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 329, Loss: 0.2292, Loss Cls: 0.2292, Train: 82.68%, Valid: 78.98%, Test: 81.49%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8346489221536431\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 330, Loss: 0.2286, Loss Cls: 0.2286, Train: 83.62%, Valid: 80.42%, Test: 82.38%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8460370027175582\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 331, Loss: 0.2287, Loss Cls: 0.2287, Train: 82.66%, Valid: 78.88%, Test: 81.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8356383576090117\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 332, Loss: 0.2282, Loss Cls: 0.2282, Train: 83.53%, Valid: 80.26%, Test: 82.25%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8456821990149118\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 333, Loss: 0.2286, Loss Cls: 0.2286, Train: 82.75%, Valid: 78.93%, Test: 81.42%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8370224902560117\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 334, Loss: 0.2275, Loss Cls: 0.2275, Train: 83.31%, Valid: 79.92%, Test: 82.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8460009900782998\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 335, Loss: 0.2273, Loss Cls: 0.2273, Train: 83.12%, Valid: 79.33%, Test: 81.78%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.840054948199874\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 336, Loss: 0.2250, Loss Cls: 0.2250, Train: 83.40%, Valid: 79.90%, Test: 82.07%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8479885572557899\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 337, Loss: 0.2243, Loss Cls: 0.2243, Train: 83.96%, Valid: 80.33%, Test: 82.66%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.844994067068172\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 338, Loss: 0.2212, Loss Cls: 0.2212, Train: 83.61%, Valid: 80.05%, Test: 82.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8504199729192419\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 339, Loss: 0.2206, Loss Cls: 0.2206, Train: 84.59%, Valid: 81.11%, Test: 83.29%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8490798513198135\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 340, Loss: 0.2189, Loss Cls: 0.2189, Train: 83.38%, Valid: 79.65%, Test: 82.00%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.849744285953395\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 341, Loss: 0.2199, Loss Cls: 0.2199, Train: 84.35%, Valid: 80.96%, Test: 83.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8495808501693909\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 342, Loss: 0.2203, Loss Cls: 0.2203, Train: 82.37%, Valid: 78.47%, Test: 80.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8432080439184074\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 343, Loss: 0.2242, Loss Cls: 0.2242, Train: 83.36%, Valid: 79.97%, Test: 82.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8457547541238789\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 344, Loss: 0.2272, Loss Cls: 0.2272, Train: 80.84%, Valid: 76.79%, Test: 79.21%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8305347877730074\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 345, Loss: 0.2341, Loss Cls: 0.2341, Train: 82.35%, Valid: 78.93%, Test: 81.19%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.841095783269743\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 346, Loss: 0.2358, Loss Cls: 0.2358, Train: 80.20%, Valid: 76.19%, Test: 78.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8234542125196803\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 347, Loss: 0.2383, Loss Cls: 0.2383, Train: 82.63%, Valid: 79.26%, Test: 81.47%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8457252171460082\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 348, Loss: 0.2318, Loss Cls: 0.2318, Train: 81.45%, Valid: 77.55%, Test: 79.92%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8309798862389347\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 349, Loss: 0.2281, Loss Cls: 0.2281, Train: 84.12%, Valid: 80.86%, Test: 83.01%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8540502598221572\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 350, Loss: 0.2223, Loss Cls: 0.2223, Train: 82.54%, Valid: 78.72%, Test: 81.11%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8392081986217578\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 351, Loss: 0.2204, Loss Cls: 0.2204, Train: 85.04%, Valid: 81.91%, Test: 84.00%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8576589340951912\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 352, Loss: 0.2183, Loss Cls: 0.2183, Train: 82.59%, Valid: 78.77%, Test: 81.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8413800342052936\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 353, Loss: 0.2188, Loss Cls: 0.2188, Train: 85.19%, Valid: 82.14%, Test: 84.09%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8566528825321785\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 354, Loss: 0.2187, Loss Cls: 0.2187, Train: 82.30%, Valid: 78.50%, Test: 80.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8410648507018073\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 355, Loss: 0.2207, Loss Cls: 0.2207, Train: 85.19%, Valid: 82.05%, Test: 84.05%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8547837328335108\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 356, Loss: 0.2193, Loss Cls: 0.2193, Train: 82.51%, Valid: 78.71%, Test: 81.17%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8431520856807471\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 357, Loss: 0.2206, Loss Cls: 0.2206, Train: 85.38%, Valid: 82.21%, Test: 84.20%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8549983224560942\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 358, Loss: 0.2170, Loss Cls: 0.2170, Train: 83.20%, Valid: 79.37%, Test: 81.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8474448913613143\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 359, Loss: 0.2181, Loss Cls: 0.2181, Train: 85.55%, Valid: 82.38%, Test: 84.42%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8561583154267478\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 360, Loss: 0.2146, Loss Cls: 0.2146, Train: 83.67%, Valid: 79.84%, Test: 82.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8513027704847196\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 361, Loss: 0.2154, Loss Cls: 0.2154, Train: 85.53%, Valid: 82.33%, Test: 84.36%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8557780949282221\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 362, Loss: 0.2136, Loss Cls: 0.2136, Train: 83.67%, Valid: 79.75%, Test: 82.27%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8532052002069729\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 363, Loss: 0.2144, Loss Cls: 0.2144, Train: 85.23%, Valid: 82.04%, Test: 84.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8533187440161004\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 364, Loss: 0.2147, Loss Cls: 0.2147, Train: 82.99%, Valid: 78.91%, Test: 81.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8524728510354165\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 365, Loss: 0.2163, Loss Cls: 0.2163, Train: 84.65%, Valid: 81.44%, Test: 83.52%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8487759785259062\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 366, Loss: 0.2179, Loss Cls: 0.2179, Train: 81.92%, Valid: 77.60%, Test: 80.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.850492138440122\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 367, Loss: 0.2195, Loss Cls: 0.2195, Train: 84.35%, Valid: 81.16%, Test: 83.25%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8450881845313851\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 368, Loss: 0.2201, Loss Cls: 0.2201, Train: 81.75%, Valid: 77.33%, Test: 80.16%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8510956972958169\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 369, Loss: 0.2195, Loss Cls: 0.2195, Train: 84.90%, Valid: 81.80%, Test: 83.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8458021405708315\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 370, Loss: 0.2180, Loss Cls: 0.2180, Train: 82.71%, Valid: 78.48%, Test: 81.18%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8539446502909733\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 371, Loss: 0.2165, Loss Cls: 0.2165, Train: 85.41%, Valid: 82.35%, Test: 84.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8479481664637449\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 372, Loss: 0.2157, Loss Cls: 0.2157, Train: 83.51%, Valid: 79.54%, Test: 82.13%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8557766449231669\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 373, Loss: 0.2146, Loss Cls: 0.2146, Train: 85.37%, Valid: 82.27%, Test: 84.28%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8491471670886499\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 374, Loss: 0.2147, Loss Cls: 0.2147, Train: 83.66%, Valid: 79.77%, Test: 82.37%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8566558183379207\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 375, Loss: 0.2137, Loss Cls: 0.2137, Train: 85.13%, Valid: 82.00%, Test: 84.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.849715785738373\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 376, Loss: 0.2140, Loss Cls: 0.2140, Train: 83.39%, Valid: 79.57%, Test: 82.09%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8571272580646145\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 377, Loss: 0.2134, Loss Cls: 0.2134, Train: 85.01%, Valid: 81.81%, Test: 83.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8507255688683742\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 378, Loss: 0.2133, Loss Cls: 0.2133, Train: 83.13%, Valid: 79.38%, Test: 81.88%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8578604557912777\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 379, Loss: 0.2125, Loss Cls: 0.2125, Train: 85.05%, Valid: 81.79%, Test: 83.92%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8518514455745801\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 380, Loss: 0.2126, Loss Cls: 0.2126, Train: 82.92%, Valid: 79.30%, Test: 81.67%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8578872367417569\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 381, Loss: 0.2121, Loss Cls: 0.2121, Train: 84.98%, Valid: 81.70%, Test: 83.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8521207432272233\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 382, Loss: 0.2133, Loss Cls: 0.2133, Train: 82.77%, Valid: 79.24%, Test: 81.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8570430610779637\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 383, Loss: 0.2120, Loss Cls: 0.2120, Train: 84.94%, Valid: 81.56%, Test: 83.72%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8537162556245796\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 384, Loss: 0.2125, Loss Cls: 0.2125, Train: 82.98%, Valid: 79.46%, Test: 81.78%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8567448848734764\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 385, Loss: 0.2110, Loss Cls: 0.2110, Train: 84.98%, Valid: 81.56%, Test: 83.75%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8557424078804954\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 386, Loss: 0.2118, Loss Cls: 0.2118, Train: 83.12%, Valid: 79.62%, Test: 81.88%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8539639997919676\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 387, Loss: 0.2124, Loss Cls: 0.2124, Train: 84.69%, Valid: 81.25%, Test: 83.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8546536319674498\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 388, Loss: 0.2149, Loss Cls: 0.2149, Train: 82.97%, Valid: 79.41%, Test: 81.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8483529227393827\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 389, Loss: 0.2167, Loss Cls: 0.2167, Train: 84.22%, Valid: 80.72%, Test: 82.96%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8525346000729688\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 390, Loss: 0.2194, Loss Cls: 0.2194, Train: 83.08%, Valid: 79.47%, Test: 81.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8457286964683561\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 391, Loss: 0.2189, Loss Cls: 0.2189, Train: 84.60%, Valid: 81.08%, Test: 83.38%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8556754659326534\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 392, Loss: 0.2169, Loss Cls: 0.2169, Train: 83.90%, Valid: 80.35%, Test: 82.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8508635337453414\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 393, Loss: 0.2121, Loss Cls: 0.2121, Train: 85.64%, Valid: 82.26%, Test: 84.47%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8634329844290944\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 394, Loss: 0.2079, Loss Cls: 0.2079, Train: 84.65%, Valid: 81.11%, Test: 83.38%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8558707760271415\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 395, Loss: 0.2059, Loss Cls: 0.2059, Train: 85.96%, Valid: 82.67%, Test: 84.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8661371756807493\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 396, Loss: 0.2051, Loss Cls: 0.2051, Train: 84.60%, Valid: 80.97%, Test: 83.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8544479180449918\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 397, Loss: 0.2065, Loss Cls: 0.2065, Train: 85.61%, Valid: 82.31%, Test: 84.46%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8637539342019884\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 398, Loss: 0.2079, Loss Cls: 0.2079, Train: 84.00%, Valid: 80.28%, Test: 82.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8496226180073219\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 399, Loss: 0.2102, Loss Cls: 0.2102, Train: 84.99%, Valid: 81.71%, Test: 83.84%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.86029284317905\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 400, Loss: 0.2117, Loss Cls: 0.2117, Train: 83.52%, Valid: 79.71%, Test: 81.99%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8473428687938079\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 401, Loss: 0.2126, Loss Cls: 0.2126, Train: 84.72%, Valid: 81.50%, Test: 83.64%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.859565016163022\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 402, Loss: 0.2121, Loss Cls: 0.2121, Train: 83.82%, Valid: 80.02%, Test: 82.27%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8511265592756114\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 403, Loss: 0.2095, Loss Cls: 0.2095, Train: 85.22%, Valid: 82.05%, Test: 84.14%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.863444751225661\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 404, Loss: 0.2064, Loss Cls: 0.2064, Train: 84.82%, Valid: 81.18%, Test: 83.33%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8580865350071598\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 405, Loss: 0.2042, Loss Cls: 0.2042, Train: 85.66%, Valid: 82.47%, Test: 84.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.865186038015473\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 406, Loss: 0.2027, Loss Cls: 0.2027, Train: 85.34%, Valid: 81.80%, Test: 83.94%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.86100265578861\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 407, Loss: 0.2028, Loss Cls: 0.2028, Train: 85.45%, Valid: 82.21%, Test: 84.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8628818671957683\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 408, Loss: 0.2034, Loss Cls: 0.2034, Train: 85.25%, Valid: 81.81%, Test: 83.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8603353136956048\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 409, Loss: 0.2048, Loss Cls: 0.2048, Train: 84.78%, Valid: 81.39%, Test: 83.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8587705327120961\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 410, Loss: 0.2066, Loss Cls: 0.2066, Train: 84.77%, Valid: 81.45%, Test: 83.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.858794372560517\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 411, Loss: 0.2077, Loss Cls: 0.2077, Train: 84.06%, Valid: 80.51%, Test: 82.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8560546701329668\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 412, Loss: 0.2089, Loss Cls: 0.2089, Train: 84.67%, Valid: 81.42%, Test: 83.48%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8608664348928899\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 413, Loss: 0.2074, Loss Cls: 0.2074, Train: 83.94%, Valid: 80.25%, Test: 82.62%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8571575794217873\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 414, Loss: 0.2065, Loss Cls: 0.2065, Train: 85.12%, Valid: 81.92%, Test: 84.01%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8664293922224324\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 415, Loss: 0.2034, Loss Cls: 0.2034, Train: 84.11%, Valid: 80.30%, Test: 82.74%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8587156241453212\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 416, Loss: 0.2029, Loss Cls: 0.2029, Train: 85.47%, Valid: 82.17%, Test: 84.31%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8695979144439021\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 417, Loss: 0.2016, Loss Cls: 0.2016, Train: 83.49%, Valid: 79.55%, Test: 82.06%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8531072577243995\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 418, Loss: 0.2051, Loss Cls: 0.2051, Train: 85.06%, Valid: 81.67%, Test: 83.76%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.864268843916555\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 419, Loss: 0.2085, Loss Cls: 0.2085, Train: 81.92%, Valid: 77.84%, Test: 80.42%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8413428850216172\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 420, Loss: 0.2158, Loss Cls: 0.2158, Train: 84.51%, Valid: 81.01%, Test: 83.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8581307331905593\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 421, Loss: 0.2152, Loss Cls: 0.2152, Train: 81.87%, Valid: 77.84%, Test: 80.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8440403454845987\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 422, Loss: 0.2137, Loss Cls: 0.2137, Train: 84.94%, Valid: 81.42%, Test: 83.54%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8643724810932112\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 423, Loss: 0.2061, Loss Cls: 0.2061, Train: 83.80%, Valid: 80.09%, Test: 82.50%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8574013452260216\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 424, Loss: 0.2028, Loss Cls: 0.2028, Train: 85.49%, Valid: 81.97%, Test: 84.10%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.867751243214838\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 425, Loss: 0.2005, Loss Cls: 0.2005, Train: 85.04%, Valid: 81.55%, Test: 83.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8628085191238825\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 426, Loss: 0.2001, Loss Cls: 0.2001, Train: 85.70%, Valid: 82.13%, Test: 84.26%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8673267701154718\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 427, Loss: 0.1999, Loss Cls: 0.1999, Train: 85.66%, Valid: 82.31%, Test: 84.49%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8648368339763765\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 428, Loss: 0.1992, Loss Cls: 0.1992, Train: 85.90%, Valid: 82.30%, Test: 84.46%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8685049299602171\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 429, Loss: 0.1978, Loss Cls: 0.1978, Train: 86.31%, Valid: 83.08%, Test: 85.19%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8672266240111535\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 430, Loss: 0.1968, Loss Cls: 0.1968, Train: 86.02%, Valid: 82.39%, Test: 84.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8696314246934963\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 431, Loss: 0.1965, Loss Cls: 0.1965, Train: 86.54%, Valid: 83.28%, Test: 85.40%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8671877670898666\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 432, Loss: 0.1978, Loss Cls: 0.1978, Train: 85.38%, Valid: 81.59%, Test: 83.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8672464853425547\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 433, Loss: 0.1991, Loss Cls: 0.1991, Train: 86.12%, Valid: 82.80%, Test: 85.01%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8645922998487575\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 434, Loss: 0.2010, Loss Cls: 0.2010, Train: 84.12%, Valid: 80.21%, Test: 82.58%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8644344556558423\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 435, Loss: 0.2017, Loss Cls: 0.2017, Train: 85.64%, Valid: 82.34%, Test: 84.54%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8628595400189458\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 436, Loss: 0.2024, Loss Cls: 0.2024, Train: 82.92%, Valid: 78.99%, Test: 81.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8634421560203926\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 437, Loss: 0.2019, Loss Cls: 0.2019, Train: 85.57%, Valid: 82.30%, Test: 84.47%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.864407014463182\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 438, Loss: 0.2012, Loss Cls: 0.2012, Train: 82.85%, Valid: 78.92%, Test: 81.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8649065103552491\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 439, Loss: 0.1996, Loss Cls: 0.1996, Train: 86.01%, Valid: 82.73%, Test: 84.90%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8678900133582426\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 440, Loss: 0.1982, Loss Cls: 0.1982, Train: 83.94%, Valid: 80.03%, Test: 82.56%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.867288631733913\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 441, Loss: 0.1965, Loss Cls: 0.1965, Train: 86.56%, Valid: 83.29%, Test: 85.47%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8708858736689816\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 442, Loss: 0.1955, Loss Cls: 0.1955, Train: 85.11%, Valid: 81.36%, Test: 83.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8674357240443135\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 443, Loss: 0.1953, Loss Cls: 0.1953, Train: 86.67%, Valid: 83.35%, Test: 85.57%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8704243848157363\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 444, Loss: 0.1967, Loss Cls: 0.1967, Train: 85.53%, Valid: 81.95%, Test: 84.25%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.862534610300477\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 445, Loss: 0.1994, Loss Cls: 0.1994, Train: 86.10%, Valid: 82.73%, Test: 84.95%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8647976939986551\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 446, Loss: 0.2039, Loss Cls: 0.2039, Train: 85.31%, Valid: 81.86%, Test: 84.09%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8548941606206163\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 447, Loss: 0.2080, Loss Cls: 0.2080, Train: 85.42%, Valid: 81.93%, Test: 84.25%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8599251452361895\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 448, Loss: 0.2093, Loss Cls: 0.2093, Train: 85.64%, Valid: 82.35%, Test: 84.45%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8543124892716927\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 449, Loss: 0.2091, Loss Cls: 0.2091, Train: 85.52%, Valid: 81.97%, Test: 84.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8639471323992824\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 450, Loss: 0.2047, Loss Cls: 0.2047, Train: 86.59%, Valid: 83.45%, Test: 85.44%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8624395288092317\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 451, Loss: 0.2005, Loss Cls: 0.2005, Train: 86.01%, Valid: 82.46%, Test: 84.87%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8717028747817696\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 452, Loss: 0.1952, Loss Cls: 0.1952, Train: 87.17%, Valid: 84.06%, Test: 86.06%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8702015747815864\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 453, Loss: 0.1922, Loss Cls: 0.1922, Train: 85.80%, Valid: 82.17%, Test: 84.66%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8746392273114744\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 454, Loss: 0.1913, Loss Cls: 0.1913, Train: 86.70%, Valid: 83.58%, Test: 85.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8705036104952829\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 455, Loss: 0.1924, Loss Cls: 0.1924, Train: 84.22%, Valid: 80.42%, Test: 83.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8702904096087489\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 456, Loss: 0.1958, Loss Cls: 0.1958, Train: 85.19%, Valid: 81.92%, Test: 84.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.864293492175619\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 457, Loss: 0.1993, Loss Cls: 0.1993, Train: 81.61%, Valid: 77.62%, Test: 80.48%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8622264687018453\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 458, Loss: 0.2051, Loss Cls: 0.2051, Train: 83.85%, Valid: 80.52%, Test: 82.65%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8584387823159793\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 459, Loss: 0.2057, Loss Cls: 0.2057, Train: 80.69%, Valid: 76.63%, Test: 79.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8595941034099093\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 460, Loss: 0.2082, Loss Cls: 0.2082, Train: 84.28%, Valid: 80.91%, Test: 83.02%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8595690126692555\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 461, Loss: 0.2034, Loss Cls: 0.2034, Train: 82.98%, Valid: 79.06%, Test: 81.82%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8648411375451671\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 462, Loss: 0.2019, Loss Cls: 0.2019, Train: 85.72%, Valid: 82.49%, Test: 84.54%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8643265012357046\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 463, Loss: 0.1982, Loss Cls: 0.1982, Train: 85.53%, Valid: 81.86%, Test: 84.35%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8712853832904214\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 464, Loss: 0.1955, Loss Cls: 0.1955, Train: 86.62%, Valid: 83.35%, Test: 85.43%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8679735389027429\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 465, Loss: 0.1935, Loss Cls: 0.1935, Train: 86.83%, Valid: 83.35%, Test: 85.59%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8761571466296477\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 466, Loss: 0.1908, Loss Cls: 0.1908, Train: 86.77%, Valid: 83.43%, Test: 85.61%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8704089117167065\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 467, Loss: 0.1898, Loss Cls: 0.1898, Train: 87.24%, Valid: 83.88%, Test: 86.04%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8780936593702396\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 468, Loss: 0.1891, Loss Cls: 0.1891, Train: 86.70%, Valid: 83.31%, Test: 85.55%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8702489947922822\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 469, Loss: 0.1890, Loss Cls: 0.1890, Train: 87.35%, Valid: 84.06%, Test: 86.12%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8780333134005903\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 470, Loss: 0.1891, Loss Cls: 0.1891, Train: 86.52%, Valid: 83.15%, Test: 85.36%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8686314495487528\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 471, Loss: 0.1896, Loss Cls: 0.1896, Train: 87.26%, Valid: 84.06%, Test: 86.09%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8770177180774524\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 472, Loss: 0.1901, Loss Cls: 0.1901, Train: 86.25%, Valid: 82.88%, Test: 85.11%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8668577075036643\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 473, Loss: 0.1910, Loss Cls: 0.1910, Train: 87.11%, Valid: 83.97%, Test: 85.96%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8759798201433869\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 474, Loss: 0.1911, Loss Cls: 0.1911, Train: 85.63%, Valid: 82.17%, Test: 84.46%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8649624570066072\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 475, Loss: 0.1929, Loss Cls: 0.1929, Train: 86.74%, Valid: 83.54%, Test: 85.63%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8744390668901311\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 476, Loss: 0.1931, Loss Cls: 0.1931, Train: 84.14%, Valid: 80.36%, Test: 82.85%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8615153501964099\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 477, Loss: 0.1971, Loss Cls: 0.1971, Train: 86.12%, Valid: 82.83%, Test: 85.00%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8720319166851715\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 478, Loss: 0.1965, Loss Cls: 0.1965, Train: 82.07%, Valid: 77.98%, Test: 80.63%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8593760991143713\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 479, Loss: 0.2005, Loss Cls: 0.2005, Train: 85.94%, Valid: 82.65%, Test: 84.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8722197593167934\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 480, Loss: 0.1964, Loss Cls: 0.1964, Train: 81.67%, Valid: 77.35%, Test: 80.07%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.863290360846911\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 481, Loss: 0.1972, Loss Cls: 0.1972, Train: 86.48%, Valid: 83.31%, Test: 85.37%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8759184791883492\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 482, Loss: 0.1915, Loss Cls: 0.1915, Train: 82.99%, Valid: 78.81%, Test: 81.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8699382951380039\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 483, Loss: 0.1904, Loss Cls: 0.1904, Train: 86.92%, Valid: 83.79%, Test: 85.84%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8796565226700602\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 484, Loss: 0.1865, Loss Cls: 0.1865, Train: 83.85%, Valid: 79.84%, Test: 82.39%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8742146838681523\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 485, Loss: 0.1864, Loss Cls: 0.1864, Train: 86.86%, Valid: 83.75%, Test: 85.77%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.880057984175759\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 486, Loss: 0.1855, Loss Cls: 0.1855, Train: 83.85%, Valid: 79.95%, Test: 82.41%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8737015382161477\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 487, Loss: 0.1873, Loss Cls: 0.1873, Train: 86.45%, Valid: 83.25%, Test: 85.34%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8768302180685358\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 488, Loss: 0.1885, Loss Cls: 0.1885, Train: 83.70%, Valid: 79.88%, Test: 82.32%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8705767663111014\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 489, Loss: 0.1911, Loss Cls: 0.1911, Train: 86.25%, Valid: 83.01%, Test: 85.15%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8728105196315908\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 490, Loss: 0.1920, Loss Cls: 0.1920, Train: 84.28%, Valid: 80.59%, Test: 82.99%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8685023605538978\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 491, Loss: 0.1939, Loss Cls: 0.1939, Train: 86.61%, Valid: 83.40%, Test: 85.48%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8713331533916858\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 492, Loss: 0.1927, Loss Cls: 0.1927, Train: 85.61%, Valid: 82.09%, Test: 84.38%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8705326301167231\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 493, Loss: 0.1923, Loss Cls: 0.1923, Train: 87.23%, Valid: 83.99%, Test: 86.03%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8739693236441233\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 494, Loss: 0.1891, Loss Cls: 0.1891, Train: 86.72%, Valid: 83.31%, Test: 85.54%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8756621948875649\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 495, Loss: 0.1872, Loss Cls: 0.1872, Train: 87.53%, Valid: 84.26%, Test: 86.30%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8778311465949213\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 496, Loss: 0.1846, Loss Cls: 0.1846, Train: 87.02%, Valid: 83.62%, Test: 85.80%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8791994281629736\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 497, Loss: 0.1839, Loss Cls: 0.1839, Train: 87.30%, Valid: 83.96%, Test: 86.08%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8783649902657403\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 498, Loss: 0.1840, Loss Cls: 0.1840, Train: 86.60%, Valid: 83.10%, Test: 85.38%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8787822962216831\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 499, Loss: 0.1850, Loss Cls: 0.1850, Train: 86.77%, Valid: 83.37%, Test: 85.51%\n",
            "num_B_prime:0, new edges:44906\n",
            "Batch 0.0, train acc:0.8751103664599889\n",
            "num_B_prime:0, new edges:44906\n",
            "num_B_prime:0, new edges:6514\n",
            "num_B_prime:0, new edges:5524\n",
            "Run: 1, Epoch: 500, Loss: 0.1868, Loss Cls: 0.1868, Train: 85.91%, Valid: 82.25%, Test: 84.65%\n",
            "Run 01:\n",
            "Highest Train: 87.53\n",
            "Highest Valid: 84.26\n",
            "  Final Train: 87.53\n",
            "   Final Test: 86.30\n",
            "All runs:\n",
            "Highest Train: 87.53 ± nan\n",
            "Highest Valid: 84.26 ± nan\n",
            "  Final Train: 87.53 ± nan\n",
            "   Final Test: 86.30 ± nan\n"
          ]
        }
      ]
    }
  ]
}